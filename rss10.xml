<?xml version="1.0"?>
<rdf:RDF
	xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:foaf="http://xmlns.com/foaf/0.1/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns="http://purl.org/rss/1.0/"
>
<channel rdf:about="http://planet.sympy.org/">
	<title>Planet SymPy</title>
	<link>http://planet.sympy.org/</link>
	<description>Planet SymPy - http://planet.sympy.org/</description>

	<items>
		<rdf:Seq>
			<rdf:li rdf:resource="http://dlpeterson.com/blog/?p=162" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=755" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=845" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-2520472460430880330.post-775661391652616507" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=838" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=546" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=587" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=597" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=694" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-7530661868168314621" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=621" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=531" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=547" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=536" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-2520472460430880330.post-5266141065935110948" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=834" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=828" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-3253966970864417650" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=440" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=417" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=820" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=810" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=307" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=782" />
			<rdf:li rdf:resource="http://dlpeterson.com/blog/?p=139" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=237" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=223" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=209" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-6568744196982634289.post-6825008418537862044" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-6568744196982634289.post-8933668259195859462" />
			<rdf:li rdf:resource="http://fseoane.net/blog/?p=192" />
			<rdf:li rdf:resource="http://fseoane.net/blog/2010/lars-algorithm/" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-4696399575844014395" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-6858896334629563490" />
			<rdf:li rdf:resource="http://fseoane.net/blog/2010/second-scikitslearn-coding-sprint/" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-5343369310477112221" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9135222751616024074.post-3829230650064961450" />
			<rdf:li rdf:resource="http://fseoane.net/blog/2010/support-for-sparse-matrices-in-scikitslearn/" />
			<rdf:li rdf:resource="http://fseoane.net/blog/2010/flags-to-debug-python-c-extensions/" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-6568744196982634289.post-7325250334673304185" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=741" />
			<rdf:li rdf:resource="http://ojensen.wordpress.com/?p=250" />
			<rdf:li rdf:resource="http://ojensen.wordpress.com/?p=219" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-22566012.post-4683860477825075771" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9135222751616024074.post-8172338055248531834" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-22566012.post-6375375338891344793" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-6568744196982634289.post-2896505029722157566" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-936818886435977143.post-8445992689514487932" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=710" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-8421138063566161330" />
			<rdf:li rdf:resource="http://ojensen.wordpress.com/?p=197" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9135222751616024074.post-143425197871935102" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-6568744196982634289.post-6122266783960777317" />
			<rdf:li rdf:resource="http://asmeurersympy.wordpress.com/?p=683" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-936818886435977143.post-5753626938397121846" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-22566012.post-6741089899169036082" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-4754734402679928849.post-4782331091283891322" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-6568744196982634289.post-274396393864768585" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-936818886435977143.post-2894031447728849147" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-22566012.post-7163828547914825642" />
		</rdf:Seq>
	</items>
</channel>

<item rdf:about="http://dlpeterson.com/blog/?p=162">
	<title>Dale Peterson: MathJax test</title>
	<link>http://dlpeterson.com/blog/?p=162</link>
	<content:encoded>&lt;p&gt;I’ve been using \(\LaTeX\) for about 7 years now, and have always been impressed with its ability to make math and text look amazing.  Obviously, a serious shortfall of the web has been to be able to incorporate math directly into web pages.  There have been lots of approaches, but most of them have been ugly hacks that just can’t replace \(\LaTeX\).  Until now.  MathJax looks amazing!  Here is a quick example:&lt;br /&gt;
\[&lt;br /&gt;
\begin{aligned}&lt;br /&gt;
P_\nu^{-\mu}(z)&amp;amp;=\frac{\left(z^2-1\right)^{\frac{\mu}{2}}}{2^\mu \sqrt{\pi}\Gamma\left(\mu+\frac{1}{2}\right)}\int_{-1}^1\frac{\left(1-t^2\right)^{\mu -\frac{1}{2}}}{\left(z+t\sqrt{z^2-1}\right)^{\mu-\nu}}dt\\&lt;br /&gt;
&amp;amp;=42\\&lt;br /&gt;
&amp;amp;=\boldsymbol{b}_1&lt;br /&gt;
\end{aligned}&lt;br /&gt;
\]&lt;/p&gt;
&lt;p&gt;Notice that you can click on the math, view the source that created it, and copy and paste it!!!&lt;/p&gt;
&lt;p&gt;This is really going to help science make better use of the web.&lt;/p&gt;</content:encoded>
	<dc:date>2011-05-11T23:32:13+00:00</dc:date>
	<dc:creator>luke</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=755">
	<title>Fabian Pedregosa: Handwritten digits and Locally Linear Embedding</title>
	<link>http://fseoane.net/blog/2011/handwritten-digits-and-locally-linear-embedding/</link>
	<content:encoded>&lt;p&gt;I decided to test my &lt;a href=&quot;http://fseoane.net/blog/2011/locally-linear-embedding-and-sparse-eigensolvers/&quot;&gt;new Locally Linear Embedding (LLE)&lt;/a&gt; implementation against a real dataset. At first I didn’t think this would turn out very well, since LLE seems to be somewhat fragile, yielding largely different results for small differences in parameters such as number of neighbors or tolerance, but as it turns out, results are not bad at all.&lt;/p&gt;
&lt;p&gt;The idea is to take a handwritten digit, stored as a 8×8 pixel image and flatten it into a an array of 8×8 = 64 floating-point values.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://fseoane.net/blog/wp-content/uploads/2011/05/digits_transformation1.png&quot;&gt;&lt;img src=&quot;http://fseoane.net/blog/wp-content/uploads/2011/05/digits_transformation1.png&quot; alt=&quot;&quot; title=&quot;digits_transformation&quot; class=&quot;aligncenter size-full wp-image-786&quot; width=&quot;350&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Then each handwritten digit can be seen as a point in a 64-dimensional space. Of course, visualizing in 64-dimensional spaces is not easy, and that’s where &lt;a href=&quot;http://fseoane.net/blog/2011/locally-linear-embedding-and-sparse-eigensolvers/&quot;&gt;Locally Linear Embedding&lt;/a&gt; comes handy. We’ll use this method to reduce the dimension from 64 to 2 with the hope of preserving most of the underlying manifold structure. The following is a plot of the handwritten digits {0, 1, 2, 3, 4} after performing locally linear embedding. As you can see, some groups are nicely clustered, notably the 0 is isolated while other like {4, 5} are closer, precisely those that are more similar.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://fseoane.net/blog/wp-content/uploads/2011/05/Picture-1.png&quot;&gt;&lt;img src=&quot;http://fseoane.net/blog/wp-content/uploads/2011/05/Picture-1.png&quot; alt=&quot;&quot; title=&quot;Digitst and Locally Linear Embedding&quot; class=&quot;aligncenter size-full wp-image-757&quot; width=&quot;500&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Source code for this example &lt;a href=&quot;https://gist.github.com/954815&quot;&gt;can be found here&lt;/a&gt; but relies on my manifold branch of scikit-learn. &lt;/p&gt;</content:encoded>
	<dc:date>2011-05-04T08:46:47+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=845">
	<title>Aaron Meurer: Advice for Future Prospective GSoC Students</title>
	<link>http://asmeurersympy.wordpress.com/2011/04/27/advice-for-future-prospective-gsoc-students/</link>
	<content:encoded>&lt;p&gt;So now that Google has &lt;a href=&quot;http://asmeurersympy.wordpress.com/2011/04/27/accepted-gsoc-students-announced/&quot;&gt;announced the results&lt;/a&gt; of Google Summer of Code, I want to write down some general things that I noticed when reviewing applications while they are still fresh in my mind.  &lt;/p&gt;
&lt;p&gt;Note that none of these things apply to any specific student who applied to SymPy.  Many of these things are things that I noticed that people did right.  &lt;/p&gt;
&lt;p&gt;Most of this should apply to any organization, though some of them might be SymPy specific, since that is the lens that I am viewing this through.  These aren’t really in any particular order.  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Fulfill all the requirements.&lt;/strong&gt; This is kind of a no brainer, and as it turns out, almost all students who applied to SymPy did indeed do this.  For SymPy, this means that you should submit a patch by the deadline. Other organizations might have other requirements.  If you don’t fulfill the requirements, it doesn’t matter how good your application is; you won’t be eligible and hence won’t be accepted.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Discuss your proposal on the mailing list.&lt;/strong&gt; A proposal submitted out of the blue has a poor chance of being accepted.  First, we like to see that you will be involved in the community, and if you don’t discuss the proposal at all, it shows badly.  Second, it is very likely that we will not like something about your proposal, or will have questions (see the next point).  If you don’t discuss it at all, you are making a shot in the dark.  Even if the proposal is good, it could be rejected simply because it’s not something that we feel that we want. And you don’t want to accidentally submit a proposal to do something that has already been implemented.
&lt;p&gt;It’s important to discuss it on the public mailing list, not just with a specific mentor.  Even if that mentor is the expert on your project subject and would likely be the person to mentor you if you are accepted, you need to remember that all the mentors review the proposals and decide who to accept.   Also, this year for SymPy, we are trying to put an emphasis on students doing things publicly with the whole community, instead of just with their mentors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ask the mentors for advice on your proposal, and then follow it.&lt;/strong&gt; Again, most students who applied to SymPy were good on this one too.  We request that all students put their proposals on the GitHub wiki, so that the mentors can take a look at them and give advice.  If you feel uncomfortable putting your application in a public place, send it to some mentors privately.
&lt;p&gt;But the most important thing here is to actually follow any advice that the mentors give you.  If they tell you that you should expand your timeline section, you should expand your timeline section.  If they tell you you should discuss the implementation more, you should do that (see the next point).  If you don’t follow the advice, it looks to the mentor like you didn’t listen to him, which doesn’t make you appear like a good candidate for acceptance.  Also, the things that they tell you to improve will tend to be the things that they will look at when reviewing your proposal.  &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Don’t just discuss the theory.&lt;/strong&gt; I suspect that this may be more of a problem with SymPy than for other organizations, because SymPy is very math based, so many of the proposals to SymPy involve complex mathematics. One of the biggest issues I saw in proposals was that students discussed the theory of what they wanted to implement too much and not enough of the actual implementation. It’s easy to do this, but discussing the implementation is actually more important than the theory of what you want to do.
&lt;p&gt;An easy way to do this is to give a “fake” example session showing how your code might work after it is completed.  For example, if you were writing a proposal for a PDE solver, you might include something like&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; u = Function('u')
&amp;gt;&amp;gt;&amp;gt; # Solve the Heat Equation in one dimension
&amp;gt;&amp;gt;&amp;gt; pdesolve(u(x, t).diff(t) - c**2*u(x, t).diff(x, x), u(x), {u(x, 0):f(x), u(0, t):0, u(0, pi):0}, method='separation of variables')
2/pi*Sum(Integral(f(x)*sin(n*x), x)*sin(n*x)*exp(-n**2*c**2*t), (n, 1, oo))
&amp;gt;&amp;gt;&amp;gt; # Use Fourier Transforms to get d'Alembert's Solution to the Wave Equation
&amp;gt;&amp;gt;&amp;gt; …
&lt;/pre&gt;
&lt;p&gt;in your proposal.  Just saying “I plan to implement solvers for PDEs using separation of variables and Fourier Transforms” tells us only what we already know, which is that you can solve PDEs using separation of variables and Fourier Transforms.  What we don’t know is how it will look.  The above example shows how the PDE, initial/boundary conditions, and method are entered by the user, and how the output looks.  &lt;/p&gt;
&lt;p&gt;A more advanced thing that you can do is to give actual prototype code. This is not required, but it can show that you are dedicated enough to get a start, and can demonstrate how things will work for more complicated projects.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;But theory is important too.&lt;/strong&gt; This might also be a problem more in SymPy, but maybe not.  The mathematical backgrounds of SymPy developers ranges quite a bit.  For example, I know a lot about the complicated Risch Algorithm for symbolic integration that the majority of people (even among SymPy developers) know hardly anything about, but I know basically nothing about quantum mechanics.  So that more mentors can have a chance to even have a clue about what you are talking about when they are reviewing your proposal, you should try to explain things to a general audience, at least in the introduction of your proposal.  It can also help to explain why your project would be useful, so that even if someone doesn’t know what it is, they can see why it would be nice to have.  This doesn’t mean that you should sacrifice details by dumbing everything down.  There’s a pretty good chance that someone will understand what you are talking about in your specifics, but you should also explain things from the other end.
&lt;p&gt;If you are implementing a specific algorithm, maybe you could give a brief overview of the algorithm.  This will not only explain things to the mentors who might not know how it works, but also it shows that you know how it works too.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be involved in the community.&lt;/strong&gt; We understand that students have classes during the application period, but the more you involve yourself in the community beyond the patch requirement (or whatever requirement some other org might have), the better your chances of being accepted. Every org has to take risks accepting students, because there is always the chance that they will fail.  This is not good for anyone: the student doesn’t get paid the full stipend and the organization looses not only the project that would have been implemented, but also the slot that they could have given to someone who wouldn’t have failed.  Involving yourself in the community early is the best way to show the community that you are a low risk for failure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The proposal is the most important thing.&lt;/strong&gt; But don’t assume that just because you are involved in the community that you will be accepted.  The most important thing is the proposal.  If you don’t have a good proposal, we will not even consider the rest of your activity.  So you should focus most of your energy on writing a high quality proposal.  The quality of the patch and your involvement in the community are secondary considerations after the quality of the proposal.  These might be used to narrow down the list of good proposals to fit the number of slots Google gives us and the number of mentors we have available, but the first phase is always to narrow down the list based on the quality of the proposals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use a consistant nickname, preferably one based on your real name.&lt;/strong&gt;  This is something that I think most people do not realize.  If your real name is John Smith, and your IRC nick, GitHub handle, Google Code handle, and GSoC link_id are all jsmith, it makes it very easy for me to associate in my mind: “OK, that person who just submitted that patch is the same person I talked to on IRC last week, and I remember reading his proposal on google-melange.com.”  But if your real name is John Smith, your IRC nick is freebird, your GitHub handle is mr.nice, your Google Code handle is smithy, and your link_id on google-melange.com is johnhsmith, I can have a very hard time associating your work in one place with your work in another (my apologies if those are anybodys’ real nicknames; I just made them up to make the point here).  Maybe you actually have been very active in the IRC channel, but it is hard for me to realize that based on your nick vs. your real name.  This year for SymPy, we had 25 applications by 25 students.  None of these students were members of the SymPy community a few months ago.  It’s very hard for the other mentors and I to keep track of which nicknames associate with which people, and in the end, we may mistakenly believe that you haven’t done as much as you really have.  Your best bet is to use one nickname everywhere, and to make it based on your real name, so that we can easily tell who it is even based on the nickname.  If your name is common enough that no one permutation is guaranteed to be available everywhere, at least try to be consistent with your nickname, or just use different permutations of your real name based on what site you are on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s all I can think of for now.  I kind of wish I had thought of two more, so I could make it “Ten pieces of advice,” but whatever.  If any SymPy mentors or mentors from other projects feel that something is missing, I would love to hear about it in the comments.&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/845/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/845/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=845&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2011-04-27T21:15:54+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-2520472460430880330.post-775661391652616507">
	<title>Official SymPy blog: Accepted GSoC Students Announced</title>
	<link>http://sympy.blogspot.com/2011/04/accepted-gsoc-students-announced.html</link>
	<content:encoded>&lt;div&gt;So Google has announced the results of &lt;a href=&quot;http://www.google-melange.com/gsoc/homepage/google/gsoc2011&quot;&gt;Google Summer of Code&lt;/a&gt;. I am proud to announce that we got nine slots from Google.  The following projects have been accepted: &lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;em&gt;(Project, Student, Mentor, Link to proposal on the wiki) &lt;/em&gt;&lt;/div&gt;&lt;em&gt;&lt;/em&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;Definite Integration using Meijer G-functions, Tom Bachmann, Aaron Meurer, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Tom-Bachmann%3A-Definite-Integration&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;PyDy, Gilbert Gede, Luke Peterson, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Gilbert-Gede%3A-PyDy&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Position and Momentum Bases for Quantum Mechanics, Tomo Lazovich, Brian Granger, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Tomo-Lazovich%3A-Position-and-Momentum-Bases-for-QM&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Combinatorics package for Sympy, Saptarshi Mandal, Christian Muise, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Saptarshi-Mandal&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Symbolic Linear Algebra, Sherjil Ozair, Vinzent Steinberg, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Sherjil-Ozair:-Symbolic-Linear-Algebra&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Porting to Python 3, Vladimir Perić, Ronan Lamy, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application%3A-Vladimir-Peri%C4%87%3A-Porting-to-Python-3&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;SymPy Stats: Random Variables, Matthew Rocklin, Andy Terrel, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Matthew-Rocklin%3A-Random-Variables&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Symbolic Clebsch-Gordon coefficients/Wigner symbols and Implementing Addition of Spin Angular Momenta, Sean Vig, Ondřej Čertík, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC%202011%20Application%20Sean%20Vig&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Implementing F5, Jeremias Yehdegho, Mateusz Paprocki, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Jeremias-Yehdegho%3A-Implementing-F5&quot;&gt;Proposal&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Join me in congratulating these students on their acceptance.   &lt;/div&gt;&lt;div&gt;In case you don't know for some reason, Google Summer of Code is a program where Google pays students to write code for open source projects.  SymPy was accepted as a mentoring organization this year.  The goal of the summer is to help the students learn new skills, in particular in our case: &lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt; contributing to open source &lt;/li&gt;&lt;li&gt; working with the community &lt;/li&gt;&lt;li&gt; learn git, pull requests, reviews &lt;/li&gt;&lt;li&gt; teach them how to review other's people patches &lt;/li&gt;&lt;li&gt; do useful work for SymPy &lt;/li&gt;&lt;li&gt; have fun, and encourage the students to stay around &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Also see the &lt;a href=&quot;http://sympy.blogspot.com/2011/03/sympy-is-google-summer-of-code-2011.html&quot;&gt;previous blog post&lt;/a&gt; about it.&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/2520472460430880330-775661391652616507?l=sympy.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2011-04-27T19:46:21+00:00</dc:date>
	<dc:creator>Aaron Meurer</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=838">
	<title>Aaron Meurer: Accepted GSoC Students Announced</title>
	<link>http://asmeurersympy.wordpress.com/2011/04/27/accepted-gsoc-students-announced/</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;(Cross posted on the &lt;a href=&quot;http://sympy.blogspot.com/2011/04/accepted-gsoc-students-announced.html&quot;&gt;Official SymPy Blog&lt;/a&gt;)&lt;/em&gt;&lt;br /&gt;
So Google has announced the results of &lt;a href=&quot;http://www.google-melange.com/gsoc/homepage/google/gsoc2011&quot;&gt;Google Summer of Code&lt;/a&gt;. I am proud to announce that we got nine slots from Google.  The following projects have been accepted: &lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Project, Student, Mentor, Link to proposal on the wiki)&lt;br /&gt;
&lt;/em&gt;- Definite Integration using Meijer G-functions, Tom Bachmann, Aaron Meurer, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Tom-Bachmann%3A-Definite-Integration&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- PyDy, Gilbert Gede, Luke Peterson, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Gilbert-Gede%3A-PyDy&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- Position and Momentum Bases for Quantum Mechanics, Tomo Lazovich, Brian Granger, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Tomo-Lazovich%3A-Position-and-Momentum-Bases-for-QM&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- Combinatorics package for Sympy, Saptarshi Mandal, Christian Muise, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Saptarshi-Mandal&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- Symbolic Linear Algebra, Sherjil Ozair, Vinzent Steinberg, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Sherjil-Ozair:-Symbolic-Linear-Algebra&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- Porting to Python 3, Vladimir Perić, Ronan Lamy, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application%3A-Vladimir-Perić%3A-Porting-to-Python-3&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- SymPy Stats: Random Variables, Matthew Rocklin, Andy Terrel, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Matthew-Rocklin%3A-Random-Variables&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- Symbolic Clebsch-Gordon coefficients/Wigner symbols and Implementing Addition of Spin Angular Momenta, Sean Vig, Ondřej Čertík, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC%202011%20Application%20Sean%20Vig&quot;&gt;Proposal&lt;/a&gt;&lt;br /&gt;
- Implementing F5, Jeremias Yehdegho, Mateusz Paprocki, &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Jeremias-Yehdegho%3A-Implementing-F5&quot;&gt;Proposal&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Join me in congratulating these students on their acceptance.&lt;br /&gt;
In case you don’t know for some reason, Google Summer of Code is a program where Google pays students to write code for open source projects.  SymPy was accepted as a mentoring organization this year.  The goal of the summer is to help the students learn new skills, in particular in our case:&lt;br /&gt;
* contributing to open source&lt;br /&gt;
* working with the community&lt;br /&gt;
* learn git, pull requests, reviews&lt;br /&gt;
* teach them how to review other’s people patches&lt;br /&gt;
* do useful work for SymPy&lt;br /&gt;
* have fun, and encourage the students to stay around &lt;/p&gt;
&lt;p&gt;Also see my &lt;a href=&quot;http://asmeurersympy.wordpress.com/2011/03/18/sympy-is-a-google-summer-of-code-2011-mentoring-organization/&quot;&gt;previous blog post&lt;/a&gt; about it.&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/838/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/838/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=838&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2011-04-27T19:45:06+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=546">
	<title>Fabian Pedregosa: Low-level routines for Support Vector Machines</title>
	<link>http://fseoane.net/blog/2011/low-level-routines-for-support-vector-machines/</link>
	<content:encoded>&lt;p&gt;I’ve been working lately in improving the low-level API of the libsvm bindings in scikit-learn. The goal is to provide an API that encourages an efficient use of these libraries for expert users.&lt;/p&gt;
&lt;p&gt;These are methods that have lower overhead than the &lt;a href=&quot;http://scikit-learn.sourceforge.net/modules/svm.html&quot;&gt;object-oriented interface&lt;/a&gt; as they are closer to the C implementation, but do not have an interface as polished. Here, all parameters are expected to be of the correct type, and submitting one of the wrong type will make the function exit immediately with a ValueError. For instance, input data is expected to be of type float64, even for class labels!&lt;/p&gt;
&lt;p&gt;Another peculiarity of these methods is that they only take and return numpy arrays. No custom objects, all method take and return arrays. That looks something like:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; numpy &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;as&lt;/span&gt; np&lt;br /&gt;
&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; scikits.&lt;span style=&quot;color: black;&quot;&gt;learn&lt;/span&gt; &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; svm, datasets&lt;br /&gt;
&lt;br /&gt;
iris = datasets.&lt;span style=&quot;color: black;&quot;&gt;load_iris&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
iris.&lt;span style=&quot;color: black;&quot;&gt;target&lt;/span&gt; = iris.&lt;span style=&quot;color: black;&quot;&gt;target&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;astype&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;np.&lt;span style=&quot;color: black;&quot;&gt;float64&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
learned_params = svm.&lt;span style=&quot;color: black;&quot;&gt;libsvm&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;fit&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;iris.&lt;span style=&quot;color: black;&quot;&gt;data&lt;/span&gt;, iris.&lt;span style=&quot;color: black;&quot;&gt;target&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
pred = svm.&lt;span style=&quot;color: black;&quot;&gt;libsvm&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;predict&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;iris.&lt;span style=&quot;color: black;&quot;&gt;data&lt;/span&gt;, &lt;span style=&quot;color: #66cc66;&quot;&gt;*&lt;/span&gt;learned_params&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here, I used the fact that the parameters returned by &lt;a href=&quot;http://scikit-learn.sourceforge.net/dev/modules/generated/scikits.learn.svm.libsvm.fit.html&quot;&gt;libsvm.fit&lt;/a&gt; can just passed to &lt;a href=&quot;http://scikit-learn.sourceforge.net/dev/modules/generated/scikits.learn.svm.libsvm.predict.html&quot;&gt;libsvm.predict&lt;/a&gt;. However, any other given parameters should be manually passed to both method.&lt;/p&gt;</content:encoded>
	<dc:date>2011-04-27T13:27:17+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=587">
	<title>Fabian Pedregosa: new get_blas_funcs in scipy.linalg</title>
	<link>http://fseoane.net/blog/2011/new-get_blas_funcs-in-scipy-linalg/</link>
	<content:encoded>&lt;p&gt;Today got merged some changes I made to function scipy.linalg.get_blas_funcs(). The main enhacement is that get_blas_funcs() now also accepts a single string as input parameter and a dtype, so that fetching the BLAS function for a specific type becomes more natural. &lt;/p&gt;
&lt;p&gt;For example, fetching the gemm routine for a single-precision complex number now looks like this:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;gemm = scipy.&lt;span style=&quot;color: black;&quot;&gt;linalg&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;get_blas_funcs&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: #483d8b;&quot;&gt;'gemm'&lt;/span&gt;, dtype=np.&lt;span style=&quot;color: black;&quot;&gt;complex64&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;compared to the clumsy old syntax:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;X = np.&lt;span style=&quot;color: black;&quot;&gt;empty&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, dtype=np.&lt;span style=&quot;color: black;&quot;&gt;complex64&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
gemm, = scipy.&lt;span style=&quot;color: black;&quot;&gt;linalg&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;get_blas_funcs&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: #483d8b;&quot;&gt;'gemm'&lt;/span&gt;,&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;X,&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2011-04-23T16:24:17+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=597">
	<title>Fabian Pedregosa: Locally linear embedding and sparse eigensolvers</title>
	<link>http://fseoane.net/blog/2011/locally-linear-embedding-and-sparse-eigensolvers/</link>
	<content:encoded>&lt;p&gt;I’ve been working for some time on implementing a &lt;a href=&quot;http://www.cs.nyu.edu/~roweis/lle/algorithm.html&quot;&gt;locally linear embedding&lt;/a&gt; algorithm for the upcoming manifold module in scikit-learn. &lt;/p&gt;
&lt;p&gt;While several implementations of this algorithm exist in Python, as far as I know none of them is able to use a sparse eigensolver in the last step of the algorithm, falling back to dense routines causing a huge overhead in this step. &lt;/p&gt;
&lt;p&gt;To overcome this, my first implementation used &lt;code&gt;scipy.sparse.linalg.eigsh&lt;/code&gt;, which is a sparse eigensolver shipped by scipy and based on ARPACK. However, this approach converged extremely slowly, with timings that exceeded largely those of dense solvers.&lt;/p&gt;
&lt;p&gt;Recently I found a way that seems to work reasonably well, with timings that win by a factor of 5 on the swiss roll existing routines. This code is able to solve the problem making use of a preconditioner computed by &lt;a href=&quot;http://code.google.com/p/pyamg/&quot;&gt;PyAMG&lt;/a&gt;.&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; numpy &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;as&lt;/span&gt; np&lt;br /&gt;
&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; scipy.&lt;span style=&quot;color: black;&quot;&gt;sparse&lt;/span&gt; &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; linalg, eye&lt;br /&gt;
&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; pyamg &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; smoothed_aggregation_solver&lt;br /&gt;
&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; scikits.&lt;span style=&quot;color: black;&quot;&gt;learn&lt;/span&gt; &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; neighbors&lt;br /&gt;
&lt;br /&gt;
&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;def&lt;/span&gt; locally_linear_embedding&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;X, n_neighbors, out_dim, tol=1e-6, max_iter=&lt;span style=&quot;color: #ff4500;&quot;&gt;200&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;:&lt;br /&gt;
    W = neighbors.&lt;span style=&quot;color: black;&quot;&gt;kneighbors_graph&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;br /&gt;
        X, n_neighbors=n_neighbors, mode=&lt;span style=&quot;color: #483d8b;&quot;&gt;'barycenter'&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
    &lt;span style=&quot;color: #808080; font-style: italic;&quot;&gt;# M = (I-W)' (I-W)&lt;/span&gt;&lt;br /&gt;
    A = eye&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: #66cc66;&quot;&gt;*&lt;/span&gt;W.&lt;span style=&quot;color: black;&quot;&gt;shape&lt;/span&gt;, format=W.&lt;span style=&quot;color: black;&quot;&gt;format&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt; - W&lt;br /&gt;
    A = &lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A.&lt;span style=&quot;color: black;&quot;&gt;T&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;tocsr&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
    &lt;span style=&quot;color: #808080; font-style: italic;&quot;&gt;# initial approximation to the eigenvectors&lt;/span&gt;&lt;br /&gt;
    X = np.&lt;span style=&quot;color: #dc143c;&quot;&gt;random&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;rand&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;W.&lt;span style=&quot;color: black;&quot;&gt;shape&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, out_dim&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    ml = smoothed_aggregation_solver&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A, symmetry=&lt;span style=&quot;color: #483d8b;&quot;&gt;'symmetric'&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    prec = ml.&lt;span style=&quot;color: black;&quot;&gt;aspreconditioner&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
    &lt;span style=&quot;color: #808080; font-style: italic;&quot;&gt;# compute eigenvalues and eigenvectors with LOBPCG&lt;/span&gt;&lt;br /&gt;
    eigen_values, eigen_vectors = linalg.&lt;span style=&quot;color: black;&quot;&gt;lobpcg&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;br /&gt;
        A, X, M=prec, largest=&lt;span style=&quot;color: #008000;&quot;&gt;False&lt;/span&gt;, tol=tol, maxiter=max_iter&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
    index = np.&lt;span style=&quot;color: black;&quot;&gt;argsort&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;eigen_values&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;return&lt;/span&gt; eigen_vectors&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;:, index&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, np.&lt;span style=&quot;color: #008000;&quot;&gt;sum&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;eigen_values&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Full code for this algorithm applied to the swiss roll can be found here &lt;a href=&quot;https://gist.github.com/934363&quot;&gt;here&lt;/a&gt;, and I hope it will soon be part of &lt;a href=&quot;http://scikit-learn.sourceforge.net/&quot;&gt;scikit-learn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://fseoane.net/blog/wp-content/uploads/2011/04/lle1.png&quot;&gt;&lt;img src=&quot;http://fseoane.net/blog/wp-content/uploads/2011/04/lle1-690x1024.png&quot; alt=&quot;&quot; title=&quot;Locally linear embedding on the swiss roll&quot; class=&quot;aligncenter size-large wp-image-731&quot; width=&quot;500&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2011-04-21T12:28:17+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=694">
	<title>Fabian Pedregosa: scikits.learn is now part of pythonxy</title>
	<link>http://fseoane.net/blog/2011/scikits-learn-is-now-part-of-pythonxy/</link>
	<content:encoded>&lt;p&gt;The guys behind &lt;a href=&quot;http://www.pythonxy.com/&quot;&gt;pythonxy&lt;/a&gt; have been kind enough to add the latest scikit-learn as an &lt;a href=&quot;http://code.google.com/p/pythonxy/wiki/AdditionalPlugins&quot;&gt;additional plugin&lt;/a&gt; for their distribution. Having scikit-learn being in both &lt;a href=&quot;http://www.pythonxy.com/&quot;&gt;pythonxy&lt;/a&gt; and &lt;a href=&quot;http://www.enthought.com/products/epd.php&quot;&gt;EPD&lt;/a&gt; will hopefully make it easier to use for Windows users.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://fseoane.net/blog/wp-content/uploads/2011/04/pythonxy-logo.png&quot; title=&quot;pythonxy-logo&quot; height=&quot;70&quot; width=&quot;161&quot; alt=&quot;pythonxy-logo&quot; class=&quot;alignnone size-full wp-image-695&quot; /&gt;&lt;/p&gt;
&lt;p&gt;For now I will continue to make windows precompiled binaries, but pythonxy users finally have a package that is guaranteed to work with their installation.&lt;/p&gt;</content:encoded>
	<dc:date>2011-04-20T11:48:45+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-7530661868168314621">
	<title>Fredrik Johansson: 100 mpmath one-liners for pi</title>
	<link>http://fredrik-j.blogspot.com/2011/03/100-mpmath-one-liners-for-pi.html</link>
	<content:encoded>Since it's pi day today, I thought I'd share a list of mpmath one-liners for computing the value of pi to high precision using various representations in terms of special functions, infinite series, integrals, etc. Most of them can already be found as doctest examples in some form in the mpmath documentation.&lt;br /&gt;&lt;br /&gt;A few of the formulas explicitly involve pi. Using those to calculate pi is rather &lt;i&gt;circular&lt;/i&gt; (!), though a few of them could still be used for computing pi using numerical root-finding. In any case, most of the formulas are circular even when pi doesn't appear explicitly since mpmath is likely using its value internally. In any &lt;i&gt;further&lt;/i&gt; case, the majority of the formulas are not efficient for computing pi to very high precision (at least as written). Still, ~50 digits is no problem. Enjoy!&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;from mpmath import *&lt;br /&gt;mp.dps = 50; mp.pretty = True&lt;br /&gt;&lt;br /&gt;+pi&lt;br /&gt;180*degree&lt;br /&gt;4*atan(1)&lt;br /&gt;16*acot(5)-4*acot(239)&lt;br /&gt;48*acot(49)+128*acot(57)-20*acot(239)+48*acot(110443)&lt;br /&gt;chop(2*j*log((1-j)/(1+j)))&lt;br /&gt;chop(-2j*asinh(1j))&lt;br /&gt;chop(ci(-inf)/1j)&lt;br /&gt;gamma(0.5)**2&lt;br /&gt;beta(0.5,0.5)&lt;br /&gt;(2/diff(erf, 0))**2&lt;br /&gt;findroot(sin, 3)&lt;br /&gt;findroot(cos, 1)*2&lt;br /&gt;chop(-2j*lambertw(-pi/2))&lt;br /&gt;besseljzero(0.5,1)&lt;br /&gt;3*sqrt(3)/2/hyp2f1((-1,3),(1,3),1,1)&lt;br /&gt;8/(hyp2f1(0.5,0.5,1,0.5)*gamma(0.75)/gamma(1.25))**2&lt;br /&gt;4*(hyp1f2(1,1.5,1,1) / struvel(-0.5, 2))**2&lt;br /&gt;1/meijerg([[],[]], [[0],[0.5]], 0)**2&lt;br /&gt;(meijerg([[],[2]], [[1,1.5],[]], 1, 0.5) / erfc(1))**2&lt;br /&gt;(1-e) / meijerg([[1],[0.5]], [[1],[0.5,0]], 1)&lt;br /&gt;sqrt(psi(1,0.25)-8*catalan)&lt;br /&gt;elliprc(1,2)*4&lt;br /&gt;elliprg(0,1,1)*4&lt;br /&gt;2*agm(1,0.5)*ellipk(0.75)&lt;br /&gt;(gamma(0.75)*jtheta(3,0,exp(-pi)))**4&lt;br /&gt;cbrt(gamma(0.25)**4*agm(1,sqrt(2))**2/8)&lt;br /&gt;sqrt(6*zeta(2))&lt;br /&gt;sqrt(6*(zeta(2,3)+5./4))&lt;br /&gt;sqrt(zeta(2,(3,4))+8*catalan)&lt;br /&gt;exp(-2*zeta(0,1,1))/2&lt;br /&gt;sqrt(12*altzeta(2))&lt;br /&gt;4*dirichlet(1,[0,1,0,-1])&lt;br /&gt;2*catalan/dirichlet(-1,[0,1,0,-1],1)&lt;br /&gt;exp(-dirichlet(0,[0,1,0,-1],1))*gamma(0.25)**2/(2*sqrt(2))&lt;br /&gt;sqrt(7*zeta(3)/(4*diff(lerchphi, (-1,-2,1), (0,1,0))))&lt;br /&gt;sqrt(-12*polylog(2,-1))&lt;br /&gt;sqrt(6*log(2)**2+12*polylog(2,0.5))&lt;br /&gt;chop(root(-81j*(polylog(3,root(1,3,1))+4*zeta(3)/9)/2,3))&lt;br /&gt;2*clsin(1,1)+1&lt;br /&gt;(3+sqrt(3)*sqrt(1+8*clcos(2,1)))/2&lt;br /&gt;root(2,6)*sqrt(e)/(glaisher**6*barnesg(0.5)**4)&lt;br /&gt;nsum(lambda k: 4*(-1)**(k+1)/(2*k-1), [1,inf])&lt;br /&gt;nsum(lambda k: (3**k-1)/4**k*zeta(k+1), [1,inf])&lt;br /&gt;nsum(lambda k: 8/(2*k-1)**2, [1,inf])**0.5&lt;br /&gt;nsum(lambda k: 2*fac(k)/fac2(2*k+1), [0,inf])&lt;br /&gt;nsum(lambda k: fac(k)**2/fac(2*k+1), [0,inf])*3*sqrt(3)/2&lt;br /&gt;nsum(lambda k: fac(k)**2/(phi**(2*k+1)*fac(2*k+1)), [0,inf])*(5*sqrt(phi+2))/2&lt;br /&gt;nsum(lambda k: (4/(8*k+1)-2/(8*k+4)-1/(8*k+5)-1/(8*k+6))/16**k, [0,inf])&lt;br /&gt;2/nsum(lambda k: (-1)**k*(4*k+1)*(fac2(2*k-1)/fac2(2*k))**3, [0,inf])&lt;br /&gt;nsum(lambda k: 72/(k*expm1(k*pi))-96/(k*expm1(2*pi*k))+24/(k*expm1(4*pi*k)), [1,inf])&lt;br /&gt;1/nsum(lambda k: binomial(2*k,k)**3*(42*k+5)/2**(12*k+4), [0,inf])&lt;br /&gt;4/nsum(lambda k: (-1)**k*(1123+21460*k)*fac2(2*k-1)*fac2(4*k-1)/(882**(2*k+1)*32**k*fac(k)**3), [0,inf])&lt;br /&gt;9801/sqrt(8)/nsum(lambda k: fac(4*k)*(1103+26390*k)/(fac(k)**4*396**(4*k)), [0,inf])&lt;br /&gt;426880*sqrt(10005)/nsum(lambda k: (-1)**k*fac(6*k)*(13591409+545140134*k)/(fac(k)**3*fac(3*k)*(640320**3)**k), [0,inf])&lt;br /&gt;4/nsum(lambda k: (6*k+1)*rf(0.5,k)**3/(4**k*fac(k)**3), [0,inf])&lt;br /&gt;(ln(8)+sqrt(48*nsum(lambda m,n: (-1)**(m+n)/(m**2+n**2), [1,inf],[1,inf]) + 9*log(2)**2))/2&lt;br /&gt;-nsum(lambda x,y: (-1)**(x+y)/(x**2+y**2), [-inf,inf], [-inf,inf], ignore=True)/ln2&lt;br /&gt;2*nsum(lambda k: sin(k)/k, [1,inf])+1&lt;br /&gt;quad(lambda x: 2/(x**2+1), [0,inf])&lt;br /&gt;quad(lambda x: exp(-x**2), [-inf,inf])**2&lt;br /&gt;2*quad(lambda x: sqrt(1-x**2), [-1,1])&lt;br /&gt;chop(quad(lambda z: 1/(2j*z), [1,j,-1,-j,1]))&lt;br /&gt;3*(4*log(2+sqrt(3))-quad(lambda x,y: 1/sqrt(1+x**2+y**2), [-1,1],[-1,1]))/2&lt;br /&gt;sqrt(8*quad(lambda x,y: 1/(1-(x*y)**2), [0,1],[0,1]))&lt;br /&gt;sqrt(6*quad(lambda x,y: 1/(1-x*y), [0,1],[0,1]))&lt;br /&gt;sqrt(6*quad(lambda x: x/expm1(x), [0,inf]))&lt;br /&gt;quad(lambda x: (16*x-16)/(x**4-2*x**3+4*x-4), [0,1])&lt;br /&gt;quad(lambda x: sqrt(x-x**2), [0,0.25])*24+3*sqrt(3)/4&lt;br /&gt;mpf(22)/7 - quad(lambda x: x**4*(1-x)**4/(1+x**2), [0,1])&lt;br /&gt;mpf(355)/113 - quad(lambda x: x**8*(1-x)**8*(25+816*x**2)/(1+x**2), [0,1])/3164&lt;br /&gt;2*quadosc(lambda x: sin(x)/x, [0,inf], omega=1)&lt;br /&gt;40*quadosc(lambda x: sin(x)**6/x**6, [0,inf], omega=1)/11&lt;br /&gt;e*quadosc(lambda x: cos(x)/(1+x**2), [-inf,inf], omega=1)&lt;br /&gt;8*quadosc(lambda x: cos(x**2), [0,inf], zeros=lambda n: sqrt(n))**2&lt;br /&gt;2*quadosc(lambda x: sin(exp(x)), [1,inf], zeros=ln)+2*si(e)&lt;br /&gt;exp(2*quad(loggamma, [0,1]))/2&lt;br /&gt;2*nprod(lambda k: sec(pi/2**k), [2,inf])&lt;br /&gt;s=lambda k: sqrt(0.5+s(k-1)/2) if k else 0; 2/nprod(s, [1,inf])&lt;br /&gt;s=lambda k: sqrt(2+s(k-1)) if k else 0; limit(lambda k: sqrt(2-s(k))*2**(k+1), inf)&lt;br /&gt;2*nprod(lambda k: (2*k)**2/((2*k-1)*(2*k+1)), [1,inf])&lt;br /&gt;2*nprod(lambda k: (4*k**2)/(4*k**2-1), [1, inf])&lt;br /&gt;sqrt(6*ln(nprod(lambda k: exp(1/k**2), [1,inf])))&lt;br /&gt;nprod(lambda k: (k**2-1)/(k**2+1), [2,inf])/csch(pi)&lt;br /&gt;nprod(lambda k: (k**2-1)/(k**2+1), [2,inf])*sinh(pi)&lt;br /&gt;nprod(lambda k: (k**4-1)/(k**4+1), [2, inf])*(cosh(sqrt(2)*pi)-cos(sqrt(2)*pi))/sinh(pi)&lt;br /&gt;sinh(pi)/nprod(lambda k: (1-1/k**4), [2, inf])/4&lt;br /&gt;sinh(pi)/nprod(lambda k: (1+1/k**2), [2, inf])/2&lt;br /&gt;(exp(1+euler/2)/nprod(lambda n: (1+1/n)**n * exp(1/(2*n)-1), [1, inf]))**2/2&lt;br /&gt;3*sqrt(2)*cosh(pi*sqrt(3)/2)**2*csch(pi*sqrt(2))/nprod(lambda k: (1+1/k+1/k**2)**2/(1+2/k+3/k**2), [1, inf])&lt;br /&gt;2/e*nprod(lambda k: (1+2/k)**((-1)**(k+1)*k), [1,inf])&lt;br /&gt;limit(lambda k: 16**k/(k*binomial(2*k,k)**2), inf)&lt;br /&gt;limit(lambda x: 4*x*hyp1f2(0.5,1.5,1.5,-x**2), inf)&lt;br /&gt;1/log(limit(lambda n: nprod(lambda k: pi/(2*atan(k)), [n,2*n]), inf),4)&lt;br /&gt;limit(lambda k: 2**(4*k+1)*fac(k)**4/(2*k+1)/fac(2*k)**2, inf)&lt;br /&gt;limit(lambda k: fac(k) / (sqrt(k)*(k/e)**k), inf)**2/2&lt;br /&gt;limit(lambda k: (-(-1)**k*bernoulli(2*k)*2**(2*k-1)/fac(2*k))**(-1/(2*k)), inf)&lt;br /&gt;limit(lambda k: besseljzero(1,k)/k, inf)&lt;br /&gt;1/limit(lambda x: airyai(x)*2*x**0.25*exp(2*x**1.5/3), inf, exp=True)**2&lt;br /&gt;1/limit(lambda x: airybi(x)*x**0.25*exp(-2*x**1.5/3), inf, exp=True)**2&lt;br /&gt;&lt;/pre&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-7530661868168314621?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2011-04-16T17:39:13+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=621">
	<title>Fabian Pedregosa: Least squares with equality constrain</title>
	<link>http://fseoane.net/blog/2011/least-squares-with-equality-constrain/</link>
	<content:encoded>&lt;p&gt;The following algorithm computes the Least squares solution || Ax – b|| subject to the equality constrain Bx = d. It’s a classic algorithm that can be implemented only using a QR decomposition and a least squares solver. &lt;/p&gt;
&lt;p&gt;This implementation uses numpy and scipy. It makes use of the new linalg.solve_triangular function in scipy 0.9, although degrades to linalg.solve on older versions.&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; numpy &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;as&lt;/span&gt; np&lt;br /&gt;
&lt;br /&gt;
&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;def&lt;/span&gt; lse&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A, b, B, d, cond=&lt;span style=&quot;color: #008000;&quot;&gt;None&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;:&lt;br /&gt;
    &lt;span style=&quot;color: #483d8b;&quot;&gt;&quot;&quot;&quot;&lt;br /&gt;
    Equality-contrained least squares.&lt;br /&gt;
&lt;br /&gt;
    The following algorithm minimizes ||Ax - b|| subject to the&lt;br /&gt;
    constrain Bx = d.&lt;br /&gt;
&lt;br /&gt;
    Parameters&lt;br /&gt;
    ----------&lt;br /&gt;
    A : array-like, shape=[m, n]&lt;br /&gt;
&lt;br /&gt;
    b : array-like, shape=[m]&lt;br /&gt;
&lt;br /&gt;
    B : array-like, shape=[p, n]&lt;br /&gt;
&lt;br /&gt;
    d : array-like, shape=[p]&lt;br /&gt;
&lt;br /&gt;
    cond : float, optional&lt;br /&gt;
        Cutoff for 'small' singular values; used to determine effective&lt;br /&gt;
        rank of A. Singular values smaller than&lt;br /&gt;
        ``rcond * largest_singular_value`` are considered zero.&lt;br /&gt;
&lt;br /&gt;
    Reference&lt;br /&gt;
    ---------&lt;br /&gt;
    Matrix Computations, Golub &amp;amp; van Loan, algorithm 12.1.2&lt;br /&gt;
&lt;br /&gt;
    Examples&lt;br /&gt;
    --------&lt;br /&gt;
    &amp;gt;&amp;gt;&amp;gt; A, b = [[0, 2, 3], [1, 3, 4.5]], [1, 1]&lt;br /&gt;
    &amp;gt;&amp;gt;&amp;gt; B, d = [[1, 1, 0]], [1]&lt;br /&gt;
    &amp;gt;&amp;gt;&amp;gt; lse(A, b, B, d)&lt;br /&gt;
    array([-0.5       ,  1.5       , -0.66666667])    &lt;br /&gt;
    &quot;&quot;&quot;&lt;/span&gt;&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; scipy &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; linalg&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;if&lt;/span&gt; &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;not&lt;/span&gt; &lt;span style=&quot;color: #008000;&quot;&gt;hasattr&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;linalg, &lt;span style=&quot;color: #483d8b;&quot;&gt;'solve_triangular'&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;:&lt;br /&gt;
        &lt;span style=&quot;color: #808080; font-style: italic;&quot;&gt;# compatibility for old scipy&lt;/span&gt;&lt;br /&gt;
        &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;def&lt;/span&gt; solve_triangular&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;X, y, &lt;span style=&quot;color: #66cc66;&quot;&gt;**&lt;/span&gt;kwargs&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;:&lt;br /&gt;
            &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;return&lt;/span&gt; linalg.&lt;span style=&quot;color: black;&quot;&gt;solve&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;X, y&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;else&lt;/span&gt;:&lt;br /&gt;
        solve_triangular = linalg.&lt;span style=&quot;color: black;&quot;&gt;solve_triangular&lt;/span&gt;&lt;br /&gt;
    A, b, B, d = &lt;span style=&quot;color: #008000;&quot;&gt;map&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;np.&lt;span style=&quot;color: black;&quot;&gt;asanyarray&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A, b, B, d&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    p = B.&lt;span style=&quot;color: black;&quot;&gt;shape&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;
    Q, R = linalg.&lt;span style=&quot;color: black;&quot;&gt;qr&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;B.&lt;span style=&quot;color: black;&quot;&gt;T&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    y = solve_triangular&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;R&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;:p, :p&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, d, trans=&lt;span style=&quot;color: #483d8b;&quot;&gt;'T'&lt;/span&gt;, lower=&lt;span style=&quot;color: #008000;&quot;&gt;False&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    A = np.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A, Q&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    z = linalg.&lt;span style=&quot;color: black;&quot;&gt;lstsq&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;:, p:&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, b - np.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;A&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;:, :p&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, y&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;, &lt;br /&gt;
                         cond=cond&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;ravel&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;return&lt;/span&gt; np.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;Q&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;:, :p&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, y&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt; + np.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;Q&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;:, p:&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, z&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2011-04-14T08:02:10+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=531">
	<title>Fabian Pedregosa: A profiler for Python extensions</title>
	<link>http://fseoane.net/blog/2011/a-profiler-for-python-extensions/</link>
	<content:encoded>&lt;p&gt;Profiling Python extensions has not been a pleasant experience for me, so I made my own package to do the job. Existing alternatives were either hard to use, forcing you to recompile with custom flags like gprofile or desperately slow like valgrind/callgrind. The package I’ll talk about is called &lt;a href=&quot;http://pypi.python.org/pypi/yep&quot;&gt;YEP&lt;/a&gt; and is designed to be:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Unobtrusive: no recompiling, no custom linking. Just lauch &amp;amp; profile.&lt;/li&gt;
&lt;li&gt;Fast: waiting sucks.&lt;/li&gt;
&lt;li&gt;Easy to use.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Basic usage&lt;/h2&gt;
&lt;p&gt;YEP is distributed as a python module and can be &lt;a href=&quot;http://pypi.python.org/pypi/yep&quot;&gt;downloaded from the pypi&lt;/a&gt;. After installation, it is executed by giving the &lt;b&gt;-m yep&lt;/b&gt; flags to the interpreter. Without any arguments, it will just print a help message:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container text default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;text codecolorer&quot;&gt;    $ python -m yep&lt;br /&gt;
Usage: python -m yep [options] scriptfile [arg] ...&lt;br /&gt;
 ...&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Say you want to profile a script called my_script.py, then the way to quickly get a profiler report is to execute:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container text default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;text codecolorer&quot;&gt;    $ python -m yep -v my_script.py&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For example, running YEP on &lt;a href=&quot;http://scikit-learn.sourceforge.net/auto_examples/grid_search_digits.html&quot;&gt;this example&lt;/a&gt; that makes use of &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;libsvm&lt;/a&gt;, a C++ library for Support Vector Machines, outputs&lt;/p&gt;
&lt;table style=&quot;width: auto;&quot;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://picasaweb.google.com/lh/photo/ltfRg59k-z9Zrk7LBDTUxA?feat=embedwebsite&quot;&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/_IOBIGAGXP4o/TZruzeuFJjI/AAAAAAAAAGI/JSmxqbOd0o4/s400/Screenshot-fabian%40localhost%3A%20-home-fabian.png&quot; height=&quot;238&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;font-family: arial,sans-serif; font-size: 11px; text-align: right;&quot;&gt;From &lt;a href=&quot;https://picasaweb.google.com/fabian.pedregosa.izquierdo/Screenshots?feat=embedwebsite&quot;&gt;Screenshots&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;The last column prints the name of the functions, so just looking at those that start with svm:: gives you an overview of how our libsvm is spending its time.&lt;/p&gt;
&lt;h2&gt;Other usages&lt;/h2&gt;
&lt;p&gt;Calling YEP without the -v will create a my_script.py.prof file that can be analyzed with pprof (google-pprof on some systems). pprof has a huge range of options, letting you to filter on some funtions, output to ghostview or print a line-by-line profiling, to mention a few. For example, you can generate a call graph with the command:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container text default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;text codecolorer&quot;&gt; $ pprof --gv /usr/bin/python my_script.py.prof&lt;/div&gt;&lt;/div&gt;
&lt;h2&gt;More control&lt;/h2&gt;
&lt;p&gt;If you would like to manually start/stop the profiler rather than profile the whole script, you can use the functions yep.start() and yep.stop() inside a python script. This will write the profile to a given filename, so make sure the directory is writable:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;&lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; yep&lt;br /&gt;
yep.&lt;span style=&quot;color: black;&quot;&gt;start&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: #483d8b;&quot;&gt;'out.prof'&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt; &lt;span style=&quot;color: #808080; font-style: italic;&quot;&gt;# will create an out.prof file&lt;/span&gt;&lt;br /&gt;
&lt;span style=&quot;color: #808080; font-style: italic;&quot;&gt;# do something ...&lt;/span&gt;&lt;br /&gt;
yep.&lt;span style=&quot;color: black;&quot;&gt;stop&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2&gt;Future work&lt;/h2&gt;
&lt;p&gt;The -v option showed at the beginning is just a dirty hack that launches pprof and pipes the output into less. A more robust approach would be to read the resulting profile from python and manipulate it from there, either to std or to &lt;a href=&quot;http://docs.python.org/library/profile.html#pstats.Stats&quot;&gt;pstats&lt;/a&gt; format. This shouldn’t be too difficult as the pprof format is described &lt;a href=&quot;http://google-perftools.googlecode.com/svn/trunk/doc/cpuprofile-fileformat.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt; Acknowledgment&lt;/h2&gt;
&lt;p&gt;The original idea to use google-perftools to profile Python extensions was given on this &lt;a href=&quot;http://stackoverflow.com/questions/2615153/profiling-python-c-extensions&quot;&gt;Stack overflow question&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2011-04-06T12:02:44+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=547">
	<title>Fabian Pedregosa: scikit-learn coding sprint in Paris</title>
	<link>http://fseoane.net/blog/2011/scikit-learn-coding-sprint-in-paris/</link>
	<content:encoded>&lt;p&gt;Yesterday was the scikit-learn coding sprint in Paris. It was great to meet with old developers (Vincent Michel) and new ones: some of whom I was already familiar with from the mailing list while others came just to say hi and get familiar with the code. It was really great to have people from such different backgrounds discuss on concrete problems and getting things done.&lt;/p&gt;
&lt;p&gt;A lot of work was done, most of it unmerged yet, but if I had to highlight the three most important for me, that would be the the &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/pull/86&quot;&gt;merge of the hcluster2 branch&lt;/a&gt;, the awesome work of &lt;a href=&quot;https://github.com/thouis&quot;&gt;thouis&lt;/a&gt; in replacing the &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/pull/120&quot;&gt;C++ interface to the ball_tree with a Cython one&lt;/a&gt; and suppport for Python3 (not bug-free but imports OK).&lt;/p&gt;
&lt;p&gt;As for me, I’ve been working mostly in providing efficient cross-validatation for Support Vector Machines. The status of this is: low-level API seems to work fine (scikits.learn.svm.libsvm.cross_validation) but high-level API &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/pull/117&quot;&gt;still needs some work&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is the picture featuring (most) of the people that were at the sprint around 16h in &lt;a href=&quot;http://www.logilab.fr/&quot;&gt;Logilab’s&lt;/a&gt; headquarters.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/fseoane/5578952957/&quot; title=&quot;IMG_0012 por Fabian Pedregosa, en Flickr&quot;&gt;&lt;img src=&quot;http://farm6.static.flickr.com/5092/5578952957_27b653d0a4.jpg&quot; alt=&quot;IMG_0012&quot; height=&quot;375&quot; width=&quot;500&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2011-04-02T10:07:11+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=536">
	<title>Fabian Pedregosa: py3k in scikit-learn</title>
	<link>http://fseoane.net/blog/2011/py3k-in-scikit-learn/</link>
	<content:encoded>&lt;p&gt;One thing I’d really like to see done in &lt;a href=&quot;http://gael-varoquaux.info/blog/?p=149&quot;&gt;this Friday’s scikit-learn sprint&lt;/a&gt; is to have full support for Python 3.&lt;/p&gt;
&lt;p&gt;There’s &lt;a href=&quot;http://github.com/fabianp/scikit-learn/compare/master...py3k&quot;&gt;a branch were the hard word has been done&lt;/a&gt; (porting C extensions, automatic 2to3 conversion, etc.), although joblib still has some bugs and no one has attempted to do anything serious with this branch yet …&lt;/p&gt;</content:encoded>
	<dc:date>2011-03-28T13:23:46+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-2520472460430880330.post-5266141065935110948">
	<title>Official SymPy blog: SymPy is a Google Summer of Code 2011 Mentoring Organization</title>
	<link>http://sympy.blogspot.com/2011/03/sympy-is-google-summer-of-code-2011.html</link>
	<content:encoded>&lt;div&gt;I am proud to announce that SymPy has been accepted as a mentoring organization for Google Summer of Code 2011.  This is great news for the project.  Although we have participated in the past under the umbrella of the Python Software Foundation and Portland State University mentoring organizations, this is the first time that we have been accepted as a mentoring organization.  Out of 417 organizations that applied to Google, 175 were accepted, 50 of which were new.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In case you don't know, Google Summer of Code is a program run by Google every year where they pay college students all around the world to write code for open source projects. Each student has a mentor assigned to him/her, who helps the student get started with interacting with open source (most students who are accepted have never participated in open source before).  &lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;So now that were are accepted, students are open to applications.  The actual application period opens on March 28, and closes on April 8 (see &lt;a href=&quot;http://www.google-melange.com/document/show/gsoc_program/google/gsoc2011/timeline&quot;&gt;the program timeline&lt;/a&gt;).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;To students:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;If you are interested in applying, please write the to mailing list and introduce yourself.  The program is open to anyone worldwide who is 18 years of age or older who is enrolled in a higher education institution (this includes undergraduate and graduate).  If you are interested in applying, here is what you should do (if you have not already):&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;- As I said above, write to the list and introduce yourself.  You might also join our IRC channel, which is #sympy on freenode.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;- Start thinking about what you want to apply to do.  See our &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Ideas&quot;&gt;ideas page&lt;/a&gt;.  However, we are open to ideas that are not on that page. Anything that fits in a computer algebra system would fit in SymPy.  If you have an idea not on that page, please discuss it on our mailing list, so we can see if it has not already be implemented, and if it is fitting for SymPy and for a project.  I recommend you apply to do something that you are interested in personally.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;- We require for any student to be accepted that he/she submit at least one patch to SymPy, which gets reviewed and pushed in.  See &lt;a href=&quot;http://code.google.com/p/sympy/issues/list?can=2&amp;amp;q=label%3AEasyToFix&quot;&gt;issues labeled EasyToFix in our issue tracker&lt;/a&gt; for some easy to fix issues that are a good place to start.  Don't worry if you do not know how to send in a patch or use git.  We will help you (that is the whole point of the program).  Just ask on the mailing list, on the issue page, or on IRC.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;- You should start thinking about your application.  See our &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Template&quot;&gt;application template&lt;/a&gt; (it will also be at our page on the Google site).  If you like, you can start a page on our wiki to write your proposal.  If you do this, we will help you edit it (though understand that we will not help you write it).  Remember that we want you to get accepted just as much as you do, so you can help improve SymPy!&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;To SymPy developers:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;- We need people who are willing to mentor students.  If you are willing to mentor, please add your name to the bottom of the &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-ideas&quot;&gt;ideas page&lt;/a&gt;. &lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;- Please edit the ideas page to improve formatting and add new ideas.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Good luck to all students who plan on applying!&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/2520472460430880330-5266141065935110948?l=sympy.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2011-03-19T03:12:59+00:00</dc:date>
	<dc:creator>Aaron Meurer</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=834">
	<title>Aaron Meurer: SymPy is a Google Summer of Code 2011 Mentoring Organization</title>
	<link>http://asmeurersympy.wordpress.com/2011/03/18/sympy-is-a-google-summer-of-code-2011-mentoring-organization/</link>
	<content:encoded>&lt;p&gt;I am proud to announce that SymPy has been accepted as a mentoring organization for Google Summer of Code 2011.  This is great news for the project.  Although we have participated in the past under the umbrella of the Python Software Foundation and Portland State University mentoring organizations, this is the first time that we have been accepted as a mentoring organization.  Out of 417 organizations that applied to Google, 175 were accepted, 50 of which were new.&lt;/p&gt;
&lt;p&gt;In case you don’t know, Google Summer of Code is a program run by Google every year where they pay college students all around the world to write code for open source projects. Each student has a mentor assigned to him/her, who helps the student get started with interacting with open source (most students who are accepted have never participated in open source before).  &lt;/p&gt;
&lt;p&gt;So now that were are accepted, students are open to applications.  The actual application period opens on March 28, and closes on April 8 (see &lt;a href=&quot;http://www.google-melange.com/document/show/gsoc_program/google/gsoc2011/timeline&quot;&gt;the program timeline&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;To students:&lt;/p&gt;
&lt;p&gt;If you are interested in applying, please write the to mailing list and introduce yourself.  The program is open to anyone worldwide who is 18 years of age or older who is enrolled in a higher education institution (this includes undergraduate and graduate).  If you are interested in applying, here is what you should do (if you have not already):&lt;/p&gt;
&lt;p&gt;- As I said above, write to the list and introduce yourself.  You might also join our IRC channel, which is #sympy on freenode.&lt;/p&gt;
&lt;p&gt;- Start thinking about what you want to apply to do.  See our &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Ideas&quot;&gt;ideas page&lt;/a&gt;.  However, we are open to ideas that are not on that page. Anything that fits in a computer algebra system would fit in SymPy.  If you have an idea not on that page, please discuss it on our mailing list, so we can see if it has not already be implemented, and if it is fitting for SymPy and for a project.  I recommend you apply to do something that you are interested in personally.&lt;/p&gt;
&lt;p&gt;- We require for any student to be accepted that he/she submit at least one patch to SymPy, which gets reviewed and pushed in.  See &lt;a href=&quot;http://code.google.com/p/sympy/issues/list?can=2&amp;amp;q=label%3AEasyToFix&quot;&gt;issues labeled EasyToFix in our issue tracker&lt;/a&gt; for some easy to fix issues that are a good place to start.  Don’t worry if you do not know how to send in a patch or use git.  We will help you (that is the whole point of the program).  Just ask on the mailing list, on the issue page, or on IRC.&lt;/p&gt;
&lt;p&gt;- You should start thinking about your application.  See our &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-Application-Template&quot;&gt;application template&lt;/a&gt; (it will also be at our page on the Google site).  If you like, you can start a page on our wiki to write your proposal.  If you do this, we will help you edit it (though understand that we will not help you write it).  Remember that we want you to get accepted just as much as you do, so you can help improve SymPy!&lt;/p&gt;
&lt;p&gt;To SymPy developers:&lt;/p&gt;
&lt;p&gt;- We need people who are willing to mentor students.  If you are willing to mentor, please add your name to the bottom of the &lt;a href=&quot;https://github.com/sympy/sympy/wiki/GSoC-2011-ideas&quot;&gt;ideas page&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;- Please edit the ideas page to improve formatting and add new ideas.&lt;/p&gt;
&lt;p&gt;Good luck to all students who plan on applying!&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/834/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/834/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=834&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2011-03-18T22:50:04+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=828">
	<title>Aaron Meurer: True is True is False is True is False</title>
	<link>http://asmeurersympy.wordpress.com/2011/03/15/true-is-true-is-false-is-true-is-false/</link>
	<content:encoded>&lt;p&gt;Time for &lt;a href=&quot;http://asmeurersympy.wordpress.com/2009/07/20/modifying-a-list-while-looping-through-it-in-python/&quot;&gt;another&lt;/a&gt; &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here/&quot;&gt;one&lt;/a&gt; of my WTF Python blog posts.  Yesterday, I randomly typed this in a Python session (it was late at night):&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; True is True is False is True is False
False
&lt;/pre&gt;
&lt;p&gt;First a little background, in case you don’t know.  The &lt;code&gt;is&lt;/code&gt; operator in Python does exact object comparison in memory. Unlike &lt;code&gt;==&lt;/code&gt;, which only compares it two objects are equal, &lt;code&gt;is&lt;/code&gt; only returns True if both arguments have the same memory address.  So you can have something like:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a = 12345
&amp;gt;&amp;gt;&amp;gt; b = 12345
&amp;gt;&amp;gt;&amp;gt; a == b
True
&amp;gt;&amp;gt;&amp;gt; a is b
False
&lt;/pre&gt;
&lt;p&gt;Now, there are a handful of Python built-ins that are always equal one another with the &lt;code&gt;is&lt;/code&gt; operator.  &lt;code&gt;True&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt; are two such constants:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a = True
&amp;gt;&amp;gt;&amp;gt; b = True
&amp;gt;&amp;gt;&amp;gt; a == b
True
&amp;gt;&amp;gt;&amp;gt; a is b
True
&amp;gt;&amp;gt;&amp;gt; c = False
&amp;gt;&amp;gt;&amp;gt; d = False
&amp;gt;&amp;gt;&amp;gt; c == d
True
&amp;gt;&amp;gt;&amp;gt; c is d
True
&lt;/pre&gt;
&lt;p&gt;Now, going back to the above, we see that each &lt;code&gt;is&lt;/code&gt; returns &lt;code&gt;True&lt;/code&gt; or &lt;code&gt;False&lt;/code&gt;, which is then evaluated with the next one.  Or at least that is what you would think is happening.  But go back and look at it again, and see if you can figure out what it should evaluate to.  You could probably guess that something was amiss from the fact that I was blogging about it.  If you haven’t figured it out already, look at the following:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; True is True is False is True is False
False
&amp;gt;&amp;gt;&amp;gt; (((True is True) is False) is True) is False
True
&amp;gt;&amp;gt;&amp;gt; True is (True is (False is (True is False)))
True
&lt;/pre&gt;
&lt;p&gt;So it seems that &lt;code&gt;is&lt;/code&gt; does not associate to the left or to the right.  Let’s see if we can figure out what is going on.  First off, &lt;code&gt;True is True&lt;/code&gt;, etc. do behave as you expect them to:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; True is True
True
&amp;gt;&amp;gt;&amp;gt; False is False
True
&amp;gt;&amp;gt;&amp;gt; True is False
False
&amp;gt;&amp;gt;&amp;gt; False is True
False
&lt;/pre&gt;
&lt;p&gt;It is when we start using multiple &lt;code&gt;is&lt;/code&gt;s in the same statement that we start seeing problems:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; False is False is False
True
&amp;gt;&amp;gt;&amp;gt; (False is False) is False
False
&lt;/pre&gt;
&lt;p&gt;So what’s going on here?  &lt;code&gt;False is False&lt;/code&gt; is True, so maybe it is short-circuiting somehow.  &lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; True is False is False
False
&amp;gt;&amp;gt;&amp;gt; False is False is True
False
&lt;/pre&gt;
&lt;p&gt;No, that is not it.  Those reduce to &lt;code&gt;False is False&lt;/code&gt; and &lt;code&gt;True is True&lt;/code&gt; when associating to the left, respectively, and &lt;code&gt;True is True&lt;/code&gt; and &lt;code&gt;True is True&lt;/code&gt; when associating to the right.  &lt;/p&gt;
&lt;p&gt;Finally, at this point, it occurs to me what is really going on.  Have you figured it out too (or maybe you already knew all along)?  Maybe you can guess it from this statement, which uses &lt;code&gt;None&lt;/code&gt;, another built-in object that always compares equal to itself with the &lt;code&gt;is&lt;/code&gt; operator:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; None is None is None
True
&lt;/pre&gt;
&lt;p&gt;So you see what is happening?  &lt;code&gt;is&lt;/code&gt; doesn’t associate at all.  Rather, using multiple &lt;code&gt;is&lt;/code&gt;s in one statement does multiple comparisons at once.  Any &lt;code&gt;a is b is … x&lt;/code&gt; will return &lt;code&gt;True&lt;/code&gt; if &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, …, and &lt;code&gt;x&lt;/code&gt; are all equal by the &lt;code&gt;is&lt;/code&gt; operator (they share the same identity or memory address), and &lt;code&gt;False&lt;/code&gt; otherwise.  Actually, this isn’t surprising, since &lt;code&gt;==&lt;/code&gt; works the same way:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; False == False == False
True
&amp;gt;&amp;gt;&amp;gt; (False == False) == False
False
&lt;/pre&gt;
&lt;p&gt;This syntax can actually be useful to test equality of three or more items at once efficiently (Python will not evaluate the same &lt;code&gt;==&lt;/code&gt; or &lt;code&gt;is&lt;/code&gt; more than once).  But it can be confusing when comparing with &lt;code&gt;True&lt;/code&gt; or &lt;code&gt;False&lt;/code&gt;, since &lt;code&gt;a is b&lt;/code&gt; and &lt;code&gt;a == b&lt;/code&gt; themselves evaluate to one of those values.  So remember that it is NOT associative in any way.  Rather, it acts as an n-way comparison. &lt;/p&gt;
&lt;p&gt;Finally, as &lt;a href=&quot;http://docs.python.org/reference/expressions.html#summary&quot;&gt;this table&lt;/a&gt; of operator precedence in Python shows, &lt;code&gt;is&lt;/code&gt; and &lt;code&gt;==&lt;/code&gt; have the same precedence in Python.  Therefore, it should be possible to combine the two in these same statement.  Indeed, you can:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a = 12345
&amp;gt;&amp;gt;&amp;gt; b = 12345
&amp;gt;&amp;gt;&amp;gt; c = b
&amp;gt;&amp;gt;&amp;gt; a == b == c
True
&amp;gt;&amp;gt;&amp;gt; a is b is c
False
&amp;gt;&amp;gt;&amp;gt; # Because this is False
...
&amp;gt;&amp;gt;&amp;gt; a is b
False
&amp;gt;&amp;gt;&amp;gt; # But this is True
...
&amp;gt;&amp;gt;&amp;gt; b is c
True
&amp;gt;&amp;gt;&amp;gt; # So we get
...
&amp;gt;&amp;gt;&amp;gt; a == b is c
True
&lt;/pre&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/828/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/828/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=828&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2011-03-15T22:29:15+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-3253966970864417650">
	<title>Fredrik Johansson: A FLINT example: Lambert W function power series</title>
	<link>http://fredrik-j.blogspot.com/2011/03/flint-example-lambert-w-function-power.html</link>
	<content:encoded>Two days ago, a new version of the &lt;a href=&quot;http://flintlib.org/&quot;&gt;Fast Library for Number Theory (FLINT)&lt;/a&gt; was released. I contributed a lot of new code to this release, including linear algebra speed improvements and new functionality for fast power series arithmetic and computation of special numbers and polynomials (see the &lt;a href=&quot;https://groups.google.com/group/flint-devel/browse_thread/thread/759709de4720633f?hl=en&quot;&gt;release announcement&lt;/a&gt; and some of my &lt;a href=&quot;http://sage.math.washington.edu/home/fredrik/flint/timings.html&quot;&gt;benchmarking results&lt;/a&gt;).&lt;br /&gt;&lt;br /&gt;In this blog post I'll demonstrate how to do power series arithmetic with FLINT, using its &lt;tt&gt;fmpq_poly&lt;/tt&gt; module which implements polynomials over the rational numbers Q. Standard operations  (addition, multiplication and division) were available before; the functions I've added include square root, log, exp, sin, tan, atan, etc. (all the usual elementary functions). The same functions are also available for power series over a finite field Z/nZ (with word-size n). Everything is asymptotically fast (the running time is linear in the size of the output, up to logarithmic factors).&lt;br /&gt;&lt;br /&gt;Of course, transcendental functions are a bit restricted when considered over Q or Z/nZ, since it's only possible to obtain power series expansions at specific rational points (in most cases just x = 0). So at present, some very interesting numerical applications of fast power series arithmetic are not supported. But some time in the future, we'll probably add support for numerical power series over the reals and complexes as well.&lt;br /&gt;&lt;br /&gt;As today's example, let us implement the &lt;a href=&quot;http://en.wikipedia.org/wiki/Lambert_W_function&quot;&gt;Lambert W function&lt;/a&gt; for the power series ring Q[[x]]. The Lambert W function is defined implicitly by the equation x = W(x) exp(W(z)), which can be solved using Newton iteration with the update step w = w - (w exp(w) - x) / ((w+1) exp(w)).&lt;br /&gt;&lt;br /&gt;Power series Newton iteration is just like numerical Newton iteration, except that the convergence behavior is much simpler: starting with a correct first-order expansion, each iteration at least doubles the number of correct coefficients.&lt;br /&gt;&lt;br /&gt;A simple recursive implementation with asymptotically optimal performance (up to constant factors) looks as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;#include &amp;lt;stdio.h&amp;gt;&lt;br /&gt;#include &quot;flint.h&quot;&lt;br /&gt;#include &quot;fmpq_poly.h&quot;&lt;br /&gt;&lt;br /&gt;void lambertw(fmpq_poly_t w, fmpq_poly_t x, long n)&lt;br /&gt;{&lt;br /&gt;    if (n == 1)&lt;br /&gt;    {&lt;br /&gt;        fmpq_poly_zero(w);&lt;br /&gt;    }&lt;br /&gt;    else&lt;br /&gt;    {&lt;br /&gt;        fmpq_poly_t t, u, v;&lt;br /&gt;&lt;br /&gt;        lambertw(w, x, (n + 1) / 2);&lt;br /&gt;&lt;br /&gt;        fmpq_poly_init(t);&lt;br /&gt;        fmpq_poly_init(u);&lt;br /&gt;        fmpq_poly_init(v);&lt;br /&gt;&lt;br /&gt;        fmpq_poly_exp_series(t, w, n);&lt;br /&gt;        fmpq_poly_mullow(u, t, w, n);&lt;br /&gt;        fmpq_poly_sub(v, u, x);&lt;br /&gt;        fmpq_poly_add(t, u, t);&lt;br /&gt;        fmpq_poly_div_series(u, v, t, n);&lt;br /&gt;        fmpq_poly_sub(w, w, u);&lt;br /&gt;&lt;br /&gt;        fmpq_poly_clear(t);&lt;br /&gt;        fmpq_poly_clear(u);&lt;br /&gt;        fmpq_poly_clear(v);&lt;br /&gt;    }&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Beyond the base case W(x) = 0 + O(x), the function just computes w to accuracy ceil(n/2), and then extends it to accuracy n using a single Newton step. As we can see, C code directly using the FLINT library interface gets a bit verbose, but this style has the advantage of giving precise control over temporary memory allocation, polynomial lengths, etc. (it is very similar to the interface of GMP/MPIR).&lt;br /&gt;&lt;br /&gt;We add a simple test main routine:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;int main()&lt;br /&gt;{&lt;br /&gt;   fmpq_poly_t x;&lt;br /&gt;   fmpq_poly_t w;&lt;br /&gt;&lt;br /&gt;   fmpq_poly_init(x);&lt;br /&gt;   fmpq_poly_init(w);&lt;br /&gt;&lt;br /&gt;   fmpq_poly_set_coeff_ui(x, 1, 1);&lt;br /&gt;   lambertw(w, x, 10);&lt;br /&gt;&lt;br /&gt;   fmpq_poly_print_pretty(w, &quot;x&quot;);&lt;br /&gt;   printf(&quot;\n&quot;);&lt;br /&gt;&lt;br /&gt;   fmpq_poly_clear(x);&lt;br /&gt;   fmpq_poly_clear(w);&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;The output of the program is:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;531441/4480*x^9 - 16384/315*x^8 + 16807/720*x^7 - 54/5*x^6 + 125/24*x^5 - 8/3*x^4 + 3/2*x^3 - 1*x^2 + 1*x&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;It is well known that the coefficients in this series are given in closed form by (-k)&lt;sup&gt;k-1&lt;/sup&gt; / k!, so we can check that the output is correct.&lt;br /&gt;&lt;br /&gt;Computing 1000 terms takes just a few seconds. If this sounds like much, remember that the coefficients grow rapidly: together, the computed numerators and denominators have over 2 million digits!&lt;br /&gt;&lt;br /&gt;So far this is perhaps not so interesting, as we could compute the coefficients faster using a direct formula. But the nice thing is that arbitrary compositions are allowed, i.e we can compute W(f(x)) for any given power series f, and this will still be just as fast.&lt;br /&gt;&lt;br /&gt;Let's consider a nontrivial example: the infinite &quot;power tower&quot; T(z) = z&lt;sup&gt;z&lt;sup&gt;z&lt;sup&gt;z&lt;sup&gt;.&lt;sup&gt;.&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;. A moment's reflection shows that this is an analytic function with a rational power series expansion around z = 1. In fact, we have explicitly T(z) = W(-log(z))/(-log(z)). We can compute this series expansion (in the shifted variable x = z - 1) as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;int main()&lt;br /&gt;{&lt;br /&gt;    fmpq_poly_t x;&lt;br /&gt;    fmpq_poly_t w;&lt;br /&gt;&lt;br /&gt;    long n = 10;&lt;br /&gt;&lt;br /&gt;    fmpq_poly_init(x);&lt;br /&gt;    fmpq_poly_init(w);&lt;br /&gt;&lt;br /&gt;    fmpq_poly_set_coeff_ui(x, 0, 1);&lt;br /&gt;    fmpq_poly_set_coeff_ui(x, 1, 1);&lt;br /&gt;    fmpq_poly_log_series(x, x, n + 1);&lt;br /&gt;    fmpq_poly_neg(x, x);&lt;br /&gt;    lambertw(w, x, n + 1);&lt;br /&gt;    fmpq_poly_shift_right(w, w, 1);&lt;br /&gt;    fmpq_poly_shift_right(x, x, 1);&lt;br /&gt;    fmpq_poly_div_series(w, w, x, n);&lt;br /&gt;&lt;br /&gt;    fmpq_poly_print_pretty(w, &quot;x&quot;);&lt;br /&gt;    printf(&quot;\n&quot;);&lt;br /&gt;&lt;br /&gt;    fmpq_poly_clear(x);&lt;br /&gt;    fmpq_poly_clear(w);&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;The only complication is that &lt;tt&gt;fmpq_poly_div_series&lt;/tt&gt; requires a nonzero leading coefficient in the denominator, so we must shift both series down one power.&lt;br /&gt;&lt;br /&gt;The program outputs:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;118001/2520*x^9 + 123101/5040*x^8 + 4681/360*x^7 + 283/40*x^6 + 4*x^5 + 7/3*x^4 + 3/2*x^3 + 1*x^2 + 1*x + 1&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;To make things nicer, we assume that the coefficients have the form a&lt;sub&gt;k&lt;/sub&gt; / k! (i.e. that T(z) is the exponential generating function for a&lt;sub&gt;k&lt;/sub&gt;) and change the output code to something like the following:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;    long k;&lt;br /&gt;    mpq_t t;&lt;br /&gt;    mpz_t u;&lt;br /&gt;    mpq_init(t);&lt;br /&gt;    mpz_init(u);&lt;br /&gt;&lt;br /&gt;    for (k = 0; k &amp;lt; n; k++)&lt;br /&gt;    {&lt;br /&gt;        fmpq_poly_get_coeff_mpq(t, w, k);&lt;br /&gt;        mpz_fac_ui(u, k);&lt;br /&gt;        mpz_mul(mpq_numref(t), mpq_numref(t), u);&lt;br /&gt;        mpq_canonicalize(t);&lt;br /&gt;        gmp_printf(&quot;%Qd &quot;, t);&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    mpq_clear(t);&lt;br /&gt;    mpz_clear(u);&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;This indeed gives us an integer sequence:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;1 1 2 9 56 480 5094 65534 984808 16992144&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Now what is the value of the 1000th coefficient (to be precise, a&lt;sub&gt;1000&lt;/sub&gt;, the initial one being the 0th!) in this sequence? After a simple modification of the program, 2.9 seconds of computation gives:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;11608872341636087705816513947297167830568265588875720061704&lt;br /&gt;01832880235304267566817912141661469362953389062004053809005&lt;br /&gt;65797054717998071778437757582562676432270594729770831984037&lt;br /&gt;17901116787718293231769568392734610884078152929278291961741&lt;br /&gt;58010228897635319982035567487202368704727403137478203768363&lt;br /&gt;54056589570878404139562784693762331122998711070595645913436&lt;br /&gt;44753733499423283972136827590268687580725109528808039530647&lt;br /&gt;10910254098110789162443473433433758060122558659258182027755&lt;br /&gt;69656436509351036076228649393400187670469063215003559774586&lt;br /&gt;49501015173633083100668758800804388616363320813332492596835&lt;br /&gt;40185987183963214465225072970422690115905543500507650640978&lt;br /&gt;08856685726892919091844572545581642428942983342505179168857&lt;br /&gt;61923031601434642410137173087273453449219217659949560840949&lt;br /&gt;29145910407919393564145312029717057693032572341514569188719&lt;br /&gt;42207889248610196901459400077483577940763454422516589494589&lt;br /&gt;38697976290832628091067571489853751119661925805775760182956&lt;br /&gt;07151657547554699411688610841404991952520564137242651305186&lt;br /&gt;19966880917401902668151574186675809680229260294868082194497&lt;br /&gt;63338464294487320831362657576767926588975644587806316363928&lt;br /&gt;21662453081804476234328933125206970873131871382852201414093&lt;br /&gt;31942812710129867491990841736391939490562342870154316209797&lt;br /&gt;95555638177793757660689621198594912024704112203014400855204&lt;br /&gt;04879191040818216462884689447945725483793082854991264186114&lt;br /&gt;00713712447555062853630274495412279277142852027491666742488&lt;br /&gt;18689076794537156576609645279481454870296442864829766014978&lt;br /&gt;76385015229773871193575960430599394232421616401025152808967&lt;br /&gt;97542967829629757402705726445239053261557399630212654678115&lt;br /&gt;91948563122399554735529747742515102962530483866618795187470&lt;br /&gt;92568029262248891738821070847168914030430887617489382116571&lt;br /&gt;31479578425767585519331805968937010542495567221591600504522&lt;br /&gt;70151935685333213987251220404383044513120115761331175072544&lt;br /&gt;91881860724844683157343078083901966247367831930705346651165&lt;br /&gt;57731933519958498663270193078704185994119446629783305199163&lt;br /&gt;25824443621182783667024174595493553934149891052564101562124&lt;br /&gt;66082538519787858297949190033471879555319648142879656530503&lt;br /&gt;22140399695072998272983889906823049155302053273484019653833&lt;br /&gt;08158019685729676988160041114485564188896445502120959889736&lt;br /&gt;26684734069125268167350474483728161637188322446040542612820&lt;br /&gt;83620649731423678182582137133666912162187578149277916758677&lt;br /&gt;65932622140692260754343559763758688544180440952477345437585&lt;br /&gt;88260535486569816885029406514351482276962081562798684604230&lt;br /&gt;27051552771077659399889469617306015354335528530235916712574&lt;br /&gt;33756257973655927835185354982512983428012895270181767297060&lt;br /&gt;61394636504681554763302758450669487653360858511886083023090&lt;br /&gt;56603401440047692698200295529572915618836122163118770906896&lt;br /&gt;63441094011689868848158568518095899683719854486361541380832&lt;br /&gt;18026233272569661209672552513531416295218659379214599386577&lt;br /&gt;71439492527626159018195922050167504883881038997644963556212&lt;br /&gt;95634222871269535245013411241216112695705600000000000000000&lt;br /&gt;0000000000000000000000000 &lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;In fact, if we look up the first 10 coefficients in the On-Line Encyclopedia of Integer Sequences, we find &lt;a href=&quot;http://oeis.org/A033917&quot;&gt;http://oeis.org/A033917&lt;/a&gt;. This OEIS entry lists the representation&lt;br /&gt;&lt;br /&gt;a(n) = Sum_{k=0..n} Stirling1(n, k)*(k+1)^(k-1)&lt;br /&gt;&lt;br /&gt;Since FLINT supports fast vector computation of Stirling numbers, this formula can be implemented efficiently:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;#include &quot;fmpz.h&quot;&lt;br /&gt;#include &quot;fmpz_vec.h&quot;&lt;br /&gt;#include &quot;arith.h&quot;&lt;br /&gt;&lt;br /&gt;void coefficient(fmpz_t a, long n)&lt;br /&gt;{&lt;br /&gt;    long k;&lt;br /&gt;    fmpz * s;&lt;br /&gt;    fmpz_t t;&lt;br /&gt;&lt;br /&gt;    s = _fmpz_vec_init(n + 1);&lt;br /&gt;    fmpz_stirling1_vec(s, n, n + 1);&lt;br /&gt;&lt;br /&gt;    fmpz_init(t);&lt;br /&gt;    fmpz_zero(a);&lt;br /&gt;    for (k = 1; k &amp;lt;= n; k++)&lt;br /&gt;    {&lt;br /&gt;        fmpz_set_ui(t, k + 1);&lt;br /&gt;        fmpz_pow_ui(t, t, k - 1);&lt;br /&gt;        fmpz_addmul(a, s + k, t);&lt;br /&gt;    }&lt;br /&gt;&lt;br /&gt;    _fmpz_vec_clear(s, n + 1);&lt;br /&gt;    fmpz_clear(t);&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;int main()&lt;br /&gt;{&lt;br /&gt;    fmpz_t a;&lt;br /&gt;    fmpz_init(a);&lt;br /&gt;    coefficient(a, 1000);&lt;br /&gt;    fmpz_print(a);&lt;br /&gt;    printf(&quot;\n&quot;);&lt;br /&gt;    fmpz_clear(a);&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;And indeed, the output turns out to be the same!&lt;br /&gt;&lt;br /&gt;This program is faster, taking only 0.1 seconds to run. But of course, it only gives us a single coefficient, and would be slower for computing a range of values by making repeated calls.&lt;br /&gt;&lt;br /&gt;Similar ideas to those presented here (basically, reducing a problem to fast polynomial multiplication using generating functions, Newton iteration, etc.) are used internally by FLINT for computation of the standard elementary functions themselves as well as various special numbers and polynomials (Bernoulli numbers and polynomials, partitions, Stirling numbers, Bell numbers, etc). The internal code uses a lot of tricks to reduce overhead and handle special cases faster, however. (See the previous blog post &lt;a href=&quot;http://fredrik-j.blogspot.com/2010/09/fast-combinatorial-and-number-theoretic.html&quot;&gt;Fast combinatorial and number-theoretic functions with FLINT 2&lt;/a&gt;, and for more recent information the release announcement and benchmarks page linked at the top of this post.)&lt;br /&gt;&lt;br /&gt;In other news, I haven't written a lot of code for mpmath or Sage recently. Of course, my hope is that FLINT (2) will make it into Sage in the not too distant future. The fast polynomial and power series arithmetic support in FLINT will also be very useful for future special functions applications (in mpmath and elsewhere).&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-3253966970864417650?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2011-03-11T15:37:53+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=440">
	<title>Fabian Pedregosa: Computing the vector norm</title>
	<link>http://fseoane.net/blog/2011/computing-the-vector-norm/</link>
	<content:encoded>&lt;p&gt;Last week I discussed with &lt;a href=&quot;http://gael-varoquaux.info/blog/&quot;&gt;Gael&lt;/a&gt; how we should compute the euclidean norm of a vector a using SciPy. Two approaches suggest themselves, either calling scipy.linalg.norm(a) or computing sqrt(a.T a), but as I learned later, both suck.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; I use single-precision arithmetic for simplicity, but similar results hold for double-precision.&lt;/p&gt;
&lt;h3&gt;Overflow and underflow&lt;/h3&gt;
&lt;p&gt;Both approaches behave terribly in presence of big or small numbers. Take for example an array with a single entry:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: a = np.&lt;span style=&quot;color: #dc143c;&quot;&gt;array&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;1e20&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, dtype=np.&lt;span style=&quot;color: black;&quot;&gt;float32&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: a&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #dc143c;&quot;&gt;array&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;  1.00000002e+20&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, dtype=float32&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;2&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: scipy.&lt;span style=&quot;color: black;&quot;&gt;linalg&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;norm&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;2&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: inf&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;3&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: np.&lt;span style=&quot;color: black;&quot;&gt;sqrt&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;np.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a.&lt;span style=&quot;color: black;&quot;&gt;T&lt;/span&gt;, a&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;3&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: inf&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;That is, both methods return Infinity. However, the correct answer is 10^20, which would comfortably fit in a &lt;a href=&quot;http://en.wikipedia.org/wiki/Single_precision_floating-point_format&quot;&gt;single-precision&lt;/a&gt; instruction. Similar examples can be found where numbers underflow.&lt;/p&gt;
&lt;h3&gt;Stability&lt;/h3&gt;
&lt;p&gt;Again, scipy.linalg.norm has a terrible behavior in what concerns numerical stability. In presence of different magnitudes severe cancellation can occur. Take for example and array with one 10.000 in the first value and 10.000 ones behind:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;a = np.&lt;span style=&quot;color: #dc143c;&quot;&gt;array&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;1e4&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt; + &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;span style=&quot;color: #66cc66;&quot;&gt;*&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;10000&lt;/span&gt;, dtype=np.&lt;span style=&quot;color: black;&quot;&gt;float32&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In this case, scipy.linalg.norm will discard all the ones, producing&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;3&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: linalg.&lt;span style=&quot;color: black;&quot;&gt;norm&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt; - 1e4&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;3&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #ff4500;&quot;&gt;0.0&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;when the correct answer is 0.5. Here &lt;img src=&quot;http://s.wordpress.com/latex.php?latex=%5Csqrt%7Ba%5ET%20a%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\sqrt{a^T a}&quot; class=&quot;latex&quot; title=&quot;\sqrt{a^T a}&quot; /&gt; has a much nicer behavior since results of a dot-product in single precision are accumulated using double-precision (but if double-precision is used, results won’t be accumulated using quadruple-precision):&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;4&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: np.&lt;span style=&quot;color: black;&quot;&gt;sqrt&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;np.&lt;span style=&quot;color: black;&quot;&gt;dot&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a.&lt;span style=&quot;color: black;&quot;&gt;T&lt;/span&gt;, a&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt; - 1e4&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;4&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #ff4500;&quot;&gt;0.5&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3&gt;BLAS BLAS BLAS …&lt;/h3&gt;
&lt;p&gt;The BLAS function &lt;a href=&quot;http://www.netlib.org/blas/snrm2.f&quot;&gt;nrm2&lt;/a&gt; does automatic scaling of parameters rendering it more stable and tolerant to overflow. Luckily, scipy provides a mechanism to call some BLAS functions:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;5&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: nrm2, = scipy.&lt;span style=&quot;color: black;&quot;&gt;linalg&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;get_blas_funcs&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: #483d8b;&quot;&gt;'nrm2'&lt;/span&gt;,&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a,&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Using this function, no overflow occurs (hurray!)&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;95&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: a = np.&lt;span style=&quot;color: #dc143c;&quot;&gt;array&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;1e20&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, dtype=np.&lt;span style=&quot;color: black;&quot;&gt;float32&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;96&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: nrm2&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;96&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: 1.0000000200408773e+20&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and stability is greatly improved&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;99&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: nrm2&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;a&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt; - 1e4&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;99&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #ff4500;&quot;&gt;0.49998750062513864&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3&gt;Timing&lt;/h3&gt;
&lt;p&gt;Computing the 2-norm of an array is a very cheap operation, thus computations are usually dominated by external factors, such as latency of memory access or overhead in the Python/C layer. Experimental benchmarks on an array of size 10^7 show that nrm2 is marginally slower than &lt;img src=&quot;http://s.wordpress.com/latex.php?latex=%5Csqrt%7Ba%5ET%20a%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\sqrt{a^T a}&quot; class=&quot;latex&quot; title=&quot;\sqrt{a^T a}&quot; /&gt;, because scaling has a cost, but is is also more stable and less prone to overflow and underflow. It also shows that scipy.linalg.norm is the slowest (and numerically worst!) of all.&lt;/p&gt;
&lt;table border=&quot;1&quot;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src=&quot;http://s.wordpress.com/latex.php?latex=%5Csqrt%7Ba%5ET%20a%7D&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;\sqrt{a^T a}&quot; class=&quot;latex&quot; title=&quot;\sqrt{a^T a}&quot; /&gt;&lt;/td&gt;
&lt;td&gt;BLAS nrm2(a)&lt;/td&gt;
&lt;td&gt;scipy.linalg.norm(a)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.02&lt;/td&gt;
&lt;td&gt;0.02&lt;/td&gt;
&lt;td&gt;0.16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</content:encoded>
	<dc:date>2011-02-15T08:31:21+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=417">
	<title>Fabian Pedregosa: Smells like hacker spirit</title>
	<link>http://fseoane.net/blog/2011/smells-like-hacker-spirit/</link>
	<content:encoded>&lt;p&gt;I was last weekend in &lt;a href=&quot;http://fosdem.org/2011/&quot;&gt;FOSDEM&lt;/a&gt; presenting &lt;a href=&quot;http://scikit-learn.sf.net&quot;&gt;scikits.learn&lt;/a&gt; (&lt;a href=&quot;http://fseoane.net/talks/fosdem-skl/&quot;&gt;here are the slides&lt;/a&gt; I used at the Data Analytics Devroom). Kudos to &lt;a href=&quot;http://twitter.com/#!/ogrisel&quot;&gt;Olivier Grisel&lt;/a&gt; and all the people who organized such a fun and authentic meeting!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/alper/5417861859/&quot;&gt;&lt;img src=&quot;http://farm6.static.flickr.com/5136/5417861859_8480c65eed_m.jpg&quot; height=&quot;240&quot; width=&quot;179&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/fseoane/5425114531/&quot; title=&quot;scikits.learn at FOSDEM 2011 por Fabian Pedregosa, en Flickr&quot;&gt;&lt;img src=&quot;http://farm6.static.flickr.com/5294/5425114531_6eec316967_m.jpg&quot; alt=&quot;scikits.learn at FOSDEM 2011&quot; height=&quot;240&quot; width=&quot;194&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2011-02-11T07:50:19+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=820">
	<title>Aaron Meurer: I am now the SymPy project leader</title>
	<link>http://asmeurersympy.wordpress.com/2011/01/09/i-am-now-the-sympy-project-leader/</link>
	<content:encoded>&lt;p&gt;You can imagine my surprise when I opened my email last Monday and saw this message from Ondrej:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
Hi Aaron,&lt;/p&gt;
&lt;p&gt;would you like to become the main maintainer/project leader for sympy?&lt;br /&gt;
In the last year, it is clearly you, who does most of the work, and&lt;br /&gt;
also your blog has quite some visibility now.&lt;br /&gt;
It’d be cool to do some release from time to time. Mateusz is&lt;br /&gt;
finishing is poly’s branch, so probably his code would go into the&lt;br /&gt;
release.
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So I guess now I am the project leader for SymPy.  As to what exactly this means, I am not yet entirely sure, but so far it has meant that I get to do a lot more work than before (yay!).&lt;/p&gt;
&lt;p&gt;Actually, the work is because I have spent the last week working nonstop to get things ready to do a release.  I should have a release candidate for SymPy 0.7.0 ready some time next week.  I’ll post more here about what’s change, but this is going to be a big release.  The biggest change will be the new polys, which makes things much faster and more powerful.  &lt;/p&gt;
&lt;p&gt;Also, I will try to post things here relating to SymPy as a whole, not just my work.  &lt;/p&gt;
&lt;p&gt;Ondrej, by the way, isn’t going anywhere. He plans on doing some work on ways to get SymPy out to more people by writing more/better web and mobile interfaces for it.  A big thanks to Ondrej and the SymPy community for making such an awesome piece of software!&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/820/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/820/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=820&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2011-01-09T00:29:53+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=810">
	<title>Aaron Meurer: 2010 in review</title>
	<link>http://asmeurersympy.wordpress.com/2011/01/02/2010-in-review/</link>
	<content:encoded>&lt;p&gt;&lt;i&gt;Here’s some silly thing that WordPress sent me:&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;The stats helper monkeys at WordPress.com mulled over how this blog did in 2010, and here’s a high level summary of its overall blog health:&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;http://s0.wp.com/i/annual-recap/meter-healthy4.gif&quot; alt=&quot;Healthy blog!&quot; height=&quot;183&quot; style=&quot;border: 1px solid #ddd; background: #f5f5f5; padding: 20px;&quot; width=&quot;250&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;The &lt;em&gt;Blog-Health-o-Meter™&lt;/em&gt; reads This blog is on fire!.&lt;/p&gt;
&lt;h2&gt;Crunchy numbers&lt;/h2&gt;
&lt;p&gt;			&lt;a href=&quot;http://asmeurersympy.files.wordpress.com/2009/07/code-block-2.png&quot;&gt;&lt;img src=&quot;http://asmeurersympy.files.wordpress.com/2009/07/code-block-2.png?w=288&quot; alt=&quot;Featured image&quot; style=&quot;float: right; border: 1px solid #ddd; background: #fff; margin: 0 0 1em 1em; padding: 6px;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A Boeing 747-400 passenger jet can hold 416 passengers.  This blog was viewed about &lt;strong&gt;6,800&lt;/strong&gt; times in 2010.  That’s about 16 full 747s.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;In 2010, there were &lt;strong&gt;16&lt;/strong&gt; new posts, growing the total archive of this blog to 41 posts. There were &lt;strong&gt;7&lt;/strong&gt; pictures uploaded, taking up a total of 1mb. &lt;/p&gt;
&lt;p&gt;The busiest day of the year was July 4th with &lt;strong&gt;103&lt;/strong&gt; views. The most popular post that day was &lt;a style=&quot;color: #08c;&quot; href=&quot;http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/&quot;&gt;The Risch Algorithm: Part 1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h2&gt;Where did they come from?&lt;/h2&gt;
&lt;p&gt;The top referring sites in 2010 were &lt;strong&gt;&lt;a href=&quot;http://code.google.com&quot;&gt;code.google.com&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&quot;http://planet.sympy.org&quot;&gt;planet.sympy.org&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&quot;http://www.facebook.com&quot;&gt;facebook.com&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&quot;http://www.stackoverflow.com&quot;&gt;stackoverflow.com&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href=&quot;http://socghop.appspot.com&quot;&gt;socghop.appspot.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Some visitors came searching, mostly for &lt;strong&gt;&lt;a href=&quot;http://www.google.com/search?q=risch%20algorithm&quot;&gt;risch algorithm&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&quot;http://www.google.com/search?q=pudb&quot;&gt;pudb&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&quot;http://www.google.com/search?q=integrate%20exponential&quot;&gt;integrate exponential&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&quot;http://www.google.com/search?q=equations%20with%20homogeneous%20coefficients&quot;&gt;equations with homogeneous coefficients&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href=&quot;http://www.google.com/search?q=xcode%20trailing%20whitespace&quot;&gt;xcode trailing whitespace&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I have linked the search terms to their respective Google searches, so you can see how far up my blog posts are in the results list.&lt;/em&gt;&lt;/p&gt;
&lt;div style=&quot;clear: both;&quot;&gt;&lt;/div&gt;
&lt;h2&gt;Attractions in 2010&lt;/h2&gt;
&lt;p&gt;These are the posts and pages that got the most views in 2010.&lt;/p&gt;
&lt;div style=&quot;&quot;&gt;1&lt;/div&gt;
&lt;p&gt;					&lt;a style=&quot;margin-right: 10px;&quot; href=&quot;http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/&quot;&gt;The Risch Algorithm: Part 1&lt;/a&gt; &lt;span style=&quot;color: #999; font-size: 8pt;&quot;&gt;June 2010&lt;/span&gt;&lt;br /&gt;3 comments											&lt;/p&gt;
&lt;div style=&quot;&quot;&gt;2&lt;/div&gt;
&lt;p&gt;					&lt;a style=&quot;margin-right: 10px;&quot; href=&quot;http://asmeurersympy.wordpress.com/2009/11/13/how-to-get-both-32-bit/&quot;&gt;How to get both 32-bit and 64-bit Python in Snow Leopard&lt;/a&gt; &lt;span style=&quot;color: #999; font-size: 8pt;&quot;&gt;November 2009&lt;/span&gt;&lt;br /&gt;5 comments and 1 Like on WordPress.com,											&lt;/p&gt;
&lt;div style=&quot;&quot;&gt;3&lt;/div&gt;
&lt;p&gt;					&lt;a style=&quot;margin-right: 10px;&quot; href=&quot;http://asmeurersympy.wordpress.com/2009/07/20/modifying-a-list-while-looping-through-it-in-python/&quot;&gt;Modifying a list while looping through it in Python&lt;/a&gt; &lt;span style=&quot;color: #999; font-size: 8pt;&quot;&gt;July 2009&lt;/span&gt;&lt;br /&gt;13 comments											&lt;/p&gt;
&lt;div style=&quot;&quot;&gt;4&lt;/div&gt;
&lt;p&gt;					&lt;a style=&quot;margin-right: 10px;&quot; href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;Integration of exponential functions&lt;/a&gt; &lt;span style=&quot;color: #999; font-size: 8pt;&quot;&gt;July 2010&lt;/span&gt;&lt;br /&gt;3 comments											&lt;/p&gt;
&lt;div style=&quot;&quot;&gt;5&lt;/div&gt;
&lt;p&gt;					&lt;a style=&quot;margin-right: 10px;&quot; href=&quot;http://asmeurersympy.wordpress.com/2009/05/31/first-order-differential-equations-with-homogeneous-coefficients/&quot;&gt;First Order Differential Equations with Homogeneous Coefficients&lt;/a&gt; &lt;span style=&quot;color: #999; font-size: 8pt;&quot;&gt;May 2009&lt;/span&gt;&lt;br /&gt;2 comments											&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I wonder where things are coming from from Facebook.  I do not have an account there, so I can’t search it to find out.&lt;/em&gt;&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/810/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/810/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=810&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2011-01-02T23:07:04+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=307">
	<title>Fabian Pedregosa: New examples in scikits.learn 0.6</title>
	<link>http://fseoane.net/blog/2010/new-examples-in-scikits-learn-0-6/</link>
	<content:encoded>&lt;p&gt;Latest release of &lt;a href=&quot;http://scikit-learn.sf.net&quot;&gt;scikits.learn&lt;/a&gt; comes with an &lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/index.html&quot;&gt;awesome collection of examples&lt;/a&gt;. These are some of my favorites:&lt;/p&gt;
&lt;h3&gt;Faces recognition&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/plot_face_recognition.html&quot;&gt;This example&lt;/a&gt; by &lt;a href=&quot;http://twitter.com/ogrisel/&quot;&gt;Olivier Grisel&lt;/a&gt;, downloads a 58MB faces dataset from &lt;a href=&quot;http://vis-www.cs.umass.edu/lfw/&quot;&gt;Labeled Faces in the Wild&lt;/a&gt;, and is able to perform PCA for feature extraction and SVC for classification, yielding a very acceptable 0.85 f1-score.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/plot_face_recognition.html&quot;&gt;&lt;img src=&quot;http://scikit-learn.sourceforge.net/0.6/_images/plot_face_recognition.png&quot; width=&quot;500px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/plot_face_recognition.html&quot;&gt;
&lt;h3&gt;Species distribution modeling&lt;/h3&gt;
&lt;/a&gt;&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/plot_face_recognition.html&quot;&gt;&lt;/a&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/plot_species_distribution_modeling.html&quot;&gt;This example&lt;/a&gt; by &lt;a href=&quot;http://sites.google.com/site/peterprettenhofer/&quot;&gt;Peter Prettenhofer&lt;/a&gt;, models the geographical distribution of two south american mammals given past observations and 14 environmental variables. &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/plot_species_distribution_modeling.html&quot;&gt;&lt;img src=&quot;http://scikit-learn.sourceforge.net/0.6/_images/plot_species_distribution_modeling.png&quot; width=&quot;500px&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Libsvm GUI&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/0.6/auto_examples/applications/svm_gui.html&quot;&gt;This example&lt;/a&gt;, again by &lt;a href=&quot;http://sites.google.com/site/peterprettenhofer/&quot;&gt;Peter Prettenhofer&lt;/a&gt; and based on matplotlib and Tk, lets you draw data points in a canvas and it will interactively show the decision function of the SVM classifier. See &lt;a href=&quot;http://vimeo.com/18308519&quot;&gt;this video&lt;/a&gt; for a small showcase (music by &lt;a href=&quot;http://www.crepus.com/supercrepus.html&quot;&gt;Joe Crepúsculo&lt;/a&gt; can be downloaded &lt;a href=&quot;http://www.crepus.com/Supercrepus.rar&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt; &amp;lt;iframe frameborder=&quot;0&quot; height=&quot;300&quot; src=&quot;http://player.vimeo.com/video/18308519&quot; width=&quot;400&quot;&amp;gt;&amp;lt;/iframe&amp;gt;&lt;/p&gt;</content:encoded>
	<dc:date>2010-12-31T11:55:07+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=782">
	<title>Aaron Meurer: Major API Change for the Risch Algorithm Functions</title>
	<link>http://asmeurersympy.wordpress.com/2010/12/27/major-api-change-for-the-risch-algorithm-functions/</link>
	<content:encoded>&lt;p&gt;I have been able to get to work again on the Risch Algorithm now that I have a month winter break from classes.  So the first thing I did was commit a bunch of bug fixes that had been sitting there since the end of the summer.  Then, I set out to make a major internal API change to the entire Risch Algorithm.&lt;/p&gt;
&lt;p&gt;Let me give some background.  When I first started programming the Risch Algorithm at the beginning of the summer, I didn’t have a very good idea of how differential extensions worked yet (remember that I programmed the algorithm as I learned it from Bronstein’s book).  Let me use the function &lt;code&gt;derivation()&lt;/code&gt; to demonstrate how the API has changed.  &lt;code&gt;derivation()&lt;/code&gt; takes the Poly &lt;code&gt;p&lt;/code&gt; in &lt;code&gt;t&lt;/code&gt; and computes the derivative (&lt;code&gt;t&lt;/code&gt; is some transcendental extension, like &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x&quot; class=&quot;latex&quot; title=&quot;e^x&quot; /&gt;).  Also, the integration variable is &lt;code&gt;x&lt;/code&gt;.  The first internal API that I used was&lt;/p&gt;
&lt;p&gt;&lt;code&gt;derivation(p, D, x, t)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;D&lt;/code&gt; is a Poly of the derivative of &lt;code&gt;t&lt;/code&gt;, and &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt; are Symbols (see &lt;a href=&quot;https://github.com/asmeurer/sympy/commit/0f6a3d90f724118fadc5fdaf290a0cb3e3963efd&quot;&gt;this commit&lt;/a&gt;).   The problem here is that &lt;code&gt;p&lt;/code&gt; might not be in just one symbol, &lt;code&gt;t&lt;/code&gt;, but in many. This would happen whenever the function had more than one transcendental function, or extension, in it.  So, for example, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex%5Clog%7Bx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x\log{x}&quot; class=&quot;latex&quot; title=&quot;e^x\log{x}&quot; /&gt; would have this problem. Surprisingly, according to the git log, it took me until July 4 to figure this out (that above linked commit, which is the first occurrence of this function and when I started the full algorithm, dates from June 7, so it took me almost a month!), after which I had already written a good portion of the Risch Algorithm.  I changed the API to&lt;/p&gt;
&lt;p&gt;&lt;code&gt;derivation(p, D, x, T)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;T&lt;/code&gt; is a list of the extension variables and &lt;code&gt;D&lt;/code&gt; is a list of the derivations of the respective elements of &lt;code&gt;T&lt;/code&gt; with respect to the lower elements and x (see &lt;a href=&quot;https://github.com/asmeurer/sympy/commit/20b7a5f8ca8dec579065f85583f11cc0955b96f0&quot;&gt;this commit&lt;/a&gt;).  Now, the derivation of &lt;code&gt;x&lt;/code&gt; is always &lt;code&gt;Poly(1, x)&lt;/code&gt;, so I didn’t think it was necessary to include it.  But it turns out that it is easier to just always include this in &lt;code&gt;D&lt;/code&gt; rather than try to special case it in the code.  Also, the lowest extension variable, &lt;code&gt;x&lt;/code&gt;, isn’t used very often in the code, so it also doesn’t make much sense to keep it separate from the rest of the variables in &lt;code&gt;T&lt;/code&gt;.  Now this didn’t take me as long to figure out (July 11).  Therefore, I changed the API to just&lt;/p&gt;
&lt;p&gt;&lt;code&gt;derivation(p, D, T)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where the first element of &lt;code&gt;T&lt;/code&gt; is always &lt;code&gt;x&lt;/code&gt; and the first element of &lt;code&gt;D&lt;/code&gt; is always &lt;code&gt;Poly(1, x)&lt;/code&gt; (see &lt;a href=&quot;https://github.com/asmeurer/sympy/commit/bca2b19844ae71aa1ef8e27a9f77eabb70b4aa5f&quot;&gt;this commit&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Now this API worked quite well for the remainder of the summer.  However, at the very end, I discovered that a function required to handle some special cases in certain parts of the algorithm needed four more lists (the elements of the extension that are logarithms, the elements of the extension that are exponentials, the arguments of those logarithms, and the arguments of those exponentials).  I had previously thought that these lists would only be needed when creating the extension at the beginning of integration, but it turned out that this was not the case and that they could be needed in several rather deep places in the algorithm.  The only way to get them there would be to pass them through to every single function in the algorithm.    &lt;/p&gt;
&lt;p&gt;So I was faced with a dilemma.  I didn’t want to pass six arguments through each function just because a few might need them all.  I knew that the answer was to create an object to store all the data for a differential extension and to just pass this object around.  Unfortunately, this happened at the very end of the summer, so I hadn’t been able to do that until now.  &lt;/p&gt;
&lt;p&gt;This brings us to now.  Over the past couple of weeks, I created an object called &lt;code&gt;DifferentialExtension&lt;/code&gt;, and replaced the API in the Risch Algorithm to use it.  See &lt;a href=&quot;https://github.com/asmeurer/sympy/commit/d9d9548625513188aaa663621bfe4e097aebf741&quot;&gt;this commit&lt;/a&gt; and &lt;a href=&quot;https://github.com/asmeurer/sympy/commit/1935b6d6e1fdf8eae4deb5a4f56ea53c5d6989fa&quot;&gt;this commit&lt;/a&gt; and some of the ones in between to see what I did. More or less, the object is like a C struct—it does little more than hold a lot of information as attributes.  However, at the suggestion of Ronan Lamy on the &lt;a href=&quot;http://groups.google.com/group/sympy/browse_thread/thread/a051b5ba1fb5cb4d&quot;&gt;mailing list&lt;/a&gt;, I have moved all the relevant code for building the extension from the &lt;code&gt;build_extension()&lt;/code&gt; function into &lt;code&gt;DifferentialExtension.__init__()&lt;/code&gt;.  I have also created some “magic” to handle the recursive nature of the algorithm.  A DifferentialExtension object has an attribute &lt;code&gt;level&lt;/code&gt;, which represents the level of the extension that the algorithm is working in.  So you can store all the derivations of the extension in &lt;code&gt;DifferentialExtension.D&lt;/code&gt;, but only have &lt;code&gt;DifferentialExtension.d&lt;/code&gt; point to the “current” outermost derivation.  This replaces things like&lt;/p&gt;
&lt;p&gt;&lt;code&gt;D = D[:-1]&lt;br /&gt;
T = T[:-1]&lt;br /&gt;
&lt;/code&gt; &lt;/p&gt;
&lt;p&gt;from the old API to just&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DE.decrement_level()&lt;br /&gt;
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;(and then later on, &lt;code&gt;DE.increment_level()&lt;/code&gt;).  The entire API is now just&lt;/p&gt;
&lt;p&gt;&lt;code&gt;derivation(p, DE)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;DE&lt;/code&gt; is a &lt;code&gt;DifferentialExtension&lt;/code&gt; object.  Changing the API of the entire code base at this point was a bit of work, but I have finally finished it, and I must say, this is much cleaner.  True, you now have to use &lt;code&gt;DE.t&lt;/code&gt; everywhere instead of &lt;code&gt;t&lt;/code&gt; (with &lt;code&gt;t = T[-1]&lt;/code&gt; at the top of the function), which is three characters more space for every use, but I think in the end it is cleaner.  For example, the function that used to be&lt;/p&gt;
&lt;p&gt;&lt;code&gt;is_log_deriv_k_t_radical(fa, fd, L_K, E_K, L_args, E_args, D, T)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;is now just&lt;/p&gt;
&lt;p&gt;&lt;code&gt;is_log_deriv_k_t_radical(fa, fd, DE)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Also, because it is an object, I can do cool things like override &lt;code&gt;DifferentialExtension.__str__()&lt;/code&gt; to print out a tuple of the most important attributes of the object, making debugging much easier (now there is just one print statement instead of five).  &lt;/p&gt;
&lt;p&gt;Another thing I had to do was to allow the creation of these objects manually, because what is now &lt;code&gt;DifferentialExtension.__init__()&lt;/code&gt; cannot yet handle, for example, tangent extensions, but some of the tests involve those.  So I created an &lt;code&gt;extension&lt;/code&gt; flag to &lt;code&gt;__init__()&lt;/code&gt; to which you could pass a dictionary, and it would create a skeleton extension from that (see &lt;a href=&quot;https://github.com/asmeurer/sympy/commit/7121b06eab3f1e0f8464c287438fb7175f07762b&quot;&gt;this commit&lt;/a&gt;).  I made it smart enough to create some attributes automatically, so I only have to pass the list &lt;code&gt;D&lt;/code&gt; in most tests—it creates attributes like &lt;code&gt;T&lt;/code&gt; from that automatically.  Thus, this in some ways made the tests a little simpler, because I didn’t have to worry about &lt;code&gt;T&lt;/code&gt; any more.  &lt;/p&gt;
&lt;p&gt;We’ll see how things go, but this fourth API change should hopefully be the last.  This should also make it much easier whenever I add trigonometric function support, where I will have to add even more attributes to the object.  I won’t have to change the code in any existing function (unless it specifically needs to be able to know about trig extensions), because, to them, the information in &lt;code&gt;DE&lt;/code&gt; will not change.&lt;/p&gt;
&lt;p&gt;So the good news behind all of this, as I mentioned at the beginning of this post, is that I can now write some algorithm that requires those &lt;code&gt;L_K&lt;/code&gt;, &lt;code&gt;E_K&lt;/code&gt;, &lt;code&gt;L_args&lt;/code&gt;, &lt;code&gt;E_args&lt;/code&gt; variables from arbitrary places within the algorithm.  This should allow me to completely finish the exponential case.  So look forward soon to a &lt;code&gt;risch_integrate()&lt;/code&gt; that can handle completely any transcendental function of exponentials (either produce an integral or prove that no elementary integral exists).  &lt;/p&gt;
&lt;p&gt;And just to be clear, this doesn’t change anything with &lt;code&gt;risch_integrate()&lt;/code&gt;—this is only an internal change. And at the moment, it doesn’t add any features, though that should soon change. So keep on testing it for me!  If you see any errors along the lines of “Variable t not defined,” it probably means that I missed that one when I was switching the API due to poor test coverage in that area of the code.  I would love to know about any errors you find, or, indeed, any testing you do with &lt;code&gt;risch_integrate&lt;/code&gt;.  Remember that you can obtain my branch at &lt;a href=&quot;https://github.com/asmeurer/sympy/tree/integration3&quot;&gt;my GitHub account (branch integration3)&lt;/a&gt;.&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/782/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/782/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=782&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-12-27T07:34:30+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="http://dlpeterson.com/blog/?p=139">
	<title>Dale Peterson: High speed voltage level translators</title>
	<link>http://dlpeterson.com/blog/?p=139</link>
	<content:encoded>&lt;p&gt;My robotic bike has several 5.0V devices (encoders and motor controllers, and a 5.0V Arduino Mega), as well as several 3.3V logic level devices (Vector Nav VN-100 IMU, SST SPI Flash).  For high speed voltage level conversion, I found these products from Maxim-IC:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.maxim-ic.com/datasheet/index.mvp/id/3672&quot;&gt;http://www.maxim-ic.com/datasheet/index.mvp/id/3672&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;They will convert from 1.2V to 5.5V, or 5.5V to 1.2V and are specifically designed for high speed digital I/O (like SPI and I2C).  I ordered some samples and I’ll be testing them out as soon as they come in.&lt;/p&gt;
&lt;p&gt;I also found a place that sells a ton of breakout boards for all different types of SMT devices:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.proto-advantage.com/store/&quot;&gt;http://www.proto-advantage.com/store/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The prices range from $3-5, and they have detailed specs of every board, so you can be sure you get the board that fits your physical package.&lt;/p&gt;</content:encoded>
	<dc:date>2010-12-01T01:09:50+00:00</dc:date>
	<dc:creator>luke</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=237">
	<title>Fabian Pedregosa: Weighted samples for SVMs</title>
	<link>http://fseoane.net/blog/2010/weighted-samples-for-svms/</link>
	<content:encoded>&lt;p&gt;Based on the work of &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#weights_for_data_instances&quot;&gt;libsvm-dense&lt;/a&gt; by Ming-Wei Chang, Hsuan-Tien Lin, Ming-Hen Tsai, Chia-Hua Ho and Hsiang-Fu Yu I patched the libsvm distribution shipped with scikits.learn to allow setting weights for individual instances.&lt;/p&gt;
&lt;p&gt;The motivation behind this is to be able force a classifier to focus its attention in some samples instead of others. &lt;a href=&quot;http://scikit-learn.sourceforge.net/auto_examples/svm/plot_weighted_samples.html&quot;&gt;This example&lt;/a&gt; shows how different weights modify the decision function:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/auto_examples/svm/plot_weighted_samples.html&quot;&gt;&lt;img src=&quot;http://lh5.ggpht.com/_IOBIGAGXP4o/TPOK1z_KKNI/AAAAAAAAADQ/DNZCKc4Zt3w/s400/weights1.png&quot; height=&quot;300&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://picasaweb.google.com/lh/photo/wDNH13zH70UHfohww2iRyA?feat=directlink&quot;&gt;&lt;img src=&quot;http://lh4.ggpht.com/_IOBIGAGXP4o/TPOK2B9kUAI/AAAAAAAAADU/68dOJ6Bm3eY/s400/weights2.png&quot; height=&quot;300&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://picasaweb.google.com/lh/photo/ipW2ZqXmjGQMCQntTVpyUg?feat=directlink&quot;&gt;&lt;img src=&quot;http://lh5.ggpht.com/_IOBIGAGXP4o/TPOK2UXIRlI/AAAAAAAAADY/xKjk2HKHLdc/s400/weights3.png&quot; height=&quot;300&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2010-11-29T11:20:22+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=223">
	<title>Fabian Pedregosa: Coming soon …</title>
	<link>http://fseoane.net/blog/2010/coming-soon/</link>
	<content:encoded>&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/fseoane/5203822436/&quot; title=&quot;scikits.learn 0.6 por Fabian Pedregosa, en Flickr&quot;&gt;&lt;img src=&quot;http://farm5.static.flickr.com/4107/5203822436_41b9c350c2.jpg&quot; alt=&quot;scikits.learn 0.6&quot; height=&quot;306&quot; width=&quot;450&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Highlights for this release:&lt;/p&gt;
&lt;p&gt;   * New &lt;a href=&quot;http://scikit-learn.sourceforge.net/modules/sgd.html&quot;&gt;stochastic gradient descent module&lt;/a&gt; by &lt;a href=&quot;http://sites.google.com/site/peterprettenhofer/&quot;&gt;Peter Prettenhofer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;   * Improved svm module: memory efficiency, automatic class weights.&lt;/p&gt;
&lt;p&gt;   * Wrap for liblinear’s Multi-class SVC  (option multi_class in &lt;a href=&quot;http://scikit-learn.sourceforge.net/modules/generated/scikits.learn.svm.LinearSVC.html&quot;&gt;LinearSVC&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;   * New features and performance improvements of text feature extraction.&lt;/p&gt;
&lt;p&gt;   * Improved sparse matrix support, both in main classes (GridSearch) as in sparse modules: scikits.learn.svm.sparse and scikits.learn.glm.sparse.&lt;/p&gt;
&lt;p&gt;   * Lots of cool new examples: (&lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/blob/master/examples/svm/svm_gui.py&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/blob/master/examples/plot_species_distribution_modeling.py&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://github.com/scikit-learn/scikit-learn/blob/master/examples/plot_face_recognition.py&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;   * New Gaussian Process module by &lt;a href=&quot;https://github.com/dubourg&quot;&gt;Vincent Dubourg&lt;/a&gt; (still to be merged)&lt;/p&gt;
&lt;p&gt;   * Faster implementation of the &lt;a href=&quot;http://scikit-learn.sourceforge.net/modules/glm.html#lars-algorithm-and-its-variants&quot;&gt;LARS algorithm&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;   * Probability estimates for logistic regression.&lt;/p&gt;
&lt;p&gt;   * Lots of bug fixes and documentation improvements.&lt;/p&gt;
&lt;p&gt;   * Probably other things I am forgetting …&lt;/p&gt;</content:encoded>
	<dc:date>2010-11-24T08:39:52+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=209">
	<title>Fabian Pedregosa: memory efficient bindigs for libsvm</title>
	<link>http://fseoane.net/blog/2010/memory-efficient-bindigs-for-libsvm/</link>
	<content:encoded>&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sf.net&quot;&gt;scikits.learn.svm&lt;/a&gt; now uses &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#libsvm_for_dense_data&quot;&gt;LibSVM-dense&lt;/a&gt; instead of &lt;a href=&quot;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&quot;&gt;LibSVM&lt;/a&gt; for some support vector machine related algorithms when input is a dense matrix. &lt;/p&gt;
&lt;p&gt;As a result most of the copies associated with argument passing are avoided, giving 50% less memory footprint and several times less than the python bindings that ship with libsvm, which stores data in the very inefficient python list structure. On the performance side I didn’t see any significant difference, although on large datasets less memory footprint can make the difference between swapping or not.&lt;/p&gt;</content:encoded>
	<dc:date>2010-11-19T13:08:05+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-6568744196982634289.post-6825008418537862044">
	<title>Ond&amp;#345;ej &amp;#268;ert&amp;iacute;k: Google Code vs GitHub for hosting opensource projects</title>
	<link>http://ondrejcertik.blogspot.com/2010/11/google-code-vs-github-for-hosting.html</link>
	<content:encoded>&lt;a href=&quot;http://cython.org/&quot;&gt;Cython&lt;/a&gt; is now considering options where to move the main (mercurial) repository, and &lt;a href=&quot;http://www.math.washington.edu/~robertwb/&quot;&gt;Robert Bradshaw&lt;/a&gt; (one of the main Cython developers) has asked me about my experience with regards to &lt;a href=&quot;http://code.google.com/hosting/&quot;&gt;Google Code&lt;/a&gt; and &lt;a href=&quot;http://github.com/&quot;&gt;GitHub&lt;/a&gt;, since we use both with &lt;a href=&quot;http://sympy.org/&quot;&gt;SymPy&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Google Code is older, and it was the first service that provided free (virtually unlimited) number of projects that you could easily and immediately setup. At that time (4 years ago?) that was something unheard of. However, the GitHub guys in the meantime not only made this available too, but also implemented features, that (as far as I know) no one offers at all, in particular hosting your own pages at your own domain (but at GitHub's servers, some examples are &lt;a href=&quot;http://sympy.org&quot;&gt;sympy.org&lt;/a&gt; and &lt;a href=&quot;http://docs.sympy.org/&quot;&gt;docs.sympy.org&lt;/a&gt;), commenting on git branches and pull requests &lt;span style=&quot;font-style: italic;&quot;&gt;before&lt;/span&gt; the code gets merged in (I am 100% convinced that this is the right approach, as opposed to comment on the code &lt;span style=&quot;font-style: italic;&quot;&gt;after&lt;/span&gt; it gets in), allow to easily fork the repository and it has simply more social features, that the Google Code doesn't have.&lt;br /&gt;&lt;br /&gt;I believe that managing an opensource project is mainly a social activity, and GitHub's social features really make so many things easier. From this point of view, GitHub is clearly the best choice today.&lt;br /&gt;&lt;br /&gt;I think there is only one (but potentially big) problem with GitHub, that its issue tracker is very bad, compared to the Google Code one. For that reason (and also because we already use it), we keep our issues at Google Code with SymPy.&lt;br /&gt;&lt;br /&gt;The above are the main things to consider. Now there are some little things to keep in mind, that I will briefly touch below: Google Code doesn't support git and blocks access from Cuba and other countries, when you want to change the front page, you need to be an admin, while at GitHub I simply add push access to all sympy developers, so anyone just pushes a patch to this repository: &lt;a href=&quot;https://github.com/sympy/sympy.github.com&quot;&gt;https://github.com/sympy/sympy.github.com&lt;/a&gt;, and it automatically appears on our front page (&lt;a href=&quot;http://sympy.org/&quot;&gt;sympy.org&lt;/a&gt;), with Google Code we had to write long pages (in our docs) about how to send patches, with GitHub we just say, send us a pull request, and point to: &lt;a href=&quot;http://help.github.com/pull-requests/&quot;&gt;http://help.github.com/pull-requests/&lt;/a&gt;. In other words, GitHub takes care of teaching people how to use git and figure out how to send patches, and we can concentrate on reviewing the patches and pushing them in. &lt;br /&gt;&lt;br /&gt;Wikipages at github are maintained in git, and they provide the webfrontend to it as &lt;a href=&quot;https://github.com/github/gollum&quot;&gt;opensource&lt;/a&gt;, so there is no vendor lock-in. Anyone with github account can modify our wiki pages, while the Google Code pages can only be modified by people that I add to the Google Code project, which forced us to install mediawiki on my linode server (hosted at &lt;a href=&quot;http://linode.com/&quot;&gt;linode.com&lt;/a&gt;, which by the way is an excellent VPS hosting service, that I have been using for couple of years already and I can fully recommend it), and I had to manage it all the time, and now we are moving our pages to the github wiki, so that I have one less thing to worry about.&lt;br /&gt;&lt;br /&gt;So as you can see, I, as admin, have less things to worry about, as github manages everything for me now, while with Google Code, I had to manage lots of things on my linodes.&lt;br /&gt;&lt;br /&gt;One other thing to consider is that GitHub is only for git, but they also provide svn and hg access (both push and pull, they translate the repository automatically between git and svn/hg), I never really used it much, so I don't know how stable this is. As I wrote &lt;a href=&quot;http://ondrejcertik.blogspot.com/2010/10/git-has-won.html&quot;&gt;before&lt;/a&gt;, I think that git is the best tool now for maintaining a project, and I think that github is now the best choice to host it (except the issue tracker, where Google Code is better).&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/6568744196982634289-6825008418537862044?l=ondrejcertik.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-11-19T02:52:55+00:00</dc:date>
	<dc:creator>Ondřej Čertík</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-6568744196982634289.post-8933668259195859462">
	<title>Ond&amp;#345;ej &amp;#268;ert&amp;iacute;k: git has won</title>
	<link>http://ondrejcertik.blogspot.com/2010/10/git-has-won.html</link>
	<content:encoded>I switched to git from mercurial about two years ago. See here why I &lt;a href=&quot;http://ondrejcertik.blogspot.com/2008/08/i-am-switching-from-mercurial-to-git.html&quot;&gt;switched&lt;/a&gt; and here my experience &lt;a href=&quot;http://ondrejcertik.blogspot.com/2008/12/experience-with-git-after-4-months.html&quot;&gt;after 4 months&lt;/a&gt;. Back then I was unsure, whether git will win, but I thought it has a bigger momentum. Well, I think that now it's quite clear that git has already won. Pretty much everybody that I collaborate with is using git now.&lt;br /&gt;&lt;br /&gt;I use github everyday, and now thanks to github &lt;a href=&quot;http://help.github.com/pull-requests/&quot;&gt;pull requests&lt;/a&gt;, I think it's the best collaboration platform out there (compared to Google Code, Sourceforge, Bitbucket or Launchpad).&lt;br /&gt;&lt;br /&gt;I think it's partly because the github guys have a clear vision of what has to be done in order to make collaboration more easier and they do it, but more importantly that git branches is the way to go, as well as other git features, that are &quot;right&quot; from the beginning (branches, interactive rebase, and so on), while other VCS like bzr and mercurial simply either don't have them, or are getting them, but it's hard to get used to it (for example mercurial uses the &quot;mercurial queues&quot;, and I think that is the totally wrong approach to things).&lt;br /&gt;&lt;br /&gt;Anyway, this is just my own personal opinion. I'll be happy to discuss it in the comments, if you disagree.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/6568744196982634289-8933668259195859462?l=ondrejcertik.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-10-31T07:40:59+00:00</dc:date>
	<dc:creator>Ondřej Čertík</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/?p=192">
	<title>Fabian Pedregosa: solve_triangular in scipy.linalg</title>
	<link>http://fseoane.net/blog/2010/solve_triangular-in-scipy-linalg/</link>
	<content:encoded>&lt;p&gt;For some time now I’ve been missing a function in scipy that exploits the triangular structure of a matrix to efficiently solve the associated system, so I decided to &lt;a href=&quot;http://projects.scipy.org/scipy/changeset/6844&quot;&gt;implement it&lt;/a&gt; by binding the LAPACK method “trtrs”, which also checks for singularities and is capable handling several right-hand sides. &lt;/p&gt;
&lt;p&gt;Contrary to what I expected, binding Fortran code with f2py is pretty straightforward, even for someone like me who has never programmed in that language: I took a similar example, modified it’s parameters and it worked! Also, thanks to Pauli Virtanen the review process was really fast and the patch was committed within a few hours.&lt;/p&gt;
&lt;p&gt;The high level interface for LAPACK’s trtrs is linalg.solve_triangular, which accepts roughly the same arguments as linalg.solve, but assumes the first argument is a triangular matrix:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; scipy &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; linalg&lt;br /&gt;
&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;2&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: linalg.&lt;span style=&quot;color: black;&quot;&gt;solve_triangular&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;, &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;2&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #dc143c;&quot;&gt;array&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;-&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;.,  &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Simple &lt;a href=&quot;http://gist.github.com/654407&quot;&gt;benchmarks&lt;/a&gt; lets us clearly appreciate the complexity gap between both methods : solving an (n, n) triangular system is an O(n^2) operation, while solving a full one is at least a O(n^3):&lt;/p&gt;
&lt;table style=&quot;width: auto;&quot;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;http://picasaweb.google.com/lh/photo/8IaZpyMK_An_OLX38r3Xow?feat=embedwebsite&quot;&gt;&lt;img src=&quot;http://lh3.ggpht.com/_IOBIGAGXP4o/TMs3PvgFIwI/AAAAAAAAABA/ImOSqSZmljA/s400/works.png&quot; height=&quot;300&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;font-family: arial,sans-serif; font-size: 11px; text-align: right;&quot;&gt;From &lt;a href=&quot;http://picasaweb.google.com/fabian.pedregosa.izquierdo/Screenshots?feat=embedwebsite&quot;&gt;Screenshots&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</content:encoded>
	<dc:date>2010-10-29T23:13:22+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/2010/lars-algorithm/">
	<title>Fabian Pedregosa: LARS algorithm</title>
	<link>http://fseoane.net/blog/2010/lars-algorithm/</link>
	<content:encoded>&lt;p&gt;I’ve been working lately with &lt;a href=&quot;http://www-sop.inria.fr/members/Alexandre.Gramfort/&quot;&gt;Alexandre Gramfort&lt;/a&gt; coding the &lt;a href=&quot;http://scikit-learn.sf.net/modules/glm.html#lars-algorithm-and-its-variants&quot;&gt;LARS algorithm&lt;/a&gt; in &lt;a&gt;scikits.learn&lt;/a&gt;. This algorithm computes the solution to several general linear models used in machine learning: LAR, Lasso, Elasticnet and Forward Stagewise.&lt;/p&gt;
&lt;p&gt;Unlike the implementation by coordinate descent, the LARS algorithm gives the full coefficient path along the regularization parameter, and thus it is specially well suited for performing model selection. &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://scikit-learn.sourceforge.net/auto_examples/glm/plot_lasso_lars.html&quot;&gt;&lt;img src=&quot;http://scikit-learn.sourceforge.net/_images/plot_lasso_lars.png&quot; alt=&quot;LassoLARS&quot; style=&quot;height: 400px;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The algorithm is coded mostly in python, with some tiny parts in C (because I already had the code for cholesky deletes in C) and a cython interface for the blas function dtrsv, which will be proposed to scipy once I stabilize this code. The algorithm is mostly complete, allowing some optimizations, like using a precomputed Gram matrix or specify maximum number of features/iterations, but could still be extended to compute other models, like ElasticNet or Forward Stagewise.&lt;/p&gt;
&lt;p&gt;I haven’t done any benchmarks yet, but preliminary ones by Alexandre Gramfort showed that it is roughly equivalent to this &lt;a href=&quot;http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=3897&quot;&gt;Matlab implementation&lt;/a&gt;. Using &lt;a href=&quot;http://pymvpa.org&quot;&gt;PyMVPA&lt;/a&gt;, it shouldn’t be difficult to benchmark it against th R implementation, though.&lt;/p&gt;</content:encoded>
	<dc:date>2010-09-30T14:01:33+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-4696399575844014395">
	<title>Fredrik Johansson: Announcing mpmath 0.16</title>
	<link>http://fredrik-j.blogspot.com/2010/09/announcing-mpmath-016.html</link>
	<content:encoded>I'm happy to announce the release of &lt;a href=&quot;http://code.google.com/p/mpmath/&quot;&gt;mpmath 0.16&lt;/a&gt;, which contains the usual bugfixes as well as a slew of new features!&lt;br /&gt;&lt;br /&gt;The main focus has been to improve coverage of special functions. Additions include inhomogeneous Bessel functions, Bessel function zeros, incomplete elliptic integrals, and parabolic cylinder functions. As of 0.16, mpmath implements essentially everything listed in the &lt;a href=&quot;http://dlmf.nist.gov/&quot;&gt;NIST Digital Library of Mathematical Functions&lt;/a&gt; chapters 1-20, as well as 21,24,27 and 33. (For 25 and 26 -- combinatorial and number-theoretic functions, see also my post about &lt;a href=&quot;http://fredrik-j.blogspot.com/2010/09/fast-combinatorial-and-number-theoretic.html&quot;&gt;FLINT 2&lt;/a&gt;.)&lt;br /&gt;&lt;br /&gt;Another major change is that mpmath 0.16 running in &lt;a href=&quot;http://www.sagemath.org/&quot;&gt;Sage&lt;/a&gt; will be much faster thanks to new extension code (currently awaiting review for inclusion in Sage). I've clocked speedups between 1.3x and 2x for various nontrivial pieces of code (such as the mpmath test suite and the torture test programs).&lt;br /&gt;&lt;br /&gt;Thanks to William Stein, my work on mpmath during the summer was funded using resources from &lt;a href=&quot;http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=0757627&amp;amp;version=noscript&quot;&gt;NSF grant DMS-0757627&lt;/a&gt;. This support is gratefully acknowledged.&lt;br /&gt;&lt;br /&gt;Most of the new features are described in previous posts on this blog. For convenience, here is a short summary:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://fredrik-j.blogspot.com/2010/06/assorted-special-functions-update.html&quot;&gt;Assorted special functions update&lt;/a&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;The documentation now includes plots to illustrate several of the special functions.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Airy functions have been rewritten for improved speed and accuracy and to support evaluation of derivatives.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Functions &lt;tt&gt;airyaizero()&lt;/tt&gt;, &lt;tt&gt;airybizero()&lt;/tt&gt; for computation of Airy function zeros have been implemented.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Inhomogeneous Airy (Scorer) functions &lt;tt&gt;scorergi()&lt;/tt&gt; and &lt;tt&gt;scorerhi()&lt;/tt&gt; have been implemented.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Four inhomogeneous Bessel functions have been added (&lt;tt&gt;lommels1()&lt;/tt&gt;, &lt;tt&gt;lommels2()&lt;/tt&gt;, &lt;tt&gt;angerj()&lt;/tt&gt;, &lt;tt&gt;webere()&lt;/tt&gt;).&lt;/li&gt;&lt;br /&gt;&lt;li&gt;The Lambert W function has been rewritten to fix various bugs and numerical issues&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;a href=&quot;http://fredrik-j.blogspot.com/2010/06/incomplete-elliptic-integrals-complete.html&quot;&gt;Incomplete elliptic integrals complete&lt;/a&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;The Legendre and Carlson incomplete elliptic integrals for real and complex arguments have been implemented (&lt;tt&gt;ellipf()&lt;/tt&gt;, &lt;tt&gt;ellipe()&lt;/tt&gt;, &lt;tt&gt;ellippi()&lt;/tt&gt;, &lt;tt&gt;elliprf()&lt;/tt&gt;, &lt;tt&gt;elliprc()&lt;/tt&gt;, &lt;tt&gt;elliprj()&lt;/tt&gt;, &lt;tt&gt;elliprd()&lt;/tt&gt;, &lt;tt&gt;elliprg()&lt;/tt&gt;).&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;a href=&quot;http://fredrik-j.blogspot.com/2010/07/sage-days-23-and-bessel-function-zeros.html&quot;&gt;Sage Days 23, and Bessel function zeros&lt;/a&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;Functions &lt;tt&gt;besseljzero()&lt;/tt&gt; and &lt;tt&gt;besselyzero()&lt;/tt&gt; have been implemented for computing the &lt;i&gt;m&lt;/i&gt;-th zero of &lt;i&gt;J&lt;sub&gt;ν&lt;/sub&gt;&lt;/i&gt;(&lt;i&gt;z&lt;/i&gt;), &lt;i&gt;J'&lt;sub&gt;ν&lt;/sub&gt;&lt;/i&gt;(&lt;i&gt;z&lt;/i&gt;) &lt;i&gt;Y&lt;sub&gt;ν&lt;/sub&gt;&lt;/i&gt;(&lt;i&gt;z&lt;/i&gt;), or &lt;i&gt;Y'&lt;sub&gt;ν&lt;/sub&gt;&lt;/i&gt;(&lt;i&gt;z&lt;/i&gt;) for any positive integer index &lt;i&gt;m&lt;/i&gt; and real order ν ≥ 0.&lt;br /&gt;&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;a href=&quot;http://fredrik-j.blogspot.com/2010/07/post-sage-days-24-report.html&quot;&gt;Post Sage Days 24 report&lt;/a&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;The Parabolic cylinder functions &lt;tt&gt;pcfd()&lt;/tt&gt;, &lt;tt&gt;pcfu()&lt;/tt&gt;, &lt;tt&gt;pcfv()&lt;/tt&gt;, &lt;tt&gt;pcfw()&lt;/tt&gt; have been implemented.&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;a href=&quot;http://fredrik-j.blogspot.com/2010/07/euler-maclaurin-summation-of.html&quot;&gt;Euler-Maclaurin summation of hypergeometric series&lt;/a&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;Hypergeometric functions &lt;sub&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;&lt;i&gt;p&lt;/i&gt;-1&lt;/sub&gt;(...; ...; &lt;i&gt;z&lt;/i&gt;) now support accurate evaluation close to the singularity at &lt;i&gt;z&lt;/i&gt; = 1.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;A function &lt;tt&gt;sumap()&lt;/tt&gt; has been added for summation of infinite series using the Abel-Plana formula.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Functions &lt;tt&gt;diffs_prod()&lt;/tt&gt; and &lt;tt&gt;diffs_prod()&lt;/tt&gt; have been added for generating high-order derivatives of products or exponentials of functions with known derivatives.&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;a href=&quot;http://fredrik-j.blogspot.com/2010/09/again-mpmath-in-sage-is-about-to-get.html&quot;&gt;Again, mpmath in Sage is about to get faster&lt;/a&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;New Cython extension code has been written for Sage to speed up various operations in mpmath, including elementary functions and hypergeometric series.&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;There are various other changes as well, such as support for matrix slice indexing (contributed by Ioannis Tziakos -- thanks!). As usual, details are available in the &lt;a href=&quot;http://mpmath.googlecode.com/svn/trunk/CHANGES&quot;&gt;changelog&lt;/a&gt; and the &lt;a href=&quot;http://code.google.com/p/mpmath/source/list&quot;&gt;Changes&lt;/a&gt; page on the Google Code project site.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-4696399575844014395?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-09-24T16:32:18+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-6858896334629563490">
	<title>Fredrik Johansson: Again, mpmath in Sage is about to get faster</title>
	<link>http://fredrik-j.blogspot.com/2010/09/again-mpmath-in-sage-is-about-to-get.html</link>
	<content:encoded>My summer project on special functions in mpmath and Sage, generously supported by William Stein with funds from &lt;a href=&quot;http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=0757627&amp;amp;version=noscript&quot;&gt;NSF grant DMS-0757627&lt;/a&gt;, is nearing completion. I will soon release mpmath-0.16, which contains lots of new special functions and bugfixes. Sage users will also benefit from ~1500 lines of new Cython code (preliminary patch &lt;a href=&quot;http://trac.sagemath.org/sage_trac/ticket/9969&quot;&gt;here&lt;/a&gt;) that speeds up various basic operations. Executing &lt;tt&gt;mpmath.runtests()&lt;/tt&gt; in Sage on my laptop now takes 10.47 seconds (8.60 from a warm cache), compared to 14.21 (11.84) seconds with the new extensions disabled -- a global speedup of 30%.&lt;br /&gt;&lt;br /&gt;For comparison, pure-Python mpmath with &lt;a href=&quot;http://code.google.com/p/gmpy/&quot;&gt;gmpy&lt;/a&gt; as the backend takes 21.46 (18.72) seconds to execute the unit tests and pure-Python mpmath with the pure-Python backend takes 52.33 (45.92) seconds.&lt;br /&gt;&lt;br /&gt;Specifically, the new extension code implements exp for real and complex arguments, cos, sin and ln for real arguments, complex exponentiation in some cases, and summation of hypergeometric series, entirely in Cython.&lt;br /&gt;&lt;br /&gt;Timings before (new extensions disabled):&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;sage: import mpmath&lt;br /&gt;sage: x = mpmath.mpf(0.37)&lt;br /&gt;sage: y = mpmath.mpf(0.49)&lt;br /&gt;sage: %timeit mpmath.exp(x)&lt;br /&gt;625 loops, best of 3: 14.5 µs per loop&lt;br /&gt;sage: %timeit mpmath.ln(x)&lt;br /&gt;625 loops, best of 3: 23.2 µs per loop&lt;br /&gt;sage: %timeit mpmath.cos(x)&lt;br /&gt;625 loops, best of 3: 17.2 µs per loop&lt;br /&gt;sage: %timeit x ^ y&lt;br /&gt;625 loops, best of 3: 39.9 µs per loop&lt;br /&gt;sage: %timeit mpmath.hyp1f1(2r,3r,4r)&lt;br /&gt;625 loops, best of 3: 90.3 µs per loop&lt;br /&gt;sage: %timeit mpmath.hyp1f1(x,y,x)&lt;br /&gt;625 loops, best of 3: 83.6 µs per loop&lt;br /&gt;sage: %timeit mpmath.hyp1f1(x,y,mpmath.mpc(x,y))&lt;br /&gt;625 loops, best of 3: 136 µs per loop&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Timings after (new extensions enabled):&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;sage: import mpmath&lt;br /&gt;sage: x = mpmath.mpf(0.37)&lt;br /&gt;sage: y = mpmath.mpf(0.49)&lt;br /&gt;sage: %timeit mpmath.exp(x)&lt;br /&gt;625 loops, best of 3: 2.72 µs per loop&lt;br /&gt;sage: %timeit mpmath.ln(x)&lt;br /&gt;625 loops, best of 3: 7.25 µs per loop&lt;br /&gt;sage: %timeit mpmath.cos(x)&lt;br /&gt;625 loops, best of 3: 4.13 µs per loop&lt;br /&gt;sage: %timeit x ^ y&lt;br /&gt;625 loops, best of 3: 10.5 µs per loop&lt;br /&gt;sage: %timeit mpmath.hyp1f1(2r,3r,4r)&lt;br /&gt;625 loops, best of 3: 47.1 µs per loop&lt;br /&gt;sage: %timeit mpmath.hyp1f1(x,y,x)&lt;br /&gt;625 loops, best of 3: 59.4 µs per loop&lt;br /&gt;sage: %timeit mpmath.hyp1f1(x,y,mpmath.mpc(x,y))&lt;br /&gt;625 loops, best of 3: 83.1 µs per loop&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;The new elementary functions use a combination of custom algorithms and straightforward &lt;a href=&quot;http://www.mpfr.org/&quot;&gt;MPFR&lt;/a&gt; wrappers. Why not just wrap MPFR for everything? There are two primary reasons:&lt;br /&gt;&lt;br /&gt;Firstly, because MPFR numbers have a limited range, custom code still needs to be used in the overflowing cases, and this is almost as much work as an implementation-from-scratch. (There are also some more minor incompatibilities, like lack of round-away-from-zero in MPFR, that result in a lot of extra work.)&lt;br /&gt;&lt;br /&gt;Secondly, MPFR is not always fast (or as fast as it could be), so it pays off to write custom code. In fact, some of the ordinary Python implementations of functions in mpmath are faster than their MPFR counterparts in various cases, although that is rather exceptional (atan is an example). But generally, at low-mid precisions, it is possible to be perhaps 2-4x faster than MPFR with carefully optimized C code (see &lt;a href=&quot;http://code.google.com/p/fastfunlib/&quot;&gt;fastfunlib&lt;/a&gt;). This is a longer-term goal.&lt;br /&gt;&lt;br /&gt;Already now, with the new extension code, the mpmath exponential function becomes faster than the Sage RealNumber version (based on MPFR) at low precision:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;sage: %timeit mpmath.exp(x)&lt;br /&gt;625 loops, best of 3: 2.75 µs per loop&lt;br /&gt;sage: w = RealField(53)(x)&lt;br /&gt;sage: %timeit w.exp()&lt;br /&gt;625 loops, best of 3: 5.57 µs per loop&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;As the timings above indicate, hypergeometric series have gotten up to 2x faster. The speedup of the actual summation is much larger, but much of that gain is lost in various Python overheads (more work can be done on this). There should be a noticeable speedup for some hypergeometric function computations, while others will not benefit as much, for the moment.&lt;br /&gt;&lt;br /&gt;Another benchmark is the &lt;tt&gt;extratest_zeta.py&lt;/tt&gt; script in mpmath, which exercises the mpmath implementation of the &lt;a href=&quot;http://en.wikipedia.org/wiki/Riemann%E2%80%93Siegel_formula&quot;&gt;Riemann-Siegel formula&lt;/a&gt; for evaluation of ζ(&lt;i&gt;s&lt;/i&gt;) for complex &lt;i&gt;s&lt;/i&gt; with large imaginary part. Such computations largely depend on elementary function performance (cos, sin, exp, log).&lt;br /&gt;&lt;br /&gt;Here are the new timings for mpmath in Sage: &lt;pre&gt;&lt;br /&gt;fredrik@scv:~/sage$ ./sage /home/fredrik/mp/mpmath/tests/extratest_zeta.py&lt;br /&gt;399999999 156762524.675 ok = True (time = 1.144)&lt;br /&gt;241389216 97490234.2277 ok = True (time = 9.271)&lt;br /&gt;526196239 202950727.691 ok = True (time = 1.671)&lt;br /&gt;542964976 209039046.579 ok = True (time = 1.189)&lt;br /&gt;1048449112 388858885.231 ok = True (time = 1.774)&lt;br /&gt;1048449113 388858885.384 ok = True (time = 1.604)&lt;br /&gt;1048449114 388858886.002 ok = True (time = 2.096)&lt;br /&gt;1048449115 388858886.002 ok = True (time = 2.587)&lt;br /&gt;1048449116 388858886.691 ok = True (time = 1.546)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;This is mpmath in Sage with the new extension code disabled: &lt;pre&gt;&lt;br /&gt;fredrik@scv:~/sage$ ./sage /home/fredrik/mp/mpmath/tests/extratest_zeta.py&lt;br /&gt;399999999 156762524.675 ok = True (time = 2.352)&lt;br /&gt;241389216 97490234.2277 ok = True (time = 14.088)&lt;br /&gt;526196239 202950727.691 ok = True (time = 3.036)&lt;br /&gt;542964976 209039046.579 ok = True (time = 2.104)&lt;br /&gt;1048449112 388858885.231 ok = True (time = 3.707)&lt;br /&gt;1048449113 388858885.384 ok = True (time = 3.283)&lt;br /&gt;1048449114 388858886.002 ok = True (time = 4.444)&lt;br /&gt;1048449115 388858886.002 ok = True (time = 5.592)&lt;br /&gt;1048449116 388858886.691 ok = True (time = 3.101)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;This is mpmath in ordinary Python mode, using gmpy: &lt;pre&gt;&lt;br /&gt;fredrik@scv:~/sage$ python /home/fredrik/mp/mpmath/tests/extratest_zeta.py&lt;br /&gt;399999999 156762524.675 ok = True (time = 2.741)&lt;br /&gt;241389216 97490234.2277 ok = True (time = 13.842)&lt;br /&gt;526196239 202950727.691 ok = True (time = 3.124)&lt;br /&gt;542964976 209039046.579 ok = True (time = 2.143)&lt;br /&gt;1048449112 388858885.231 ok = True (time = 3.257)&lt;br /&gt;1048449113 388858885.384 ok = True (time = 2.912)&lt;br /&gt;1048449114 388858886.002 ok = True (time = 3.953)&lt;br /&gt;1048449115 388858886.002 ok = True (time = 4.964)&lt;br /&gt;1048449116 388858886.691 ok = True (time = 2.762)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With the new extension code, it appears that zeta computations are up to about twice as fast. This speedup could be made much larger as there still is a significant amount of Python overhead left to remove -- also a project for the future.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-6858896334629563490?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-09-22T14:42:55+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/2010/second-scikitslearn-coding-sprint/">
	<title>Fabian Pedregosa: Second scikits.learn coding sprint</title>
	<link>http://fseoane.net/blog/2010/second-scikitslearn-coding-sprint/</link>
	<content:encoded>&lt;p&gt;Las week took place in Paris the second &lt;a href=&quot;http://scikit-learn.sf.net&quot;&gt;scikits.learn&lt;/a&gt; sprint. It was&lt;br /&gt;
two days of insane activity (115 commits, 6 branches, 33 coffees) in&lt;br /&gt;
which we did a lot of work, both implementing new algorithms and fixing&lt;br /&gt;
or improving old ones. This includes:&lt;/p&gt;
&lt;p&gt;  * sparse version of Lasso by coordinate descent. Not (yet) merged into master, but can be looked from &lt;a href=&quot;http://github.com/ogrisel/scikit-learn/tree/issue-77-sparse-cd&quot;&gt;Olivier’s branch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;  * new API for Pipeline. An example of this can be found in the document &lt;a href=&quot;http://scikit-learn.sourceforge.net/auto_examples/svm/plot_svm_anova.html&quot;&gt;SVM-Anova: SVM with univariate feature selection&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;  * documentation for the &lt;a href=&quot;http://scikit-learn.sourceforge.net/modules/glm.html#bayesian-regression&quot;&gt;bayesian methods&lt;/a&gt; and &lt;a href=&quot;http://scikit-learn.sourceforge.net/cross_validation.html&quot;&gt;cross validation&lt;/a&gt;: Vincent Michel contributed a lot of documentation, mainly taken from chapters of his thesis.&lt;/p&gt;
&lt;p&gt;  * &lt;a href=&quot;http://github.com/scikit-learn/scikit-learn/blob/master/scikits/learn/covariance/ledoit_wolf.py&quot;&gt;Ledoit-Wolf covariance estimation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;  * Pure python &lt;a href=&quot;http://github.com/scikit-learn/scikit-learn/blob/master/scikits/learn/fastica.py&quot;&gt;Fast ICA&lt;/a&gt; implementation.&lt;/p&gt;
&lt;p&gt;And the family picture, featuring (from left to right): &lt;a href=&quot;http://www-sop.inria.fr/members/Alexandre.Gramfort/index.fr.html&quot;&gt;Alexandre Gramfort&lt;/a&gt;, &lt;a href=&quot;http://parietal.saclay.inria.fr/Members/bertrand-thirion&quot;&gt;Bertrand Thirion&lt;/a&gt;, &lt;a href=&quot;http://parietal.saclay.inria.fr/Members/virgile-fritsch&quot;&gt;Virgine Fritsch&lt;/a&gt;, &lt;a href=&quot;http://gael-varoquaux.info/&quot;&gt;Gael Varoquaux&lt;/a&gt;, &lt;a href=&quot;http://parietal.saclay.inria.fr/Members/vincent-michel&quot;&gt;Vincent Michel&lt;/a&gt;, &lt;a href=&quot;http://github.com/ogrisel&quot;&gt;Olivier Grisel&lt;/a&gt; and me (taking the picture).&lt;br /&gt;
&lt;a href=&quot;http://www.flickr.com/photos/fseoane/4974339970/&quot; title=&quot;scikit-learn coding sprint por Fabian Pedregosa, en Flickr&quot;&gt;&lt;img src=&quot;http://farm5.static.flickr.com/4135/4974339970_566424185f.jpg&quot; alt=&quot;scikit-learn coding sprint&quot; height=&quot;375&quot; width=&quot;500&quot; /&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2010-09-12T20:31:21+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-5343369310477112221">
	<title>Fredrik Johansson: Fast combinatorial and number-theoretic functions with FLINT 2</title>
	<link>http://fredrik-j.blogspot.com/2010/09/fast-combinatorial-and-number-theoretic.html</link>
	<content:encoded>Time for a development update! Recently, I've done only a limited amount of work on mpmath (I have a some almost-finished Cython code for &lt;tt&gt;sage.libs.mpmath&lt;/tt&gt; and new code for numerical integration in mpmath, both to be committed fairly soon -- within a couple of weeks, hopefully).&lt;br /&gt;&lt;br /&gt;The last few weeks, I've mostly been contributing to &lt;a href=&quot;http://www.flintlib.org/&quot;&gt;FLINT 2&lt;/a&gt;. For those unfamiliar with it, FLINT is a fast C library for computational number theory developed by Bill Hart and others (the other active developers right now are Sebastian Pancratz and Andy Novocin). In particular, FLINT implements ridiculously fast multiprecision integer vectors and polynomials. It also provides very fast primality testing and factorization for word-size integers (32 or 64 bits), among other things. FLINT 2 is an in-progress rewrite of FLINT 1.x, a current standard component in Sage.&lt;br /&gt;&lt;br /&gt;What does this have to do with numerical evaluation of special functions (the usual theme of this blog)? In short, my goal is to add code to FLINT 2 for &lt;i&gt;exact&lt;/i&gt; special function computations -- combinatorial and number-theoretic functions, special polynomials and the like. Such functions benefit tremendously from the fast integer and polynomial arithmetic available in FLINT 2.&lt;br /&gt;&lt;br /&gt;All my code can be found in my &lt;a href=&quot;http://github.com/fredrik-johansson/flint2/&quot;&gt;public GitHub repository&lt;/a&gt; (the most recent commits as of this writing are in the 'factor' branch).&lt;br /&gt;&lt;br /&gt;Functions I've implemented so far include:&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;Möbius μ and Euler φ (totient) functions for word-size and arbitrary-size integers&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Divisor sum function σ&lt;sub&gt;&lt;i&gt;k&lt;/i&gt;&lt;/sub&gt; for arbitrary-size integers&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Ramanujan τ function (Δ-function &lt;i&gt;q&lt;/i&gt;-expansion)&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Harmonic numbers 1 + 1/2 + 1/3 + ... + 1/&lt;i&gt;n&lt;/i&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Primorials 2 · 3 · 5 · ... · &lt;i&gt;p&lt;/i&gt;&lt;sub&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sub&gt;&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Stirling numbers (1st and 2nd kind)&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;The versions in FLINT 2 of these functions should now be faster than all other implementations I've tried (GAP, Pari, Mathematica, the Sage library) for all ranges of arguments, except for those requiring factorization of large integers.&lt;br /&gt;&lt;br /&gt;Some of these functions depend fundamentally on the ability to factorize integers efficiently. So far I've only implemented trial division for large integers in FLINT 2, with some clever code to extract large powers of small factors quickly. Sufficiently small cofactors are handled by calling Bill Hart's single-word factoring routines. The resulting code is very fast for &quot;artificial&quot; numbers like factorials, and will eventually be complemented with prime and perfect power detection code, plus fast implementations of Brent's algorithm and other methods. Later on the quadratic sieve from FLINT 1 will probably be ported to FLINT 2, so that FLINT 2 will be able to factor any reasonable number reasonably quickly.&lt;br /&gt;&lt;br /&gt;Below, I've posted some benchmark results. A word of caution: all Mathematica timings were done on a different system, which is faster than my own laptop (typically by 30% or so). So in reality, Mathematica performs slightly worse relatively than indicated below. Everything else is timed on my laptop. I have not included test code for the FLINT2 functions (but it's just straightforward C code -- a function call or two between &lt;tt&gt;timeit_start&lt;/tt&gt; and &lt;tt&gt;timeit_stop&lt;/tt&gt; using FLINT 2's profiler module).&lt;br /&gt;&lt;br /&gt;Möbius function (the following is basically a raw exercise of the small-integer factoring code):&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Pari:&lt;br /&gt;sage: %time pari('sum(n=1,10^6,moebius(n))');&lt;br /&gt;CPU times: user 1.04 s, sys: 0.00 s, total: 1.04 s&lt;br /&gt;Wall time: 1.04 s&lt;br /&gt;&lt;br /&gt;Mathematica:&lt;br /&gt;In[1]:= Timing[Sum[MoebiusMu[n], {n,1,10^6}];]&lt;br /&gt;Out[1]= {0.71, Null}&lt;br /&gt;&lt;br /&gt;flint2:&lt;br /&gt;650 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Divisor sum:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Sage (uses Cython code):&lt;br /&gt;sage: %time sigma(factorial(1000),1000);&lt;br /&gt;CPU times: user 0.47 s, sys: 0.00 s, total: 0.47 s&lt;br /&gt;Wall time: 0.46 s&lt;br /&gt;&lt;br /&gt;Mathematica:&lt;br /&gt;In[1]:= Timing[DivisorSigma[1000,1000!];]&lt;br /&gt;Out[1]= {3.01, Null}&lt;br /&gt;&lt;br /&gt;flint2:&lt;br /&gt;350 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Ramanujan τ function:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Sage (uses FLINT 1):&lt;br /&gt;sage: %time delta_qexp(100000);&lt;br /&gt;CPU times: user 0.42 s, sys: 0.01 s, total: 0.43 s&lt;br /&gt;Wall time: 0.42 s&lt;br /&gt;sage: %time delta_qexp(1000000);&lt;br /&gt;CPU times: user 6.02 s, sys: 0.37 s, total: 6.39 s&lt;br /&gt;Wall time: 6.40 s&lt;br /&gt;&lt;br /&gt;flint2:&lt;br /&gt;100000: 230 ms&lt;br /&gt;1000000: 4500 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;An isolated value (Mathematica seems to be the only other software that knows how to compute this):&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Mathematica:&lt;br /&gt;In[1]:= Timing[RamanujanTau[10000!];]&lt;br /&gt;Out[1]= {8.74, Null}&lt;br /&gt;&lt;br /&gt;flint2:&lt;br /&gt;280 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Harmonic numbers (again, only Mathematica seems to implement these). See also my old blog post &lt;a href=&quot;http://fredrik-j.blogspot.com/2009/02/how-not-to-compute-harmonic-numbers.html&quot;&gt;How (not) to compute harmonic numbers&lt;/a&gt;. I've included the fastest version from there, harmonic5:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Mathematica:&lt;br /&gt;In[1]:= Timing[HarmonicNumber[100000];]&lt;br /&gt;Out[1]= {0.22, Null}&lt;br /&gt;In[2]:= Timing[HarmonicNumber[1000000];]&lt;br /&gt;Out[2]= {6.25, Null}&lt;br /&gt;In[3]:= Timing[HarmonicNumber[10000000];]&lt;br /&gt;Out[3]= {129.13, Null}&lt;br /&gt;&lt;br /&gt;harmonic5: (100000):&lt;br /&gt;100000: 0.471 s&lt;br /&gt;1000000: 8.259 s&lt;br /&gt;10000000: 143.639 s&lt;br /&gt;&lt;br /&gt;flint2:&lt;br /&gt;100000: 100 ms&lt;br /&gt;1000000: 2560 ms&lt;br /&gt;10000000: 49400 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;The FLINT 2 function benefits from an improved algorithm that eliminates terms and reduces the size of the temporary numerators and denominators, as well as low-level optimization (the basecase summation directly uses the MPIR mpn interface).&lt;br /&gt;&lt;br /&gt;Isolated Stirling numbers of the first kind:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Mathematica:&lt;br /&gt;In[1]:= Timing[StirlingS1[1000,500];]&lt;br /&gt;Out[1]= {0.24, Null}&lt;br /&gt;In[2]:= Timing[StirlingS1[2000,1000];]&lt;br /&gt;Out[2]= {1.79, Null}&lt;br /&gt;In[3]:= Timing[StirlingS1[3000,1500];]&lt;br /&gt;Out[3]= {5.13, Null}&lt;br /&gt;&lt;br /&gt;flint 2:&lt;br /&gt;100,500: 100 ms&lt;br /&gt;2000,1000: 740 ms&lt;br /&gt;3000,1500: 1520 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Isolated Stirling numbers of the second kind:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Mathematica:&lt;br /&gt;In[1]:= Timing[StirlingS2[1000,500];]&lt;br /&gt;Out11]= {0.21, Null}&lt;br /&gt;In[2]:= Timing[StirlingS2[2000,1000];]&lt;br /&gt;Out[2]= {1.54, Null}&lt;br /&gt;In[3]:= Timing[StirlingS2[3000,1500];]&lt;br /&gt;Out[3]= {4.55, Null}&lt;br /&gt;In[4]:= Timing[StirlingS2[5000,2500];]&lt;br /&gt;Out[4]= {29.25, Null}&lt;br /&gt;&lt;br /&gt;flint2:&lt;br /&gt;1000,500: 2 ms&lt;br /&gt;2000,1000: 17 ms&lt;br /&gt;3000,1500: 50 ms&lt;br /&gt;5000,2500: 240 ms&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;In addition, fast functions are provided for computing a whole row or matrix of Stirling numbers. For example, computing the triangular matrix of ~1.1 million Stirling numbers of the first kind up to S(1500,1500) takes only 1.3 seconds. In Mathematica (again, on the faster system):&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;In[1]:= Timing[Table[StirlingS1[n,k], {n,0,1500}, {k,0,n}];]&lt;br /&gt;Out[1]= {2.13, Null}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;The benchmarks above mostly demonstrate performance for large inputs. Another nice aspect of the FLINT 2 functions is that there typically is very little overhead for small inputs. The high performance is due to a combination of algorithms, low-level optimization, and (most importantly) the fast underlying arithmetic in FLINT 2. I will perhaps write some more about the algorithms (for e.g. Stirling numbers) in a later post.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-5343369310477112221?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-09-05T19:38:55+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9135222751616024074.post-3829230650064961450">
	<title>Matthew Curry: More Improvements and Nice Printing</title>
	<link>http://mattjcurry.blogspot.com/2010/07/more-improvements-and-nice-printing.html</link>
	<content:encoded>This week was quite spread out in terms of what I coded in quantum.py. I made inner products work with operators and other objects in between them. We made &lt;i&gt;pretty&lt;/i&gt; print work with various quantum classes. And finally I made a suite of validating/combining/separating functions for inner and outer products.
&lt;br /&gt;
&lt;br /&gt;&lt;b&gt;First of all, let's look at how &lt;/b&gt;&lt;i&gt;&lt;b&gt;pretty&lt;/b&gt;&lt;/i&gt;&lt;b&gt; makes quantum objects very readable. Let's create the iconic psi state (ket):&lt;/b&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;In [5]: psi = Ket('psi')
&lt;br /&gt;
&lt;br /&gt;In [6]: psi
&lt;br /&gt;Out[6]: |ψ&amp;gt;
&lt;br /&gt;
&lt;br /&gt;&lt;b&gt;Next let's create an operator and dagger it (and leave it unevaluated):&lt;/b&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;In [9]: a = Operator('A')
&lt;br /&gt;
&lt;br /&gt;In [10]: Dagger(a)
&lt;br /&gt;Out[10]:
&lt;br /&gt;†
&lt;br /&gt;A
&lt;br /&gt;
&lt;br /&gt;(the dagger symbol normally appears as a superscript to A, but Blogger is temperamental)
&lt;br /&gt;
&lt;br /&gt;&lt;b&gt;Inner products can have objects (mainly operators) between them now. Outer products will not have this functionality because it is not valid for them. When someone creates an inner product, they must instantiate the class because states and operators (and such) cannot automatically combine with their __mul__ method due to a very tricky reason (the subtlety lies deep within sympy's Mul class):&lt;/b&gt;
&lt;br /&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In [12]: bra = Bra('_a')&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In [13]: b = Operator('B')&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [15]: ip = InnerProduct(bra, b, a, psi)&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In [16]: ip&lt;/div&gt;&lt;div&gt;Out[16]: &amp;lt;_a|⋅b⋅a⋅|ψ&amp;gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In [17]: ip.bra&lt;/div&gt;&lt;div&gt;Out[17]: &amp;lt;_a|&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [19]: ip.ket&lt;/div&gt;&lt;div&gt;Out[19]: (B, A, |ψ&amp;gt;)&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Now let's take a look at some of the special functions I made:&lt;/b&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [23]: expr = bra*a*b*a*psi*a&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In [24]: expr&lt;/div&gt;&lt;div&gt;Out[24]: &amp;lt;_a|⋅a⋅b⋅a⋅|ψ&amp;gt;⋅A&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In [25]: srepr(expr)&lt;/div&gt;&lt;div&gt;Out[25]: &lt;/div&gt;&lt;div&gt;Mul(Bra(Symbol('_a')), Operator(Symbol('A')), Operator(Symbol('B')), Operator(S&lt;/div&gt;&lt;div&gt;ymbol('A')), Ket(Symbol('psi')), Operator(Symbol('A')))&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;(let's see if this is a valid mul by using the validate_mul function)&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [27]: validate_mul(expr)&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;Exception: Ket*(Operator or OuterProduct) is invalid in quantum mechanics.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;=============================================&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;(so now let's make a valid expression)&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [28]: expr = bra*a*b*a*psi*bra*a*psi&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [29]: inprod = combine_innerproduct(expr)&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [30]: inprod&lt;/div&gt;&lt;div&gt;Out[30]: &amp;lt;_a|⋅a⋅b⋅a⋅|ψ&amp;gt;⋅&amp;lt;_a|⋅a⋅|ψ&amp;gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;(these functions automatically check to see if the mul is valid with validate_mul)&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [31]: srepr(inprod)&lt;/div&gt;&lt;div&gt;Out[31]: &lt;/div&gt;&lt;div&gt;Mul(&lt;span style=&quot;color: #CC33CC;&quot; class=&quot;Apple-style-span&quot;&gt;InnerProduct&lt;/span&gt;(Bra(Symbol('_a')), Operator(Symbol('A')), Operator(Symbol('B')&lt;/div&gt;&lt;div&gt;), Operator(Symbol('A')), Ket(Symbol('psi'))), &lt;span style=&quot;color: #CC33CC;&quot; class=&quot;Apple-style-span&quot;&gt;InnerProduct&lt;/span&gt;(Bra(Symbol('_a')), &lt;/div&gt;&lt;div&gt;Operator(Symbol('A')), Ket(Symbol('psi'))))&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;=============================================&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [32]: outprod = combine_outerproduct(expr)&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [34]: srepr(outprod)&lt;/div&gt;&lt;div&gt;Out[34]: &lt;/div&gt;&lt;div&gt;Mul(Bra(Symbol('_a')), Operator(Symbol('A')), Operator(Symbol('B')), Operator(S&lt;/div&gt;&lt;div&gt;ymbol('A')), &lt;span style=&quot;color: #CC33CC;&quot; class=&quot;Apple-style-span&quot;&gt;OuterProduct&lt;/span&gt;(Ket(Symbol('psi')),Bra(Symbol('_a'))), Operator(Symbo&lt;/div&gt;&lt;div&gt;l('A')), Ket(Symbol('psi')))&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;=============================================&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;(you can also split the products; I'll show you how this works on the inprod expression)&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [36]: split = split_product(inprod)&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;In [37]: srepr(split)&lt;/div&gt;&lt;div&gt;Out[37]: &lt;/div&gt;&lt;div&gt;Mul(Bra(Symbol('_a')), Operator(Symbol('A')), Operator(Symbol('B')), Operator(S&lt;/div&gt;&lt;div&gt;ymbol('A')), Ket(Symbol('psi')), Bra(Symbol('_a')), Operator(Symbol('A')), Ket(&lt;/div&gt;&lt;div&gt;Symbol('psi')))&lt;/div&gt;&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;(see, no more inner products!)&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;=============================================&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;So we see that the same expression can be combined into inner products or an outer product depending on which function one uses. And we can also split up the inner or outer products.&lt;/div&gt;&lt;div&gt;
&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In the last few weeks of my project, we have decided that it would be best if I started working on applications with this code such as an infinite square well and other quantum physics examples. We'll see initially how far I get on this next week!&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/9135222751616024074-3829230650064961450?l=mattjcurry.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-09-03T19:12:29+00:00</dc:date>
	<dc:creator>mcurry</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/2010/support-for-sparse-matrices-in-scikitslearn/">
	<title>Fabian Pedregosa: Support for sparse matrices in scikits.learn</title>
	<link>http://fseoane.net/blog/2010/support-for-sparse-matrices-in-scikitslearn/</link>
	<content:encoded>&lt;p&gt;I recently added support for sparse matrices (as defined in&lt;br /&gt;
scipy.sparse) in some classifiers of &lt;a href=&quot;http://scikit-learn.sf.net&quot;&gt;scikits.learn&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;In those classes, the fit method will perform the algorithm without&lt;br /&gt;
converting to a dense representation and will also store parameters in&lt;br /&gt;
an efficient format.&lt;/p&gt;
&lt;p&gt;Right now, the only classese that implements this is SVC and LinearSVC&lt;br /&gt;
in scikits.learn.svm.sparse, although the plan is to add more classes in&lt;br /&gt;
the future. These are capable of taking sparse matrices in the fit()&lt;br /&gt;
method and will also store support vectors as sparse matrices.&lt;/p&gt;
&lt;p&gt;Here is an example. We first create a toy dataset and import relevant&lt;br /&gt;
modules:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; scipy.&lt;span style=&quot;color: black;&quot;&gt;sparse&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;2&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;from&lt;/span&gt; scikits.&lt;span style=&quot;color: black;&quot;&gt;learn&lt;/span&gt;. &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;import&lt;/span&gt; svm&lt;br /&gt;
&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;3&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: X, Y = scipy.&lt;span style=&quot;color: black;&quot;&gt;sparse&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;csr_matrix&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, &lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;, &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;4&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: clf = svm.&lt;span style=&quot;color: black;&quot;&gt;sparse&lt;/span&gt;.&lt;span style=&quot;color: black;&quot;&gt;SVC&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;kernel=&lt;span style=&quot;color: #483d8b;&quot;&gt;'linear'&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;now we will fit the model and query some of its parameters:&lt;/p&gt;
&lt;div style=&quot;overflow: auto; white-space: nowrap; width: 435px;&quot; class=&quot;codecolorer-container python default&quot;&gt;&lt;div style=&quot;&quot; class=&quot;python codecolorer&quot;&gt;In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;5&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: clf.&lt;span style=&quot;color: black;&quot;&gt;fit&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;X, Y&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;5&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;br /&gt;
SVC&lt;span style=&quot;color: black;&quot;&gt;(&lt;/span&gt;kernel=&lt;span style=&quot;color: #483d8b;&quot;&gt;'linear'&lt;/span&gt;, C=&lt;span style=&quot;color: #ff4500;&quot;&gt;1.0&lt;/span&gt;, probability=&lt;span style=&quot;color: #ff4500;&quot;&gt;0&lt;/span&gt;, shrinking=&lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt;, eps=&lt;span style=&quot;color: #ff4500;&quot;&gt;0.001&lt;/span&gt;,&lt;br /&gt;
  cache_size=&lt;span style=&quot;color: #ff4500;&quot;&gt;100.0&lt;/span&gt;,&lt;br /&gt;
  coef0=&lt;span style=&quot;color: #ff4500;&quot;&gt;0.0&lt;/span&gt;,&lt;br /&gt;
  gamma=&lt;span style=&quot;color: #ff4500;&quot;&gt;0.0&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;)&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;6&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: clf.&lt;span style=&quot;color: black;&quot;&gt;support_&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;6&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;br /&gt;
&lt;span style=&quot;color: #66cc66;&quot;&gt;&amp;lt;&lt;/span&gt;2x2 sparse matrix of &lt;span style=&quot;color: #008000;&quot;&gt;type&lt;/span&gt; &lt;span style=&quot;color: #483d8b;&quot;&gt;'&amp;lt;type '&lt;/span&gt;numpy.&lt;span style=&quot;color: black;&quot;&gt;float64&lt;/span&gt;&lt;span style=&quot;color: #483d8b;&quot;&gt;'&amp;gt;'&lt;/span&gt;&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;with&lt;/span&gt; &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt; stored elements &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;in&lt;/span&gt; Compressed Sparse Row format&lt;span style=&quot;color: #66cc66;&quot;&gt;&amp;gt;&lt;/span&gt;&lt;br /&gt;
&lt;br /&gt;
In &lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;7&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: clf.&lt;span style=&quot;color: black;&quot;&gt;coef_&lt;/span&gt;&lt;br /&gt;
Out&lt;span style=&quot;color: black;&quot;&gt;[&lt;/span&gt;&lt;span style=&quot;color: #ff4500;&quot;&gt;7&lt;/span&gt;&lt;span style=&quot;color: black;&quot;&gt;]&lt;/span&gt;: &lt;br /&gt;
&lt;span style=&quot;color: #66cc66;&quot;&gt;&amp;lt;&lt;/span&gt;1x2 sparse matrix of &lt;span style=&quot;color: #008000;&quot;&gt;type&lt;/span&gt; &lt;span style=&quot;color: #483d8b;&quot;&gt;'&amp;lt;type '&lt;/span&gt;numpy.&lt;span style=&quot;color: black;&quot;&gt;float64&lt;/span&gt;&lt;span style=&quot;color: #483d8b;&quot;&gt;'&amp;gt;'&lt;/span&gt;&lt;br /&gt;
    &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;with&lt;/span&gt; &lt;span style=&quot;color: #ff4500;&quot;&gt;1&lt;/span&gt; stored elements &lt;span style=&quot;color: #ff7700; font-weight: bold;&quot;&gt;in&lt;/span&gt; Compressed Sparse Row format&lt;span style=&quot;color: #66cc66;&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For a more complete example, you can look at &lt;a href=&quot;http://scikit-learn.sourceforge.net/auto_examples/mlcomp_sparse_document_classification.html&quot;&gt;Classification&lt;br /&gt;
of text documents using sparse features, contributed by Olivier Grisel.&lt;/a&gt;&lt;/p&gt;</content:encoded>
	<dc:date>2010-08-23T15:47:38+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="http://fseoane.net/blog/2010/flags-to-debug-python-c-extensions/">
	<title>Fabian Pedregosa: Flags to debug python C extensions.</title>
	<link>http://fseoane.net/blog/2010/flags-to-debug-python-c-extensions/</link>
	<content:encoded>&lt;p&gt;I often find myself debugging python C extensions from gdb, but usually some variables are hidden because aggressive optimizations that distutils sets by default. What I did not know, is that you can prevent those optimizations by passing flags &amp;lt;emph&amp;gt;-O0 -fno-inline&amp;lt;/emph&amp;gt; to gcc in keyword extra_compile_args (note: this will only work in GCC). A complete example would look like:&lt;/p&gt;
&lt;p&gt;[code lang=&quot;python&quot;]&lt;br /&gt;
config.add_extension('foo',&lt;br /&gt;
                         sources=['a.c'],&lt;br /&gt;
                         # add this for gdb debug&lt;br /&gt;
                         extra_compile_args=['-O0 -fno-inline'])&lt;br /&gt;
[/code]&lt;/p&gt;
&lt;p&gt;and your extension becomes much easier to debug from gdb.&lt;/p&gt;</content:encoded>
	<dc:date>2010-08-18T11:40:51+00:00</dc:date>
	<dc:creator>fabian</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-6568744196982634289.post-7325250334673304185">
	<title>Ond&amp;#345;ej &amp;#268;ert&amp;iacute;k: Week Aug 9 - 13</title>
	<link>http://ondrejcertik.blogspot.com/2010/08/week-aug-9-13.html</link>
	<content:encoded>On Monday I learned &lt;a href=&quot;http://fwrap.sourceforge.net/&quot;&gt;fwrap&lt;/a&gt; (excellent piece of software btw), there were a few minor technical issues, that I communicated with Kurt on the fwrap mailinglist and I also send him a simple patch, so that it works fine for my fortran code (functions returning the value itself, instead of a tuple of length 1).&lt;br /&gt;&lt;br /&gt;Then I took my old fortran based shooting method solvers that I wrote couple years ago and wrapped them using fwrap and run couple simulations against my FE solver.&lt;br /&gt;&lt;br /&gt;On Tuesday we had a lunch with all the advisors and students and the llnl director and a little presentation about what we did.&lt;br /&gt;&lt;br /&gt;On Wednesday I run shooting method calculations for 50 states of silver, both for selfconsistent DFT potential and Z/r potential. I then also run the FE solver for the same DFT potential and compared results. There are lots of small technical issues, for example I had to use cubic splines to interpolate the potential, play with the mesh for the shooting method and so on.&lt;br /&gt;&lt;br /&gt;However, the shooting method and FE agrees to every single printed digit, after making sure that the mesh is ok for both methods. For all potentials that I tried. That's very cool.&lt;br /&gt;&lt;br /&gt;In the process of it, I also wrote a patch to SymPy to calculate exact energies for the Hydrogen atom, both from Schroedinger and Dirac equations. I still need to polish it a bit.&lt;br /&gt;&lt;br /&gt;On Thursday I run couple more calculations and setup a poster and had a poster session, it was two hours, and I think around 7 people (not counting other students and people from our group) stopped by and talked with me about it, so I was very happy. Being able to solve radial Schroedinger and especially Dirac equations robustly is something that several people in the lab would really need.&lt;br /&gt;&lt;br /&gt;Today I talked little bit (finally) about some Green functions in QM and QFT with a postdoc in the Quantum Simulations group, that I always wanted to, but didn't have time before, then packed my things and went back to Reno.&lt;br /&gt;&lt;br /&gt;My plan for the next week(s) is to wrap up what I did and put it into articles. I already have enough material for some articles, so it has to be done. In parallel, I'd like to finish the FE Dirac solver, the coding is done, but now I need to play with adaptivity and also investigate if we are getting the spurious states, that other people are getting when using b-splines.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/6568744196982634289-7325250334673304185?l=ondrejcertik.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-14T04:05:47+00:00</dc:date>
	<dc:creator>Ondřej Čertík</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=741">
	<title>Aaron Meurer: The Risch Algorithm: Part 3, Liouville’s Theorem</title>
	<link>http://asmeurersympy.wordpress.com/2010/08/14/the-risch-algorithm-part-3-liouvilles-theorem/</link>
	<content:encoded>&lt;p&gt;So this is the last official week of the Summer of Code program, and my work is mostly consisting of removing &lt;code&gt;NotImplementedError&lt;/code&gt;s (i.e., implementing stuff), and fixing bugs. None of this is particularly interesting, so instead of talking about that, I figured I would produce another one of my Risch Algorithm blog posts.  It is recommended that you read parts &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/&quot;&gt;1&lt;/a&gt; and &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/24/the-risch-algorithm-part-2-elementary-functions/&quot;&gt;2&lt;/a&gt; first, as well as my post on &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/06/11/integration-of-rational-functions/&quot;&gt;rational function integration&lt;/a&gt;, which could be considered part 0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Liouville’s Theorem&lt;/strong&gt;&lt;br /&gt;
Anyone who’s taken calculus intuitively knows that integration is hard, while differentiation is easy.  For differentiation, we can produce the derivative of any elementary function, and we can do so easily, using a simple algorithm consisting of the sum and product rules, the chain rule, and the rules for the derivative of all the various elementary functions.  But for integration, we have to try to work backwards.  &lt;/p&gt;
&lt;p&gt;There are two things that make integration difficult.  First is the existence of functions that simply do not have any elementary antiderivative.  &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7B-x%5E2%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{-x^2}&quot; class=&quot;latex&quot; title=&quot;e^{-x^2}&quot; /&gt; is perhaps the most famous example of such a function, since it arises from the normal distribution in statistics.  But there are many others.  &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Csin%7B%28x%5E2%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\sin{(x^2)}&quot; class=&quot;latex&quot; title=&quot;\sin{(x^2)}&quot; /&gt;, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Clog%7B%28x%29%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{1}{\log{(x)}}&quot; class=&quot;latex&quot; title=&quot;\frac{1}{\log{(x)}}&quot; /&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=x%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;x^x&quot; class=&quot;latex&quot; title=&quot;x^x&quot; /&gt; are some other examples of famous non-integrable functions.  &lt;/p&gt;
&lt;p&gt;The second problem is that no one single simple rule for working backwards will always be applicable.  We know that u-substitution and integration by parts are the reverse of the chain rule and the product rule, respectively.  But those methods will only work if those rules were the ones that were applied originally, and then only if you chose the right &lt;img src=&quot;http://s0.wp.com/latex.php?latex=u&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;u&quot; class=&quot;latex&quot; title=&quot;u&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=dv&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;dv&quot; class=&quot;latex&quot; title=&quot;dv&quot; /&gt;.  &lt;/p&gt;
&lt;p&gt;But there is a much simpler example that gets right down to the point with Liouville’s theorem.  The power rule, which is that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7Bd%7D%7Bdx%7Dx%5En%3Dnx%5E%7Bn-1%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{d}{dx}x^n=nx^{n-1}&quot; class=&quot;latex&quot; title=&quot;\frac{d}{dx}x^n=nx^{n-1}&quot; /&gt; is easily reversed for integration.  Given the power rule for differentiation, it’s easy to see that the reverse rule should be &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cint%7Bx%5Endx%7D%3D%5Cfrac%7Bx%5E%7Bn%2B1%7D%7D%7Bn%2B1%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\int{x^ndx}=\frac{x^{n+1}}{n+1}&quot; class=&quot;latex&quot; title=&quot;\int{x^ndx}=\frac{x^{n+1}}{n+1}&quot; /&gt;.  This works fine, except that were are dividing something, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n%2B1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;n+1&quot; class=&quot;latex&quot; title=&quot;n+1&quot; /&gt;.  In mathematics, whenever we do that, we have to ensure that whatever we divide by is not 0. In this case, it means that we must assert &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n%5Cneq+-1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;n\neq -1&quot; class=&quot;latex&quot; title=&quot;n\neq -1&quot; /&gt;.  This excludes &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cint%7B%5Cfrac%7B1%7D%7Bx%7Ddx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\int{\frac{1}{x}dx}&quot; class=&quot;latex&quot; title=&quot;\int{\frac{1}{x}dx}&quot; /&gt;.  We know from calculus that this integral requires us to introduce a special function, the natural logarithm.  &lt;/p&gt;
&lt;p&gt;But we see that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n%3D-1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;n=-1&quot; class=&quot;latex&quot; title=&quot;n=-1&quot; /&gt; is the only exception to the power rule, so that the integral of any (&lt;a href=&quot;http://en.wikipedia.org/wiki/Laurent_polynomial&quot;&gt;Laurent&lt;/a&gt;) polynomial is again a (Laurent) polynomial, plus a logarithm.  Recall from part 0 (&lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/06/11/integration-of-rational-functions/&quot;&gt;Rational Function Integration&lt;/a&gt;) that the same thing is true for any rational function: the integral is again a rational function, plus a logarithm (we can combine multiple logarithms into one using the logarithmic identities, so assume for simplicity that there is just one).  The argument is very similar, too.  Assume that we have split the denominator rational function into linear factors in the &lt;a href=&quot;http://en.wikipedia.org/wiki/Algebraic_splitting_field&quot;&gt;algebraic splitting field&lt;/a&gt; (such as the complex numbers).  Then perform a partial fractions decomposition on the rational function.  Each term in the decomposition will be either a polynomial, or of the form &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7Ba%7D%7B%28x+-+b%29%5En%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{a}{(x - b)^n}&quot; class=&quot;latex&quot; title=&quot;\frac{a}{(x - b)^n}&quot; /&gt;. The integration of these terms is the same as with the power rule, making the substitution &lt;img src=&quot;http://s0.wp.com/latex.php?latex=u+%3D+x+-+b&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;u = x - b&quot; class=&quot;latex&quot; title=&quot;u = x - b&quot; /&gt;. When &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n%5Cgeq+2&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;n\geq 2&quot; class=&quot;latex&quot; title=&quot;n\geq 2&quot; /&gt;, the integral will be &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7B-1%7D%7Bn+-+1%7D%5Cfrac%7Ba%7D%7B%28x+-+b%29%5E%7Bn+-+1%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{-1}{n - 1}\frac{a}{(x - b)^{n - 1}}&quot; class=&quot;latex&quot; title=&quot;\frac{-1}{n - 1}\frac{a}{(x - b)^{n - 1}}&quot; /&gt;; when &lt;img src=&quot;http://s0.wp.com/latex.php?latex=n+%3D+1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;n = 1&quot; class=&quot;latex&quot; title=&quot;n = 1&quot; /&gt;, the integral will be &lt;img src=&quot;http://s0.wp.com/latex.php?latex=a%5Clog%7B%28x+-+b%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;a\log{(x - b)}&quot; class=&quot;latex&quot; title=&quot;a\log{(x - b)}&quot; /&gt;.  Now computationally, we don’t want to work with the algebraic splitting field, but it turns out that we don’t need to actually compute it to find the integral.  But theory is what we are dealing with here, so don’t worry about that.  &lt;/p&gt;
&lt;p&gt;Now the key observation about differentiation, as I have pointed out in the earlier parts of this blog post series,  is that the derivative of an elementary function can be expressed in terms of itself, in particular, as a polynomial in itself.  To put it another way, functions like &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x&quot; class=&quot;latex&quot; title=&quot;e^x&quot; /&gt;, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Ctan%7B%28x%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\tan{(x)}&quot; class=&quot;latex&quot; title=&quot;\tan{(x)}&quot; /&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x)}&quot; class=&quot;latex&quot; title=&quot;\log{(x)}&quot; /&gt; all satisfy linear differential equations with rational coefficients (e.g., for these, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=y%27%3Dy&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;y'=y&quot; class=&quot;latex&quot; title=&quot;y'=y&quot; /&gt;, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=y%27%3D1+%2B+y%5E2&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;y'=1 + y^2&quot; class=&quot;latex&quot; title=&quot;y'=1 + y^2&quot; /&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=y%27%3D%5Cfrac%7B1%7D%7Bx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;y'=\frac{1}{x}&quot; class=&quot;latex&quot; title=&quot;y'=\frac{1}{x}&quot; /&gt;).  &lt;/p&gt;
&lt;p&gt;Now, the theory gets more complicated, but it turns out that, using a careful analysis of this fact, we can prove a similar result to the one about rational functions to any elementary function. In a nutshell, Liouville’s Theorem says this:  if an elementary function has an elementary integral, then that integral is a composed only of functions from the original integrand, plus a finite number of logarithms of functions from the integrand, which can be considered one logarithm, as mentioned above (“functions from” more specifically means a rational function in the terms from our elementary extension).  Here is the formal statement of the theorem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem (Liouville’s Theorem – Strong version)&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Let &lt;img src=&quot;http://s0.wp.com/latex.php?latex=K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;K&quot; class=&quot;latex&quot; title=&quot;K&quot; /&gt; be a differential field, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=C%3D%5Cmathrm%7BConst%7D%28K%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;C=\mathrm{Const}(K)&quot; class=&quot;latex&quot; title=&quot;C=\mathrm{Const}(K)&quot; /&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f%5Cin+K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;f\in K&quot; class=&quot;latex&quot; title=&quot;f\in K&quot; /&gt;. If there exist an elementary extension &lt;img src=&quot;http://s0.wp.com/latex.php?latex=E&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;E&quot; class=&quot;latex&quot; title=&quot;E&quot; /&gt; of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;K&quot; class=&quot;latex&quot; title=&quot;K&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=g+%5Cin+E&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;g \in E&quot; class=&quot;latex&quot; title=&quot;g \in E&quot; /&gt; such that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=Dg+%3Df&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;Dg =f&quot; class=&quot;latex&quot; title=&quot;Dg =f&quot; /&gt;, then there are &lt;img src=&quot;http://s0.wp.com/latex.php?latex=v+%5Cin+K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;v \in K&quot; class=&quot;latex&quot; title=&quot;v \in K&quot; /&gt;, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=c_1%2C+%5Cdots%2C+c_n%5Cin+%5Cbar%7BC%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;c_1, \dots, c_n\in \bar{C}&quot; class=&quot;latex&quot; title=&quot;c_1, \dots, c_n\in \bar{C}&quot; /&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=u_1%2C+%5Cdots%2Cu_n%5Cin+K%28c_1%2C%5Cdots%2Cc_n%29%5E%2A&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;u_1, \dots,u_n\in K(c_1,\dots,c_n)^*&quot; class=&quot;latex&quot; title=&quot;u_1, \dots,u_n\in K(c_1,\dots,c_n)^*&quot; /&gt; such that &lt;/em&gt;&lt;/p&gt;&lt;em&gt;
&lt;h1&gt;
&lt;img src=&quot;http://s0.wp.com/latex.php?latex=f+%3D+Dv+%2B+%5Csum_%7Bi%3D1%7D%5En+c_i%5Cfrac%7BDu_i%7D%7Bu_i%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;f = Dv + \sum_{i=1}^n c_i\frac{Du_i}{u_i}&quot; class=&quot;latex&quot; title=&quot;f = Dv + \sum_{i=1}^n c_i\frac{Du_i}{u_i}&quot; /&gt;.&lt;br /&gt;
&lt;/h1&gt;
&lt;/em&gt;&lt;p&gt;&lt;em&gt;&lt;/em&gt;&lt;br /&gt;
Looking closely at the formal statement of the theorem, we can see that it says the same thing as my “in a nutshell” statement.  &lt;img src=&quot;http://s0.wp.com/latex.php?latex=K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;K&quot; class=&quot;latex&quot; title=&quot;K&quot; /&gt; is the differential extension, say of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x)&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x)&quot; /&gt;, that contains all of our elementary functions (see &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/24/the-risch-algorithm-part-2-elementary-functions/&quot;&gt;part 2&lt;/a&gt;).  &lt;img src=&quot;http://s0.wp.com/latex.php?latex=E&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;E&quot; class=&quot;latex&quot; title=&quot;E&quot; /&gt; is an extension of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;K&quot; class=&quot;latex&quot; title=&quot;K&quot; /&gt;.  The whole statement of the theorem is that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=E&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;E&quot; class=&quot;latex&quot; title=&quot;E&quot; /&gt; need not be extended from &lt;img src=&quot;http://s0.wp.com/latex.php?latex=K&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;K&quot; class=&quot;latex&quot; title=&quot;K&quot; /&gt; by anything more than some logarithms.   &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;f&quot; class=&quot;latex&quot; title=&quot;f&quot; /&gt; is our original function and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=g%3D%5Cint+f&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;g=\int f&quot; class=&quot;latex&quot; title=&quot;g=\int f&quot; /&gt;.  Recall from &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/&quot;&gt;part 1&lt;/a&gt; that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=Dg+%3D+%5Cfrac%7BDu%7D%7Bu%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;Dg = \frac{Du}{u}&quot; class=&quot;latex&quot; title=&quot;Dg = \frac{Du}{u}&quot; /&gt; is just another way of saying that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=g+%3D+%5Clog%7B%28u%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;g = \log{(u)}&quot; class=&quot;latex&quot; title=&quot;g = \log{(u)}&quot; /&gt;.  The rest of the formal statement is some specifics dealing with the constant field, which assure us that we do not need to introduce any new constants in the integration. This fact is actually important to the decidability of the Risch Algorithm, because many problems about constants are either unknown or undecidable (such as the transcendence degree of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28e%2C+%5Cpi%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(e, \pi)&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(e, \pi)&quot; /&gt;).  But this ensures us that as long as we start with a constant field that is computable, our constant field for our antiderivative will also be computable, and will in fact be the same field, except for some possible algebraic extensions (the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=c_i&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;c_i&quot; class=&quot;latex&quot; title=&quot;c_i&quot; /&gt;).  &lt;/p&gt;
&lt;p&gt;At this point, I want to point out that even though my work this summer has been only on the purely transcendental case of the Risch Algorithm, Liouville’s Theorem is true for all elementary functions, which includes algebraic functions.  However, if you review the proof of the theorem, the proof of the algebraic part is completely different from the proof of the transcendental part, which is the first clue that the algebraic part of the algorithm is completely different from the transcendental part (and also a clue that it is harder).&lt;/p&gt;
&lt;p&gt;Liouville’s Theorem is what allows us to prove that a given function does not have an elementary antiderivative, by giving us the form that any antiderivative must have.  We first perform the same Hermite Reduction from the &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/06/11/integration-of-rational-functions/&quot;&gt;rational integration case&lt;/a&gt;. Then, a generalization of the same Lazard-Rioboo-Trager Algorithm due to Rothstein allows us to find the logarithmic part of any integral (the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Csum_%7Bi%3D1%7D%5En+c_i%5Cfrac%7BDu_i%7D%7Bu_i%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\sum_{i=1}^n c_i\frac{Du_i}{u_i}&quot; class=&quot;latex&quot; title=&quot;\sum_{i=1}^n c_i\frac{Du_i}{u_i}&quot; /&gt; from Liouville’s Theorem).  &lt;/p&gt;
&lt;p&gt;Now a difference here is that sometimes, the part of the integrand that corresponds to the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7Ba%7D%7Bx+-+b%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{a}{x - b}&quot; class=&quot;latex&quot; title=&quot;\frac{a}{x - b}&quot; /&gt; for general functions doesn’t always have an elementary integral (these are called &lt;em&gt;simple&lt;/em&gt; functions.  I think I will talk about them in more detail in a future post in this series).   An example of this is &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Clog%7B%28x%29%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{1}{\log{(x)}}&quot; class=&quot;latex&quot; title=&quot;\frac{1}{\log{(x)}}&quot; /&gt;.  Suffice it to say that any elementary integral of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Clog%7B%28x%29%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{1}{\log{(x)}}&quot; class=&quot;latex&quot; title=&quot;\frac{1}{\log{(x)}}&quot; /&gt; must be part of some log-extension of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%2C+%5Clog%7B%28x%29%7D%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x, \log{(x)})&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x, \log{(x)})&quot; /&gt;, and that we can prove that no such logarithmic extension exists in the course of trying to compute it with the Lazard-Rioboo-Rothstein-Trager Algorithm.&lt;/p&gt;
&lt;p&gt;In the rational function case, after we found the rational part and the logarithmic part, we were practically done, because the only remaining part was a polynomial.  Well, for the general transcendental function case, we are left with an analogue, which are called &lt;em&gt;reduced&lt;/em&gt; functions, and we are far from done.  This is the hardest part of the integration algorithm.  This will also be the topic of a future post in this series.  Suffice it to say that this is where most of the proofs of non-integrability come from, including the other integrals than &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Clog%7B%28x%29%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{1}{\log{(x)}}&quot; class=&quot;latex&quot; title=&quot;\frac{1}{\log{(x)}}&quot; /&gt; that I gave above.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;br /&gt;
That’s it for now.  Originally, I was also going to include a bit on the structure theorems too, but I think I am going to save that for part 4 instead.  I may or may not have another post ready before the official end of coding date for Google Summer of Code, which is Monday (three days from now).  I want to make a post with some nice graphs comparing the timings of the new &lt;code&gt;risch_integrate()&lt;/code&gt; and the old &lt;code&gt;heurisch()&lt;/code&gt; (what is currently behind SymPy’s &lt;code&gt;integrate()&lt;/code&gt;).  But as I have said before, I plan on continuing coding the integration algorithm beyond the program until I finish it, and even beyond that (there are lots of cool ways that the algorithm can be extended to work with special functions, there’s definite integration with Meijer-G functions, and there’s of course the algebraic part of the algorithm, which is a much larger challenge).  And along with it, I plan to continue keeping you updated with blog posts, including at least all the Risch Algorithm series posts that I have promised (I have counted at least three topics that I have explicitly promised but haven’t done yet).  And of course, there will be the mandatory GSoC wrap-up blog post, detailing my work for the summer.  &lt;/p&gt;
&lt;p&gt;Please continue to test my prototype &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/08/05/prototype-risch_integrate-function-ready-for-testing/&quot;&gt;&lt;code&gt;risch_integrate()&lt;/code&gt;&lt;/a&gt; function in my &lt;a href=&quot;http://github.com/asmeurer/sympy/tree/integration3&quot;&gt;integration3&lt;/a&gt; branch, and tell me what you think (or if you find a bug).&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/741/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/741/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=741&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-08-14T02:55:23+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="http://ojensen.wordpress.com/?p=250">
	<title>Øyvind Jensen: Fast ufunc-ish Hydrogen solutions</title>
	<link>http://ojensen.wordpress.com/2010/08/10/fast-ufunc-ish-hydrogen-solutions/</link>
	<content:encoded>&lt;p&gt;In my previous post I demonstrated array operations based on the new functionality I have implemented during &lt;a href=&quot;http://socghop.appspot.com/gsoc/student_project/show/google/gsoc2010/python/t127230762991&quot;&gt;my GSOC project&lt;/a&gt;.  In this post I will discuss another feature that is essential for array calculations in a computer algebra system: The initialization of numeric arrays &lt;em&gt;based on symbolic math expressions&lt;/em&gt;.  After all, it is the symbolic stuff we are really interested in, isn’t it? &lt;img src=&quot;http://s2.wp.com/wp-includes/images/smilies/icon_smile.gif&quot; alt=&quot;:-)&quot; class=&quot;wp-smiley&quot; /&gt;   I will demonstrate how the automatic compilation and wrapping can be used to setup Numpy arrays with fast Hydrogen wave functions.&lt;/p&gt;
&lt;p&gt;Again, it will be interesting to see how we compare with the array initialization features of numpy.  One lesson I learned while preparing my previous post is that the timing results depend heavily on the compiler.  To avoid the scaling issues we observed with the matrix-matrix product last time, I will do all examples on a computer with ifort 11.0.  The Numpy installation on that computer is version 1.1.0.  The warning applies again: I report the timing results I get on my computer, but this is not a rigorous benchmark.  Also, I may not be using Numpy in the optimal way.  If you know how I could make it run faster, I’d love hear about it.&lt;/p&gt;
&lt;h3&gt;Introductory example: linspace&lt;/h3&gt;
&lt;p&gt;First, lets try to create our own compiled linspace function that we can compare with numpy.linspace.  The Numpy function creates an array of evenly spaced numbers, like this:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [1]: import numpy as np
In [2]: np.linspace(0, 1, 5)
Out[2]: array([ 0.  ,  0.25,  0.5 ,  0.75,  1.  ])
&lt;/pre&gt;
&lt;p&gt;The same functionality can be created by autowrapping a Sympy expression that maps the array index to an interval &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=%5Ba%2C+b%5D&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;[a, b]&quot; class=&quot;latex&quot; title=&quot;[a, b]&quot; /&gt; on the real axis:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [3]: from sympy.utilities.autowrap import autowrap
In [4]: a, b = symbols('a b')
In [5]: i = Idx('i', m)
In [6]: linearmap = a + (i - 1)*(a - b)/(1 - m)
In [7]: x = IndexedBase('x')
In [8]: linspace = autowrap(Eq(x[i], linearmap))
In [9]: linspace(0, 1, 5)
Out[9]: [ 0.    0.25  0.5   0.75  1.  ]
&lt;/pre&gt;
&lt;p&gt;So, it worked.  The array has been initialized according to the linear map defined by the Sympy expression at In[6].  In order to map the index to the interval correctly one must remember that the index of a Fortran array starts at 1, while C arrays start at 0.  This must be be taken into account when the initialization expression is defined, so a slightly different expression must be used with the C backend.&lt;/p&gt;
&lt;p&gt;Now, you may be wondering how I could know the order of the arguments in the wrapped linspace function, and why it was so conveniently compatible with the interface for numpy.linspace.  The answer, is that unless autowrap gets the optional keyword argument ‘args’, the arguments are sorted according to their string representation.  I carefully chose the symbols in the linear map so that my linspace would automatically get the same argument sequence as Numpy’s.&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [14]: %timeit np.linspace(0, 5, 100000)
1000 loops, best of 3: 916 µs per loop
In [15]: %timeit linspace(0, 5, 100000)
1000 loops, best of 3: 381 µs per loop
&lt;/pre&gt;
&lt;p&gt;Sweet!  Evenly spaced numbers are of course very useful, but let us also try something a bit more juicy.&lt;/p&gt;
&lt;h3&gt;Universal hydrogen functions&lt;/h3&gt;
&lt;p&gt;One of the really useful concepts in Numpy is the “universal function” or &lt;a href=&quot;http://www.google.no/url?sa=t&amp;amp;source=web&amp;amp;cd=1&amp;amp;ved=0CBYQFjAA&amp;amp;url=http%3A%2F%2Fdocs.scipy.org%2Fdoc%2Fnumpy%2Freference%2Fufuncs.html&amp;amp;rct=j&amp;amp;q=numpy%20ufunc&amp;amp;ei=aEZgTOmQJNCHOKOaiccP&amp;amp;usg=AFQjCNHF0afQWtFHqaaI5KQnz8bcvyzrAg&amp;amp;cad=rja&quot;&gt;ufunc&lt;/a&gt;. To put it short, ufuncs operate on arrays by applying a scalar function elementwise. It is actually more than that, as numpy ufuncs are required to support type casting, broadcasting and more, but we will ignore that and focus on the following quote from the Numpy docs:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;That is, a ufunc is a “vectorized” wrapper for a function that takes a fixed number of scalar inputs and produces a fixed number of scalar outputs.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Can we make such functions with the autowrap framework? As you can probably guess, the answer is positive, so the question is rather: can we beat Numpy on speed?  Let’s find out.&lt;/p&gt;
&lt;p&gt;Very recently, Sympy got functionality to generate radial electronic &lt;a href=&quot;http://github.com/jegerjensen/sympy/commit/fd0ed8330fc5025e422468fe9d7519b9b7052a90&quot;&gt;wave functions for the Hydrogen atom.&lt;/a&gt; That is, quantum mechanical solutions to the attractive Coulomb potential.  These are well known, and long since tabulated functions, that are routinely used in quantum mechanics.  Wouldn’t it be nice to have the Hydrogen wave functions available as super fast ufunc-like binary functions?&lt;/p&gt;
&lt;p&gt;The failsafe way to build a fast binary function that works element-wise on an array, is to construct a symbolic Lambda function that contains the initialization expression.  The Lambda instance should then be attached to a regular Sympy Function.  This is done with a call to implemented_function(‘f’, Lambda(…)) as in the following:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [2]: from sympy.utilities.lambdify import implemented_function
In [3]: from sympy.physics.hydrogen import R_nl
In [4]: a, r = symbols('a r')
In [5]: psi_nl = implemented_function('psi_nl', Lambda([a, r], R_nl(1, 0, a, r)))
In [6]: psi_nl(a, r)
Out[6]: psi_nl(a, r)
In [7]: psi_nl._imp_(a, r)
Out[7]:
             -r
       ____  --
      / 1    a
2*   /  -- *e
    /    3
  \/    a
&lt;/pre&gt;
&lt;p&gt;As you would guess from Out[6], psi_nl is just a regular Sympy Function, but with an additional attribute, _imp_, that works as displayed in In[7].   The implemented_function trick &lt;a href=&quot;http://github.com/jegerjensen/sympy/commit/72d4164b3399bcf2289432e042df8b4006ff3f92&quot;&gt;landed in Sympy&lt;/a&gt; just a few weeks ago.  It was intended for numeric implementations, but in my &lt;a href=&quot;http://github.com/jegerjensen/sympy/tree/autowrap3&quot;&gt;autowrap3 branch&lt;/a&gt;, I (ab)use it to store a symbolic Lambda instead.&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [8]: x = IndexedBase('x')
In [9]: y = IndexedBase('y')
In [10]: i = Idx('i', m)
In [11]: hydrogen = autowrap(Eq(y[i], psi_nl(a, x[i])), tempdir='/tmp/hydro')
&lt;/pre&gt;
&lt;p&gt;The argument ‘tempdir’ tells autowrap to compile the code in a specific directory, and leave the files intact when finished.  Checking the Fortran source code reveals that the wave function is calculated like this:&lt;/p&gt;
&lt;pre class=&quot;brush: plain;&quot;&gt;do i = 1, m
   y(i) = 2*sqrt(a**(-3))*exp(-x(i)/a)
end do
&lt;/pre&gt;
&lt;p&gt;The implemented function has been printed as an &lt;em&gt;inline&lt;/em&gt; expression, avoiding a costly function call in the loop.  (If you wonder why I didn’t just print the expression directly, the explanation is &lt;a href=&quot;http://github.com/jegerjensen/sympy/commit/9431840359486e37c5feeedfd1e885b91f60af1c&quot;&gt;here&lt;/a&gt;.)  Now that we have the functions available, this is how they look:&lt;/p&gt;
&lt;div style=&quot;width: 460px;&quot; id=&quot;attachment_348&quot; class=&quot;wp-caption aligncenter&quot;&gt;&lt;a href=&quot;http://ojensen.files.wordpress.com/2010/08/hydrogen_functions.png&quot;&gt;&lt;img src=&quot;http://ojensen.files.wordpress.com/2010/08/hydrogen_functions.png?w=450&amp;amp;h=294&quot; title=&quot;hydrogen_functions&quot; height=&quot;294&quot; width=&quot;450&quot; alt=&quot;Plot of radial hydrogen wavefunctions&quot; class=&quot;size-medium wp-image-348 &quot; /&gt;&lt;/a&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Some of the Hydrogen wave functions plotted vs. the radial distance from the nucleus.&lt;/p&gt;&lt;/div&gt;
&lt;p&gt;The parameters &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n&quot; class=&quot;latex&quot; title=&quot;n&quot; /&gt; and &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=l&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;l&quot; class=&quot;latex&quot; title=&quot;l&quot; /&gt; are quantum numbers related to the electron’s energy and orbital angular momentum respectively.&lt;/p&gt;
&lt;p&gt;The autowrapped Hydrogen functions can also be compared with numpy equivalents, as all waves are expressed in terms of functions that are universal in numpy.  We use Sympy’s ‘lambdify’ to create a Python lambda function that calls the relevant ufuncs from numpy’s namespace:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [31]: from sympy.utilities.lambdify import lambdify
In [32]: psi_lambda = lambdify([a, r], R_nl(1, 0, a, r), 'numpy')
In [33]: grid = np.linspace(0,3,100)
In [34]: np.linalg.norm(psi_lambda(0.5, grid) - hydrogen(0.5, grid))
Out[34]: 2.21416777433e-15
&lt;/pre&gt;
&lt;p&gt;But there are many solutions to the Hydrogen atom, so let’s study them a bit more systematically.  The following is the output from a loop over the energy quantum number &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n&quot; class=&quot;latex&quot; title=&quot;n&quot; /&gt;.  I used only the s-wave functions &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=l%3D0&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;l=0&quot; class=&quot;latex&quot; title=&quot;l=0&quot; /&gt;, corresponding to an electron that moves straight through the nucleus and out on the other side before turning back again to repeat the cycle.  For each &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n&quot; class=&quot;latex&quot; title=&quot;n&quot; /&gt;, I calculated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%timeit for application of lambda function with Numpy ufuncs&lt;/li&gt;
&lt;li&gt;%timeit for application of the compiled and wrapped Sympy function&lt;/li&gt;
&lt;li&gt;the absolute difference between the solutions: &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=sum%28abs%28+%5Cpsi_%7Bnumpy%7D+-+%5Cpsi_%7Bsympy%7D%29%29&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;sum(abs( \psi_{numpy} - \psi_{sympy}))&quot; class=&quot;latex&quot; title=&quot;sum(abs( \psi_{numpy} - \psi_{sympy}))&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is the output:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;n = 1
Numpy: 100000 loops, best of 3: 16.8 µs per loop
Sympy: 1000000 loops, best of 3: 1.92 µs per loop
difference: 1.07708980623e-14
n = 2
Numpy: 10000 loops, best of 3: 30 µs per loop
Sympy: 1000000 loops, best of 3: 2 µs per loop
difference: 5.13651621237e-15
n = 3
Numpy: 10000 loops, best of 3: 48.1 µs per loop
Sympy: 100000 loops, best of 3: 3.37 µs per loop
difference: 2.28896762655e-15
n = 4
Numpy: 10000 loops, best of 3: 70.9 µs per loop
Sympy: 100000 loops, best of 3: 2.7 µs per loop
difference: 6.18114500556e-15
n = 5
Numpy: 10000 loops, best of 3: 116 µs per loop
Sympy: 100000 loops, best of 3: 4.61 µs per loop
difference: 5.68967616077e-15
n = 6
Numpy: 10000 loops, best of 3: 142 µs per loop
Sympy: 100000 loops, best of 3: 5.02 µs per loop
difference: 1.21523884705e-14
n = 7
Numpy: 10000 loops, best of 3: 183 µs per loop
Sympy: 100000 loops, best of 3: 5.95 µs per loop
difference: 1.04406500806e-14
&lt;/pre&gt;
&lt;p&gt;Awesome! For &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n%3D7&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n=7&quot; class=&quot;latex&quot; title=&quot;n=7&quot; /&gt; we beat Numpy by a factor of 30. &lt;img src=&quot;http://s2.wp.com/wp-includes/images/smilies/icon_smile.gif&quot; alt=&quot;:-)&quot; class=&quot;wp-smiley&quot; /&gt;   But the really interesting thing here is the &lt;em&gt;scaling&lt;/em&gt; with expression complexity.  Look at this:&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;/p&gt;&lt;div style=&quot;width: 460px;&quot; id=&quot;attachment_354&quot; class=&quot;wp-caption aligncenter&quot;&gt;&lt;a href=&quot;http://ojensen.files.wordpress.com/2010/08/time_numpy_sympy.png&quot;&gt;&lt;img src=&quot;http://ojensen.files.wordpress.com/2010/08/time_numpy_sympy.png?w=450&quot; title=&quot;Scaling of execution time for Numpy and Sympy&quot; height=&quot;343.5&quot; width=&quot;450&quot; alt=&quot;Execution time scaling for increasing expression complexity, Numpy and Sympy&quot; class=&quot;size-medium wp-image-354 &quot; /&gt;&lt;/a&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Normalized execution time for Numpy and Sympy.  As n increases, the complexity of the  wave function expression increases, leading to the slowdown.  The values of each curve are normalized against the corresponding n=1 calculation.&lt;/p&gt;&lt;/div&gt;
&lt;p&gt;For higher &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n&quot; class=&quot;latex&quot; title=&quot;n&quot; /&gt; the wave function expressions increase in complexity, and so does the execution time of both Numpy and Sympy.  However, while the autowrapped Sympy expression needs 3 times longer for &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n+%3D+7&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n = 7&quot; class=&quot;latex&quot; title=&quot;n = 7&quot; /&gt; than for &lt;img src=&quot;http://l.wordpress.com/latex.php?latex=n+%3D+1&amp;amp;bg=ffffff&amp;amp;fg=000&amp;amp;s=0&quot; alt=&quot;n = 1&quot; class=&quot;latex&quot; title=&quot;n = 1&quot; /&gt;, the execution time for a lambda of native Numpy ufuncs increases tenfold!&lt;/p&gt;
&lt;div style=&quot;width: 460px;&quot; id=&quot;attachment_346&quot; class=&quot;wp-caption aligncenter&quot;&gt;&lt;a href=&quot;http://ojensen.files.wordpress.com/2010/08/numpy_sympy.png&quot;&gt;&lt;img src=&quot;http://ojensen.files.wordpress.com/2010/08/numpy_sympy.png?w=450&quot; title=&quot;numpy_sympy&quot; height=&quot;343.5&quot; width=&quot;450&quot; alt=&quot;Plot of Numpy vs. Sympy execution time&quot; class=&quot;size-medium wp-image-346 &quot; /&gt;&lt;/a&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Numpy execution time vs. Sympy.  The mostly linear relation means that Numpy and Sympy have similar dependence on the complexity of the expression, although the scaling factors are quite different.&lt;/p&gt;&lt;/div&gt;
&lt;p&gt;This last figure shows the linear relation between execution times of the compiled Sympy expressions and native Numpy lambda function.   The plot supports the idea that the it is the inherent complexity of the mathematical expression that determines the execution time.  By extrapolation, we can expect that for an expression that would take Sympy 9 times longer, Numpy would be hit by a factor of 100.&lt;/p&gt;
&lt;p&gt;The main reason for the speedup, is that while Numpy calculates the wave function by applying a series of ufuncs, the Sympy way is to create a new “ufunc” and apply it once.  It would be very cool to try this in an iterative solution scheme. With a super fast ufunc in a single python loop, one could do complex and cpu-intensive calculations with respectable performance from within isympy.  That would be awesome!&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/ojensen.wordpress.com/250/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/ojensen.wordpress.com/250/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=ojensen.wordpress.com&amp;amp;blog=13891021&amp;amp;post=250&amp;amp;subd=ojensen&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-08-10T10:14:38+00:00</dc:date>
	<dc:creator>jegerjensen</dc:creator>
</item>
<item rdf:about="http://ojensen.wordpress.com/?p=219">
	<title>Øyvind Jensen: Good news, everyone!</title>
	<link>http://ojensen.wordpress.com/2010/08/08/good-news-everyone/</link>
	<content:encoded>&lt;p&gt;This week has been hectic, but also very fruitful.  I have the functionality I set out for, it works and it is fast!  It still needs testing, polish and bug-fixing and is by no means finished, but it is now possible to define indexed math-expressions, translate to code, compile it, wrap it as a python module and import it again for fast numerical calculations.  All of this can be done without leaving the isympy command interpreter.&lt;/p&gt;
&lt;p&gt;I’ve been hacking on the automatic wrapping of binary routines, refactored the code printers, implemented handling of indexed powers, enabled scalar broadcasting and &lt;a href=&quot;http://docs.scipy.org/doc/numpy/reference/ufuncs.html&quot;&gt;ufunc&lt;/a&gt;-ish  support for arbitrary compiled functions.   For next week I will focus on physics inspired examples, testing of binary code and improving the documentation.  But first, it is time for a little demonstration.&lt;/p&gt;
&lt;p&gt;The latest code is &lt;a href=&quot;http://github.com/jegerjensen/sympy/tree/autowrap3&quot;&gt;here&lt;/a&gt;, if you want to try for yourself.   There are parts that don’t not work properly, for instance the  Cython wrapper cannot handle numpy arrays yet, but as you will see below there are enough working parts that you can do some fancy stuff.&lt;/p&gt;
&lt;h3&gt;The trace of a Matrix — faster that numpy!&lt;/h3&gt;
&lt;p&gt;In an earlier blog post, I showed you that the C printer is able to print the necessary loops to implement summations over array indices.  The Fortran printer has also this functionality now, so it can be used with f2py.  Let’s start with a simple function to calculate numerically the trace of a matrix while running isympy:&lt;/p&gt;
&lt;pre&gt;In [1]: from sympy.utilities.autowrap import autowrap
In [2]: m, n = symbols('m n', integer=True)
In [3]: i = Idx('i', m)
In [4]: j = Idx('j', n)
In [5]: A = IndexedBase('A')
In [6]: trace = autowrap(A[i, i])&lt;/pre&gt;
&lt;p&gt;That’s it.  Now lets have a look at the function we created,&lt;/p&gt;
&lt;pre&gt;In [7]: trace?
Type:        fortran
String Form:    &amp;lt;fortran object at 0xa93bea8&amp;gt;
Namespace:    Interactive
Docstring:
 autofunc - Function signature:
 autofunc = autofunc(a,[m])
 Required arguments:
 a : input rank-2 array('d') with bounds (m,m)
 Optional arguments:
 m := shape(a,0) input int
 Return objects:
 autofunc : float&lt;/pre&gt;
&lt;p&gt;This informative docstring is created by f2py, and only slightly distorted by the blogging software.  It tells us everything we need to know.  Let’s try this function on a numpy array:&lt;/p&gt;
&lt;pre&gt;In [8]: import numpy as np
In [9]: I = np.asarray(np.eye(1000), order='F')
In [10]: trace(I)
Out[10]: 1000.0
In [11]: timeit trace(I)
10000 loops, best of 3: 30.3 us per loop
In [12]: np.trace(I)
Out[12]: 1000.0
In [13]: timeit np.trace(I)
1000 loops, best of 3: 230 us per loop&lt;/pre&gt;
&lt;p&gt;First of all, please notice the parameter “order=’F'” passed to the numpy array.  This ensures that the array is created with column-major memory order which is the Fortran format.  Without that, the array is created with row-major order, and our Fortran function would run much, much slower.&lt;/p&gt;
&lt;p&gt;Now to the fun part: Did you notice the speedup?  The Sympy generated function is almost a factor of 8 faster that numpy!  This is great, and I think I can be really happy about this result.  But it is also time for a little warning: Please don’t take these numbers as some sort of absolute truth.  For all I know I may be comparing apples and oranges.&lt;/p&gt;
&lt;p&gt;In fact, the numbers I present are probably more relevant for a comparison of  compilers and optimization flags.  But, whatever the reason for the  speedups, faster python callable functions is no doubt a good thing.   For the record: I am running this on a little Acer Aspire One using numpy 1.3.0 shipped with Ubuntu 10.04.  The autowrapped binaries are compiled with Ubuntu’s gfortran 4.4.3.&lt;/p&gt;
&lt;h3&gt;Matrix-Matrix product&lt;/h3&gt;
&lt;p&gt;Now lets look at a more expensive array operation.  Whereas the trace of an m*m matrix has a cost of order O(m), the product of two m*m matrices scales like O(m^3).  First we need to express a matrix-matrix product in terms of Indexed Sympy objects and create the binary function.&lt;/p&gt;
&lt;pre&gt;In [14]: B = IndexedBase('B')
In [15]: C = IndexedBase('C')
In [16]: o = symbols('o', integer=True)
In [17]: k = Idx('k', o)
In [18]: expr_mat_mat = Eq(C[i, j], A[i, k]*B[k, j]); expr_mat_mat
Out[18]: C[i, j] = A[i, k]⋅B[k, j]&lt;/pre&gt;
&lt;p&gt;The matrix-matrix product displayed at Out[18] is defined in terms of an Equality instance.  This is a handy way to provide the code printers with both an expression and the variable it should be assigned to.  For indexed expressions it is important that the indices on left hand side and right hand side are compatible.  (Compatible means usually that the set of non-dummy indices must be identical, but with the exception that the right hand side can be scalar.)  For the binary function, we get:&lt;/p&gt;
&lt;pre&gt;In [19]: matmat = autowrap(expr_mat_mat)
In [20]: matmat?
Type:        fortran
String Form:    &amp;lt;fortran object at 0x8f35290&amp;gt;
Namespace:    Interactive
Docstring:
 autofunc - Function signature:
 c = autofunc(a,b,[m,n,o])
 Required arguments:
 a : input rank-2 array('d') with bounds (m,o)
 b : input rank-2 array('d') with bounds (o,n)
 Optional arguments:
 m := shape(a,0) input int
 n := shape(b,1) input int
 o := shape(a,1) input int
 Return objects:
 c : rank-2 array('d') with bounds (m,n)&lt;/pre&gt;
&lt;p&gt;Now let’s test it with a QR factorization on some numpy arrays:&lt;/p&gt;
&lt;pre&gt;In [21]: M = np.asarray(np.random.rand(100, 100), order='F')
In [22]: Q, R = np.linalg.qr(M)
In [23]: M_np = np.dot(Q, R)
In [24]: M_my = matmat(Q, R)
In [25]: np.linalg.norm(M_my - M_np)
Out[25]: 1.7522660836e-14&lt;/pre&gt;
&lt;p&gt;Here is the timing:&lt;/p&gt;
&lt;pre&gt;In [26]: %timeit M_np = np.dot(Q, R)
100 loops, best of 3: 10.9 ms per loop
In [27]: %timeit M_my = matmat(Q, R)
100 loops, best of 3: 6.11 ms per loop&lt;/pre&gt;
&lt;p&gt;This looks impressive! But, I also found that numpy has a much better scaling than what I get from autowrap on this computer:&lt;/p&gt;
&lt;pre&gt;In [53]: M = np.asarray(np.random.rand(400, 400), order='F')
In [54]: Q, R = np.linalg.qr(M)
In [55]: %timeit M_np = np.dot(Q, R)
1 loops, best of 3: 687 ms per loop
In [56]: %timeit M_my = matmat(Q, R)
1 loops, best of 3: 1.65 s per loop&lt;/pre&gt;
&lt;p&gt;I believe that this bad scaling must be an issue with gfortran, or rather an issue with how I use it.  The theoretical scaling of O(m^3) correspond to a factor of 64, and while numpy follows theory quite closely, (687/10.9=63.0) the autowrapped function misses by far. (1650/6.11=270) .  On another computer, I tested the same calculations with Intels ifort compiler and got much better results that were consistently better than numpy and had the expected scaling.&lt;/p&gt;
&lt;p&gt;I have more things I want to show, but this blog post is becoming rather long, so stay tuned for more exciting new functionality in the coming days.&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/ojensen.wordpress.com/219/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/ojensen.wordpress.com/219/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=ojensen.wordpress.com&amp;amp;blog=13891021&amp;amp;post=219&amp;amp;subd=ojensen&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-08-08T14:33:30+00:00</dc:date>
	<dc:creator>jegerjensen</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-22566012.post-4683860477825075771">
	<title>Christian Muise: SoC Wrap-up</title>
	<link>http://haz-tech.blogspot.com/2010/08/soc-wrap-up.html</link>
	<content:encoded>&lt;a href=&quot;http://socghop.appspot.com/gsoc/student_project/show/google/gsoc2010/python/t127230762878&quot;&gt;Supercharging SymPy's Assumptions&lt;/a&gt; -- that was the task for my SoC project this year. So how far has it come? Well there were three substantial pushes I'll outline here:&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;i&gt;Removal of Old Assumptions&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;  By a decent margin, this was the most time consuming task, and likely the one that will see the least contribution to SymPy's code-base. The conversation as to how best strip out SymPy's old assumptions continues, and my foray into the mess can be found in [&lt;a href=&quot;http://github.com/haz/sympy/tree/disconnect-assumptions&quot;&gt;these&lt;/a&gt;] [&lt;a href=&quot;http://github.com/haz/sympy/tree/disconnect-assumptions-2&quot;&gt;two&lt;/a&gt;] branches (the latter being the most recent and promising).&lt;br /&gt;&lt;br /&gt;  Despite the possibility of this code not making it into the trunk, this task served as a vital in-depth introduction to the SymPy system as a whole, and gave me a far greater understanding of SymPy in general than I could have hoped by simply browsing the code-base. It also brought some of the issues with the assumption system to the forefront for discussion, which will hopefully continue beyond the bounds of the SoC timeline.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;i&gt;SAT Solver&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;  Probably the most effective use of my skills, I implemented a new SAT Solver from the ground up for SymPy. It's got an &lt;a href=&quot;http://haz-tech.blogspot.com/2010/07/clause-learning-and-heuristics.html&quot;&gt;effective heuristic&lt;/a&gt;, the &lt;a href=&quot;http://haz-tech.blogspot.com/2010/07/clause-learning-flunk.html&quot;&gt;ground work&lt;/a&gt; for clause learning, and advanced SAT solver &lt;a href=&quot;http://haz-tech.blogspot.com/2010/08/whos-watching-watch-literals.html&quot;&gt;data structures&lt;/a&gt;. I've spent a fair bit talking about this on the blog already, so I won't go into further detail here. But [&lt;a href=&quot;http://github.com/haz/sympy/tree/sat-solver&quot;&gt;this&lt;/a&gt;] is the branch, and here's how it stacks up against the old DPLL solver (note that the y-axis is log scale):&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; href=&quot;http://4.bp.blogspot.com/_DvrW_QLstcQ/TF3S_KdyDJI/AAAAAAAACLU/9qhiJV4q0CM/s1600/dpll.png&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_DvrW_QLstcQ/TF3S_KdyDJI/AAAAAAAACLU/9qhiJV4q0CM/s400/dpll.png&quot; height=&quot;318&quot; border=&quot;0&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;i&gt;Knowledge Compilation&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;  This here is a fuzzy term used to describe pre-computation that helps in online queries. There's a large body of research when considering queries in boolean logic, and I've had some experience dealing with such things. In fact, [&lt;a href=&quot;http://github.com/sympy/sympy/blob/master/sympy/assumptions/ask.py#L214&quot;&gt;this line&lt;/a&gt;] in SymPy could be considered something along the lines of knowledge compilation for the assumption system -- it pre-computes the CNF of the known rules so that queries to the &lt;b&gt;ask&lt;/b&gt; function don't need to compile them every time for the logical inference.&lt;br /&gt;&lt;br /&gt;  Well we can take this a step further. And that's precisely what [&lt;a href=&quot;http://github.com/haz/sympy/tree/atms&quot;&gt;this&lt;/a&gt;] branch does. One thing it does is [&lt;a href=&quot;http://github.com/haz/sympy/blob/atms/sympy/assumptions/ask.py#L253&quot;&gt;explicitly store&lt;/a&gt;] the CNF so it's not computed at import time. This is accomplished by copying the output of [&lt;a href=&quot;http://github.com/haz/sympy/blob/atms/sympy/assumptions/ask.py#L180&quot;&gt;this function&lt;/a&gt;] to the ask.py file. So now we have a simple CNF ready to go whenever the SAT solver is invoked to answer an &lt;b&gt;ask&lt;/b&gt; query.&lt;br /&gt;&lt;br /&gt;  Beyond this simple compilation, there is more we can do to completely avoid calling the SAT solver -- if we can answer the query quickly, there's no sense in calling the full DPLL algorithm. This is accomplished by pre-computing all of the implications from single assumptions -- see [&lt;a href=&quot;http://github.com/haz/sympy/blob/atms/sympy/assumptions/ask.py#L280&quot;&gt;this dictionary&lt;/a&gt;]. An entry such as '&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;font-weight: bold; line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;n&quot;&gt;imaginary&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;color: #0086b3; line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;font-weight: bold; line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;n&quot;&gt;complex&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt; &lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;font-weight: bold; line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;n&quot;&gt;imaginary&lt;/span&gt;&lt;/span&gt;&lt;span style=&quot;font-family: 'Bitstream Vera Sans Mono', Courier, monospace; font-size: 12px; line-height: 17px; white-space: pre;&quot; class=&quot;Apple-style-span&quot;&gt;&lt;span style=&quot;line-height: 1.4em; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px;&quot; class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/span&gt;' should be read as, &quot;If we know it's imaginary, then we know it must be complex and it must be imaginary&quot;.&lt;br /&gt;&lt;br /&gt;  Simple, I know, but it saves us from calling a sat solver simply to find out that a variable is imaginary if we assume it's imaginary ;). Well maybe that would be captured by [&lt;a href=&quot;http://github.com/haz/sympy/blob/atms/sympy/assumptions/ask.py#L101&quot;&gt;this line&lt;/a&gt;], but successive implications are all compiled down, so this does save you a fair bit. How much? Well running 'bin/test sympy/assumptions' on the trunk calls the SAT Solver 811 times while this branch cuts it down to a mere 258. Granted we now have a faster SAT solver, but why use such a big hammer when the query is simple?&lt;br /&gt;&lt;br /&gt;  The method also captures things like ask(x, Q.imaginary, Assume(x, Q.complex, False)) -- if Q.imaginary was true, then Q.complex must be true (because of the lookup we pre-compiled), and since we know this isn't the case, we can conclude that x is not imaginary as well. How are these facts compiled? Well we do the exhaustive checks with the SAT solver ([&lt;a href=&quot;http://github.com/haz/sympy/blob/atms/sympy/assumptions/ask.py#L195&quot;&gt;this line&lt;/a&gt;]), and dump the results just like the pre-computed CNF.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;  So these were the dives into SymPy this summer. As I mentioned earlier, the first may not see the light of day (in the SymPy trunk), but the second two have been merged to a unified branch, [&lt;a href=&quot;http://github.com/haz/sympy/tree/soc-final&quot;&gt;here&lt;/a&gt;]. It's been rebased on top of the current SymPy trunk, and is ready to go for testing / tampering. I'll be sending it around to the sympy-patches list, and putting notes of it up on the relevant issues. Hopefully by the firm pencil down date (August 16th), it'll be in shape for inclusion to the SymPy core. So please play with it, and let me know what you think.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;i&gt;???&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;&lt;ol&gt;&lt;li&gt;The concern of caching everything (in the presence of assumptions) came up for the removal of old assumptions. One thought was to disable caching altogether, but it seems vital for the efficiency in some of the more advanced features of SymPy (integral calculation, etc). But would happen if we enable the cache as soon as a SymPy call is made, and disable / flush it when the computation is done? This would allow things to be cached within a single computation, but since assumptions don't change mid-way, we would avoid any bad-cache hits. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Do [&lt;a href=&quot;http://github.com/haz/sympy/blob/atms/sympy/assumptions/ask.py#L280&quot;&gt;these rules&lt;/a&gt;] all make sense? They look good to me, but like anything pre-compiled they should have some more eyes on them ;). &lt;br /&gt;&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Assume(x &amp;gt; 1) is a missing puzzle piece thus far. Since &lt;b&gt;ask&lt;/b&gt; can be called with any arbitrary expression (which is subsequently decomposed), this becomes increasingly more difficult to figure out. At a high level we want to be able to compute all of the primitive assumptions (ie. Predicates) for an expression, given a more complex expression. So for ask(x, Q.whatever, Assume(x &amp;gt; 0)), we would ask the Gt class to answer things such as, &quot;is x Q.positive?&quot; which would return True iff &quot;0 is nonnegative&quot;. But this is just a specific case, and like I mentioned things get complicated with complex assumptions on more than one variable. How do we get from here to there?  &lt;br /&gt;&lt;br /&gt;(&lt;b&gt;Note&lt;/b&gt;: &lt;i&gt;This wasn't really part of the SoC plan, but I don't intend on stopping work on the assumptions after next week.&lt;/i&gt;) &lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/22566012-4683860477825075771?l=haz-tech.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-07T22:38:49+00:00</dc:date>
	<dc:creator>Haz</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9135222751616024074.post-8172338055248531834">
	<title>Matthew Curry: Nearing the End</title>
	<link>http://mattjcurry.blogspot.com/2010/08/nearing-end.html</link>
	<content:encoded>Well there's only a week left in GSoC, and plenty of coding left to do. We're supposed to focus on bug fixing and documentation only next week.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;It is definitely true that my project became more and more of a bear conceptually as I continued on. Right now we are subclassing sympy's Mul, Add, and Pow classes in order to circumvent any sort of non-commutative/validation/operator problems. We've definitely found a way to avoid most/all of the design issues that I was faced with a few weeks back. Overall, I think a very respectable version of symbolic quantum mechanics (with a quantum  computing example) will be ready by the end.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This last week, we made a lot of progress on QMul, QAdd and QPow. I mainly observed that as we added more and more degrees of freedom (more code), more bugs and weird errors arose. I helped fix a few of these bugs including one today in which Bra('a')*Operator('b') was returning only Bra('a'). The fix was really simple (changing one line), but finding it was much more difficult. It was a good experience because I used more advance forms of debugging that I had previously not needed before.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Next week I'll write some tests and debug more. Things will start winding down and my project will be done soon enough :)&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/9135222751616024074-8172338055248531834?l=mattjcurry.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-07T19:16:42+00:00</dc:date>
	<dc:creator>mcurry</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-22566012.post-6375375338891344793">
	<title>Christian Muise: Who's Watching the Watch Literals?</title>
	<link>http://haz-tech.blogspot.com/2010/08/whos-watching-watch-literals.html</link>
	<content:encoded>**Yes, I just made a bad &lt;a href=&quot;http://www.imdb.com/title/tt0409459/&quot;&gt;Watchmen&lt;/a&gt; joke, and no I haven't seen the movie yet ;).**&lt;br /&gt;&lt;br /&gt;  So far we have seen how the general &lt;a href=&quot;http://haz-tech.blogspot.com/2010/07/davis-putnam-logemann-loveland.html&quot;&gt;DPLL procedure&lt;/a&gt; works, along with &lt;a href=&quot;http://haz-tech.blogspot.com/2010/07/clause-learning-and-heuristics.html&quot;&gt;clause learning and a fancy heuristic&lt;/a&gt;. If we were to profile the solver, we'd find that most of the time at this point is spent doing unit propagation -- especially when we start adding clauses, unit prop triggers constantly. So that is precisely what &lt;i&gt;watch literals&lt;/i&gt; are used to speed up.&lt;br /&gt;&lt;br /&gt;  The concept of watch literals was born out of a realization as to when exactly a clause is unit-prop'd -- this happens when every literal but one in a clause is set the wrong way. For a while solvers tried just counting the number of literals left to be set in a clause that isn't satisfied, and whenever this went from 2 to 1, you know it's time for unit propagation. Well since we only really care about that specific point (going from two unset literals to one), we will explicitly keep track of those two -- they are our watch literals.&lt;br /&gt;&lt;br /&gt;  Every clause that remains to be satisfied will have two watch literals associated with it. But the clause doesn't store this information, those literals do. So instead of keeping track of which clauses are yet to be satisfied, we keep a list of clauses for each literal such that the literal is one of the two watch literals assigned to that clause. And what happens when we set a variable? Well we only need to look at the clauses that the literal's negation is watching, and pick a new watch literal for that clause. An example:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Say we have the clause (x | y | z) and x / y are being watched.&lt;/li&gt;&lt;li&gt;If z was set (regardless of direction), we don't need to do anything for this clause -- not even consider whether or not we should do anything (since updating clauses is done by enumerating z's watch literals).&lt;/li&gt;&lt;li&gt;Say on the other hand that we set y = False instead of z. Well this clause has y as a watch literal so we would find a new watch literal to replace y -- namely z. After storing a pointer to this clause in the watch literal list for z, we continue with the search.&lt;/li&gt;&lt;li&gt;Now assume z was set to False. Again, we would check out this clause since z was a watch literal, but this time find that we can no longer find an alternative -- this triggers unit propagation.&lt;/li&gt;&lt;/ul&gt;  So now the clause is satisfied, but what happens to our watch literals? This is the beautiful part -- nothing. Sure, if x is set False later on, we'll check the clause again, but we only update watch literals when the clause isn't satisfied (quick linear time check to see if a clause is satisfied).&lt;br /&gt;&lt;br /&gt;  But what happens when we backtrack past the decisions for y and z? This is the /really/ beautiful part -- nothing again. The clause will go from being satisfied to unsatisfied (but we aren't keeping a flag for this anymore -- remember that satisfiability of a clause is a linear time check), but we still have two watch literals set (x and z). Sure, these are different watch literals than what we started with (namely x and y), but that's perfectly ok, and it's unbelievably fast -- all because backtracking doesn't need to update any of the watch literals.&lt;br /&gt;&lt;br /&gt;  So that's basically it. Implementing things to work properly isn't the easiest (I've failed a few times before taking up the SoC project this year), but boy oh boy does it ever pay off (see the latter part of &lt;a href=&quot;http://haz-tech.blogspot.com/2010/07/clause-learning-flunk.html&quot;&gt;this post&lt;/a&gt;). So have watch literals gone in to SymPy yet? &lt;a href=&quot;http://github.com/haz/sympy/commit/a4facd8d6d94f54c0fbea48806b7858bc82d99bb&quot;&gt;You bet&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;  That wraps up the series of SAT solving tutorials. I haven't covered everything that went into &lt;a href=&quot;http://github.com/haz/sympy/tree/sat-solver&quot;&gt;this branch&lt;/a&gt;, but I did touch on all the important points. I haven't come close to covering everything that goes into modern SAT solvers, but if you're interested, the &lt;a href=&quot;http://www.satisfiability.org/&quot;&gt;Conference on Satisfiability&lt;/a&gt; would be a great place to start ;). Thanks for following along, and stay tuned for some further Assumption tweaks.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/22566012-6375375338891344793?l=haz-tech.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-07T04:25:17+00:00</dc:date>
	<dc:creator>Haz</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-6568744196982634289.post-2896505029722157566">
	<title>Ond&amp;#345;ej &amp;#268;ert&amp;iacute;k: Week Aug 2 - 6</title>
	<link>http://ondrejcertik.blogspot.com/2010/08/week-aug-2-6.html</link>
	<content:encoded>This week I essentially only worked on my LLNL poster, which I finally finished about two hours ago. I have created a web page for it:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://certik.github.com/ccms-10-poster/&quot;&gt;http://certik.github.com/ccms-10-poster/&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;where you can download pdf, sources, I also put there some relevant info and links.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;It turned out to be a lot more work than I expected (well, as usual), but we were very thorough with John and in the process I discovered several bugs in my program, so I am glad we did it. I used to generate all the plots by hand, by manually adjusting all the parameters in the Python script (like atomic number, mesh parameters, element orders, adaptivity parameters, error tolerance and so on). Essentially I had to remember all these parameters for each of the plots (about 10 of them). Then I settled to have a Python dictionary, that holds all the parameters, and then I just pass them to a radial_schroedinger_equation_adapt(params, error_tol=1e-8) function.&lt;br /&gt;&lt;br /&gt;Here are example of the parameters:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;    params_hydrogen_p_L = dict(l=0, Z=1, a=0, b=100, el_num=4, el_order=1,&lt;br /&gt;            eig_num=3, mesh_uniform=False, mesh_par1=20, adapt_type=&quot;p&quot;,&lt;br /&gt;            eqn_type=&quot;R&quot;)&lt;br /&gt;    params_hydrogen_p_U = dict(l=0, Z=1, a=0, b=100, el_num=4, el_order=2,&lt;br /&gt;            eig_num=3, mesh_uniform=True, adapt_type=&quot;p&quot;, eqn_type=&quot;R&quot;)&lt;br /&gt;    params_hydrogen_hp_U = dict(l=0, Z=1, a=0, b=100, el_num=4, el_order=2,&lt;br /&gt;            eig_num=3, mesh_uniform=True, adapt_type=&quot;hp&quot;, eqn_type=&quot;R&quot;)&lt;br /&gt;    params_hydrogen_h_U = dict(l=0, Z=1, a=0, b=100, el_num=4, el_order=6,&lt;br /&gt;            eig_num=3, mesh_uniform=True, adapt_type=&quot;romanowski&quot;,&lt;br /&gt;            eqn_type=&quot;rR&quot;)&lt;br /&gt;&lt;br /&gt;    params_silver_p_L = dict(l=0, Z=47, a=0, b=150, el_num=4, el_order=13,&lt;br /&gt;            eig_num=50, mesh_uniform=False, mesh_par1=35, adapt_type=&quot;p&quot;,&lt;br /&gt;            eqn_type=&quot;R&quot;)&lt;br /&gt;    params_silver_hp_L = dict(l=0, Z=47, a=0, b=150, el_num=4, el_order=13,&lt;br /&gt;            eig_num=50, mesh_uniform=False, mesh_par1=35, adapt_type=&quot;hp&quot;,&lt;br /&gt;            eqn_type=&quot;R&quot;)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;I mean, this is kind of obvious if you think about it, but for some reason I didn't do that at all at the beginning, because I thought --- I'll just run this once and I am done with it. But I had to run it like 20x, e.g. regenerating he plots, then creating a table about meshes, then redoing the table after changing the error tolerance, and so on.&lt;br /&gt;&lt;br /&gt;Besides that I also got permission to release my code, so I'll go over it in the coming days and generate nice patches against Hermes1D.&lt;br /&gt;&lt;br /&gt;Also in the process of creating the poster, I played a lot with p-FEM, uniform-p-FEM, hp-FEM and h-FEM and I will keep playing with that. It's clear to me now, that our current Hermes1D is not optimal. Especially the convergence of hp-FEM and p-FEM (as it is implemented right now) greatly depends on the initial mesh.&lt;br /&gt;&lt;br /&gt;Nevertheless, even with the above limitations, hp-FEM seems to be really good if you don't a-priori know anything about the problem/mesh. One should not make any deep conclusions in 1D (it might be a bit different in 2D and 3D, and also I only did couple test problems), but from my experience so far, hp-FEM is a really good choice, if you just want to solve the problem and get a decent convergence (way better than h-FEM, and in general about the same as uniform-p-FEM with optimized mesh).&lt;br /&gt;&lt;br /&gt;Another conclusion is that uniform-p-FEM (also called spectral element method), if you optimize the mesh for the problem, is very fast. All you have to do is increase the polynomial order and it goes very straight on the convergence graphs, it's very hard to beat. Also, and that I would like to write in the coming days, the algorithm for optimizing the mesh is really simple: just solve it with high &quot;p&quot;, then play with the mesh parameters (for logarithmic mesh, there are only 2 parameters --- number of elements, and a ratio of first vs. last element), so that the eigenvalues (that one is interested in) are converged (with given accuracy) and optimize it wrt DOFs. The algorithm can also &quot;look&quot; at the convergence graphs and make sure it's steep enough. For atomic problems, my experience shows that the logarithmic mesh is good enough (as long as you optimize it). The advantage is that you do this once, and then (for close enough potentials in the Schroedinger equation), you just increase &quot;p&quot;, and it's very robust and fast (no need for reference mesh, or trial refinements and so on).&lt;br /&gt;&lt;br /&gt;When I get back to Reno, we'll do more research on hp-FEM with Pavel and I think this is not the last word to say. We need to review how we choose the candidates for eigenvectors, especially &quot;p&quot; vs &quot;hp&quot; and make it more robust. We'll see.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/6568744196982634289-2896505029722157566?l=ondrejcertik.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-07T01:27:19+00:00</dc:date>
	<dc:creator>Ondřej Čertík</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-936818886435977143.post-8445992689514487932">
	<title>Addison Cugini: QMul, QAdd, and QPow</title>
	<link>http://addisoncugini.blogspot.com/2010/08/qmul-qadd-and-qpow.html</link>
	<content:encoded>My time this week has been spent working on Matt's project. In my last post, I mentioned how there was difficulty teaching the code to adhere to special quantum rules as the quantum objects get swallowed up inside Mul, Add and Pow objects. In order to remedy this, I needed to create a new set of binary operation classes that adhere to these rules with the same op-priority as other quantum objects.&lt;br /&gt;&lt;br /&gt;To do this, I put logic inside the binary-ops' __new__ method which called a set of logic rules. These rules return an instance of the correct object if an object should be created or raise an error if the input expression is nonesense. For this to work, binary-op objects must know to what quantum type they evaluate (e.g. to what Hilbert space they belong as well as whether they act as a Ket, Bra, or Operator when evaluated). Thus, I used __slots__ to contain 'hilbert_space' and 'evaluates' attributes; these attributes are set during initialization in the 'rules' class methods. To make this simpler, all Quantum Objects inherit from a QuantumBasic class which contains the op_priority information, __slots__ for 'hilbert_space' and 'evaluates', as well as the __mul__, __add__, __pow__ methods which call the __new__ method of our new binary operations.&lt;br /&gt;&lt;br /&gt;I mostly have this logic working such that it can flatten non-commutatively for QMul and commutatively for QAdd. However, I still need to get the .expand() method up and working. That said, there is still much testing that needs to be done before I can get this integrated with my code, which makes me worried as the GSoC pencil down date fast approaches.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/936818886435977143-8445992689514487932?l=addisoncugini.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-06T20:57:09+00:00</dc:date>
	<dc:creator>AddisonCugini</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=710">
	<title>Aaron Meurer: Prototype risch_integrate() function ready for testing!</title>
	<link>http://asmeurersympy.wordpress.com/2010/08/05/prototype-risch_integrate-function-ready-for-testing/</link>
	<content:encoded>&lt;p&gt;So today I finally finished up the prototype function I talked about &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/31/integration-of-primitive-functions/&quot;&gt;last week&lt;/a&gt;.  The function is called &lt;code&gt;risch_integrate()&lt;/code&gt; and is available at my &lt;a href=&quot;http://github.com/asmeurer/sympy/tree/integration3&quot;&gt;integration3&lt;/a&gt; branch.  Unlike the inner level functions I have showcased in &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/31/integration-of-primitive-functions/&quot;&gt;previous&lt;/a&gt; &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;blog posts&lt;/a&gt;, this function does not require you to do substitution for dummy variables and manually create a list of derivatives, etc.  All you have to do is pass it a function and the integration variable, and it will return the result, just like normal &lt;code&gt;integrate()&lt;/code&gt;. I have spent the past few days working on a monster of a function called &lt;code&gt;build_extension()&lt;/code&gt; that does this preparsing work for you.  The reason that the function was so hard to write is that the transcendental Risch Algorithm is very picky.  &lt;em&gt;Every&lt;/em&gt; differential extension has to be transcendental over the previous extensions.  This means that if you have a function like &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex+%2B+e%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x + e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;e^x + e^{\frac{x}{2}}&quot; /&gt;, you cannot write this as &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0+%2B+t_1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0 + t_1&quot; class=&quot;latex&quot; title=&quot;t_0 + t_1&quot; /&gt; with &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^x&quot; class=&quot;latex&quot; title=&quot;t_0=e^x&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_1%3De%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_1=e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;t_1=e^{\frac{x}{2}}&quot; /&gt; because &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0&quot; class=&quot;latex&quot; title=&quot;t_0&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_1&quot; class=&quot;latex&quot; title=&quot;t_1&quot; /&gt; will each be algebraic over the other (&lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3Dt_1%5E2&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=t_1^2&quot; class=&quot;latex&quot; title=&quot;t_0=t_1^2&quot; /&gt;).  You also cannot let &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5E%7Bx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^{x}&quot; class=&quot;latex&quot; title=&quot;t_0=e^{x}&quot; /&gt; and rewrite the whole integral in terms of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0&quot; class=&quot;latex&quot; title=&quot;t_0&quot; /&gt; because you will get &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0+%2B+%5Csqrt%7Bt_0%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0 + \sqrt{t_0}&quot; class=&quot;latex&quot; title=&quot;t_0 + \sqrt{t_0}&quot; /&gt;, which is an algebraic function.  The only way that you can do it is to let &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;t_0=e^{\frac{x}{2}}&quot; /&gt;, and then your function will be &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%5E2+%2B+t_0&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0^2 + t_0&quot; class=&quot;latex&quot; title=&quot;t_0^2 + t_0&quot; /&gt;.  &lt;/p&gt;
&lt;p&gt;Now, fortunately, there is an algorithm that provides necessary and sufficient conditions for determining if an extension is algebraic over the previous ones.  It’s called the Risch Structure Theorems.  My first order of business this week was to finish implementing these.  This is actually the reason that I we had to wait until now to get this prototype function.  The Structure Theorems are at the very end of Bronstein’s book, and the integration algorithm is not correct without them (namely, it is not correct if you add an algebraic extension).  I just recently got to them in my reading.  Actually, I skipped some work on tangent integration so I could get to them first.  I hope to talk a little about them in a future “Risch Integration” blog post, though be aware that they require some extremely intense algebraic machinery to prove, so I won’t be giving any proofs.&lt;/p&gt;
&lt;p&gt;Even though these algorithms can tell me, for example, that I shouldn’t have added &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^x&quot; class=&quot;latex&quot; title=&quot;t_0=e^x&quot; /&gt; above because it makes &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D%3D%5Csqrt%7Bt_0%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{\frac{x}{2}}=\sqrt{t_0}&quot; class=&quot;latex&quot; title=&quot;e^{\frac{x}{2}}=\sqrt{t_0}&quot; /&gt;, that means that I have to go back and restart my search for an extension so that I can try to get &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;t_0=e^{\frac{x}{2}}&quot; /&gt; instead.  So I wrote a simple function that takes the arguments of the exponentials and determines the lowest common factor.  This heuristic saves a lot of time.  &lt;/p&gt;
&lt;p&gt;I also noticed (actually, Chris Smith inadvertently pointed it out to me; super thanks to him), that the Structure Theorem algorithms only tell you if the terms are the same as monomials.  It would tell you that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex+%3D+e%5E%7Bx+%2B+1%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x = e^{x + 1}&quot; class=&quot;latex&quot; title=&quot;e^x = e^{x + 1}&quot; /&gt; because both satisfy &lt;img src=&quot;http://s0.wp.com/latex.php?latex=Dt%3Dt&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;Dt=t&quot; class=&quot;latex&quot; title=&quot;Dt=t&quot; /&gt;.  Therefore, I had to also modify the structure theorem algorithms to pull out any constant term.  &lt;/p&gt;
&lt;p&gt;It can still be necessary to restart building the extension even with the above heuristic.  For example, if you have &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex+%2B+e%5E%7Bx%5E2%7D+%2B+e%5E%7B%5Cfrac%7Bx%7D%7B2%7D+%2B+x%5E2%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x + e^{x^2} + e^{\frac{x}{2} + x^2}&quot; class=&quot;latex&quot; title=&quot;e^x + e^{x^2} + e^{\frac{x}{2} + x^2}&quot; /&gt;, and start with &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^x&quot; class=&quot;latex&quot; title=&quot;t_0=e^x&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_1%3De%5E%7Bx%5E2%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_1=e^{x^2}&quot; class=&quot;latex&quot; title=&quot;t_1=e^{x^2}&quot; /&gt;, then the structure theorems will tell you that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7Bx%2F2+%2B+x%5E2%7D+%3D+%5Csqrt%7Bt_0%7Dt_1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{x/2 + x^2} = \sqrt{t_0}t_1&quot; class=&quot;latex&quot; title=&quot;e^{x/2 + x^2} = \sqrt{t_0}t_1&quot; /&gt;, which we cannot use because of the radical.  The solution it uses is to split it up as &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5Ex+%2B+e%5E%7Bx%5E2%7D+%2B+e%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7De%5E%7Bx%5E2%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^x + e^{x^2} + e^{\frac{x}{2}}e^{x^2}&quot; class=&quot;latex&quot; title=&quot;e^x + e^{x^2} + e^{\frac{x}{2}}e^{x^2}&quot; /&gt; (the structure theorems tell you exactly how to do this so you are splitting in terms of the other exponentials) and then restart the extension building entirely.  This can be an expensive operation, because you have to rebuild &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0&quot; class=&quot;latex&quot; title=&quot;t_0&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_1&quot; class=&quot;latex&quot; title=&quot;t_1&quot; /&gt;, but this time, the heuristic function I wrote from above handles the &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;e^{\frac{x}{2}}&quot; /&gt; correctly, making &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%3De%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0=e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;t_0=e^{\frac{x}{2}}&quot; /&gt;, with the final answer &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_0%5E2+%2B+t_1+%2B+t_0t_1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_0^2 + t_1 + t_0t_1&quot; class=&quot;latex&quot; title=&quot;t_0^2 + t_1 + t_0t_1&quot; /&gt;.  I could have probably made it smarter by only going back to before the conflicting extensions, but this was quite a bit more work, and adds more difficulties such as non-trivial relationships, so I just took the lazy way and restarted completely.  It doesn’t take &lt;em&gt;that&lt;/em&gt; much time.  &lt;/p&gt;
&lt;p&gt;Of course, sometimes, you cannot add a new exponential, no matter how you add the extensions.  The classic example is &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7B%5Cfrac%7B%5Clog%7B%28x%29%7D%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{\frac{\log{(x)}}{2}}&quot; class=&quot;latex&quot; title=&quot;e^{\frac{\log{(x)}}{2}}&quot; /&gt;, which you can see is actually equal to &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Csqrt%7Bx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\sqrt{x}&quot; class=&quot;latex&quot; title=&quot;\sqrt{x}&quot; /&gt;, an algebraic function.  Therefore, I had to implement some tricky logic to keep the &lt;code&gt;build_extension()&lt;/code&gt; function from trying again infinitely.  I hope I did it right, so that it never infinite loops, and never fails when it really can be done.  Only time and testing will tell.&lt;/p&gt;
&lt;p&gt;It is exactly the same for logarithms, except in that case, when a new logarithm is algebraic in terms of old ones, it can be written as a linear combination of them.  This means that there are never any radicals to worry about, though you do also have to worry about constants.  For example, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x)}&quot; class=&quot;latex&quot; title=&quot;\log{(x)}&quot; /&gt; looks the same as &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%282x%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(2x)}&quot; class=&quot;latex&quot; title=&quot;\log{(2x)}&quot; /&gt; because they both satisfy &lt;img src=&quot;http://s0.wp.com/latex.php?latex=Dt%3D%5Cfrac%7B1%7D%7Bx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;Dt=\frac{1}{x}&quot; class=&quot;latex&quot; title=&quot;Dt=\frac{1}{x}&quot; /&gt;.  An example of a logarithm that is algebraic over old ones is &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x%5E2+-+1%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x^2 - 1)}&quot; class=&quot;latex&quot; title=&quot;\log{(x^2 - 1)}&quot; /&gt; over &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x+%2B+1%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x + 1)}&quot; class=&quot;latex&quot; title=&quot;\log{(x + 1)}&quot; /&gt; and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x+-+1%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x - 1)}&quot; class=&quot;latex&quot; title=&quot;\log{(x - 1)}&quot; /&gt;, because &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x%5E2+-+1%29%7D%3D%5Clog%7B%28%28x+%2B+1%29%28x+-+1%29%29%7D%3D%5Clog%7B%28x+%2B+1%29%7D+%2B+%5Clog%7B%28x+-+1%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x^2 - 1)}=\log{((x + 1)(x - 1))}=\log{(x + 1)} + \log{(x - 1)}&quot; class=&quot;latex&quot; title=&quot;\log{(x^2 - 1)}=\log{((x + 1)(x - 1))}=\log{(x + 1)} + \log{(x - 1)}&quot; /&gt;.  &lt;/p&gt;
&lt;p&gt;The parallels between exponentials and logarithms are amazing.  For the structure theorems, the exponential case is exactly the same as the logarithmic case except replacing addition with multiplication and multiplication with exponentiation.  For the exponential case, you need the arguments of the already added logarithms to find the algebraic dependence, and the arguments of the already added exponentials to find the constant term.  For the logarithmic case, you need the arguments of the already added exponentials to find the algebraic dependence, and the arguments of the already added logarithms to find the content term. Everything else is exactly the same, except for the shift in operators.  Of course, I realize why these things are, mathematically, but the symmetry still amazing to me.  I will hopefully explain in more detail in my future Structure Theorems post.  &lt;/p&gt;
&lt;p&gt;So onto the &lt;code&gt;risch_integrate()&lt;/code&gt; function.  Here is the text that I have basically put in my &lt;a href=&quot;http://github.com/asmeurer/sympy/commit/e3cd5f18f86fd6377836f33f726182c8bd4dc1a0&quot;&gt;commit message&lt;/a&gt;, the &lt;a href=&quot;http://code.google.com/p/sympy/issues/detail?q=2010&quot;&gt;aptly numbered issue&lt;/a&gt; that I have created for it, and the &lt;a href=&quot;http://groups.google.com/group/sympy/browse_thread/thread/2464fa764f6f47aa&quot;&gt;post to the mailing list&lt;/a&gt; (it’s not so much that I am lazy as that I was really excited to get this out there).&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
I have ready in my integration3 branch a prototype risch_integrate() function that is a user-level function for the full Risch Algorithm I have been implementing this summer.  Pull from h&lt;a href=&quot;http://github.com/asmeurer/sympy/tree/integration3&quot;&gt;ttp://github.com/asmeurer/sympy/tree/integration3&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is NOT ready to go in.  It is a prototype function that I am making available so people can try out the new algorithm and hopefully help me to find the bugs in it.  Please pass it your favorite non-elementary integrals and see if it can determine that they are not elementary.  If you try to pass it a very crazy function at random, the chances are pretty high that it will not be elementary.  So a better way to test it is to come up with a crazy function, then differentiate it. Then pass the derivative and see if it can give you your original function back.  Note that it will probably not look exactly the same as your original function, and may differ by a constant.  You should verify by differentiating the result you get and calling cancel() (or simplify(), but usually cancel() is enough) on the difference.&lt;/p&gt;
&lt;p&gt;So you can review the code too, if you like, but just know that things are not stable yet, and this isn’t strictly a branch for review.  &lt;/p&gt;
&lt;p&gt;So far, this function only supports exponentials and logarithms.&lt;br /&gt;
Support for trigonometric functions is planned.  Algebraic functions are&lt;br /&gt;
not supported. If the function returns an unevaluated Integral, it means&lt;br /&gt;
that it has proven the integral to be non-elementary.  Note that several&lt;br /&gt;
cases are still not implemented, so you may get NotImplementedError&lt;br /&gt;
instead. Eventually, these will all be eliminated, and the only&lt;br /&gt;
NotImplementedError you should see from this function is&lt;br /&gt;
NotImplementedError(“Algebraic extensions are not supported.”)&lt;/p&gt;
&lt;p&gt;This function has not been integrated in any way with the already&lt;br /&gt;
existing integrate() yet, and you can use it to compare.&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [1]: risch_integrate(exp(x**2), x)
Out[1]:
⌠
⎮  ⎛ 2⎞
⎮  ⎝x ⎠
⎮ ℯ     dx
⌡

In [2]: risch_integrate(x**100*exp(x), x).diff(x)
Out[2]:
 100  x
x   ⋅ℯ

In [3]: %timeit risch_integrate(x**100*exp(x), x).diff(x)
1 loops, best of 3: 270 ms per loop

In [4]: integrate(x**100*exp(x), x)
... hangs ...

In [5]: risch_integrate(x/log(x), x)
Out[5]:
⌠
⎮   x
⎮ ────── dx
⎮ log(x)
⌡

In [6]: risch_integrate(log(x)**10, x).diff(x)
Out[6]:
   10
log  (x)

In [7]: integrate(log(x)**10, x).diff(x)
Out[7]:
   10
log  (x)

In [8]: %timeit risch_integrate(log(x)**10, x).diff(x)
10 loops, best of 3: 159 ms per loop

In [9]: %timeit integrate(log(x)**10, x).diff(x)
1 loops, best of 3: 2.35 s per loop
&lt;/pre&gt;
&lt;p&gt;Be warned that things are still very buggy and you should always verify&lt;br /&gt;
results by differentiating.  Usually, cancel(diff(result, x) – result)&lt;br /&gt;
should be enough.  This should go to 0.&lt;/p&gt;
&lt;p&gt;So please, please, PLEASE, try out this function and report any bugs that you find.  It is not necessary to report NotImplementedError bugs, because I already know about those (I put them in there), and as I mentioned above, they are all planned to disappear.  Also, I am continually updating my branch with fixes, so you should do a “git pull” and try again before you report anything.&lt;/p&gt;
&lt;p&gt;Also, I am aware that there are test failures.  This is because I had to hack exp._eval_subs() to only do exact substitution (no algebraic substitution).  It’s just a quick hack workaround, and I should eventually get a real fix.  &lt;/p&gt;
&lt;p&gt;Finally, I’m thinking there needs to be a way to differentiate between an unevaluated Integral because the integrator failed and an unevaluated Integral because it has proven the integral to be non-elementary.  Any ideas?
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Also, looking at the integral from the previous blog post, you can get the different results by using the &lt;code&gt;handle_log&lt;/code&gt; argument to &lt;code&gt;risch_integrate()&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;If &lt;code&gt;handle_first == 'log'&lt;/code&gt; (the default right now), then it will gather all logarithms first, and then exponentials (insomuch as it can do it in that order).  If &lt;code&gt;handle_first='exp'&lt;/code&gt;, it gathers exponentials first.  The difference is that the Risch Algorithm integrates recursively, one extension at a time, starting with the outer-most one. So if you have an expression with both logarithms and exponentials, such that they do not depend on each other, &lt;code&gt;handle_first == 'log'&lt;/code&gt; will integrate the exponentials first, because they will be gathered last (be at the top of the tower of extensions), and &lt;code&gt;handle_first == 'exp'&lt;/code&gt; will integrate the logarithms first.  Right now, I have defaulted to ‘log’ because the exponential integration algorithm is slightly more complete.  If you get &lt;code&gt;NotImplementedError&lt;/code&gt; with one, it is possible (though I don’t know for sure yet) that you might get an answer with the other.  &lt;/p&gt;
&lt;p&gt;Also, they can give different looking results, and at different speeds.  For example:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hover over the code and click on the left-most, “view source” icon (a paper icon with &lt;tt&gt;&amp;lt; &amp;gt;&lt;/tt&gt; over it) to view without breaks.  Opens in a new window.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [1]: f = (x*(x + 1)*((x**2*exp(2*x**2) - log(x + 1)**2)**2 +
   ...: 2*x*exp(3*x**2)*(x - (2*x**3 + 2*x**2 + x + 1)*log(x + 1))))/((x +
   ...: 1)*log(x + 1)**2 - (x**3 + x**2)*exp(2*x**2))**2

In [2]: f
Out[2]:
          ⎛                          2                                                   ⎞
          ⎜⎛                       2⎞                                                   2⎟
          ⎜⎜     2           2  2⋅x ⎟        ⎛    ⎛           2      3⎞           ⎞  3⋅x ⎟
x⋅(1 + x)⋅⎝⎝- log (1 + x) + x ⋅ℯ    ⎠  + 2⋅x⋅⎝x - ⎝1 + x + 2⋅x  + 2⋅x ⎠⋅log(1 + x)⎠⋅ℯ    ⎠
──────────────────────────────────────────────────────────────────────────────────────────
                                                                2
                         ⎛                                    2⎞
                         ⎜   2                  ⎛ 2    3⎞  2⋅x ⎟
                         ⎝log (1 + x)⋅(1 + x) - ⎝x  + x ⎠⋅ℯ    ⎠                          

In [3]: risch_integrate(f, x, handle_first='log')
Out[3]:
       ⎛              ⎛ 2⎞⎞                   ⎛                ⎛ 2⎞⎞
       ⎜log(1 + x)    ⎝x ⎠⎟                   ⎜  log(1 + x)    ⎝x ⎠⎟          ⎛ 2⎞
    log⎜────────── + ℯ    ⎟                log⎜- ────────── + ℯ    ⎟       2  ⎝x ⎠
       ⎝    x             ⎠                   ⎝      x             ⎠      x ⋅ℯ    ⋅log(1 + x)
x + ─────────────────────── - log(1 + x) - ───────────────────────── + ──────────────────────────
               2                                       2                                        2
                                                                              2           3  2⋅x
                                                                       - x⋅log (1 + x) + x ⋅ℯ    

In [4]: risch_integrate(f, x, handle_first='exp')
Out[4]:
       ⎛                ⎛ 2⎞⎞                   ⎛                ⎛ 2⎞⎞        ⎛ 2⎞
       ⎜                ⎝x ⎠⎟                   ⎜                ⎝x ⎠⎟        ⎝x ⎠
    log⎝log(1 + x) + x⋅ℯ    ⎠                log⎝log(1 + x) - x⋅ℯ    ⎠     x⋅ℯ    ⋅log(1 + x)
x + ───────────────────────── - log(1 + x) - ───────────────────────── - ──────────────────────
                2                                        2                                    2
                                                                            2           2  2⋅x
                                                                         log (1 + x) - x ⋅ℯ    

In [5]: %timeit risch_integrate(f, x, handle_first='log')
1 loops, best of 3: 1.49 s per loop

In [6]: %timeit risch_integrate(f, x, handle_first='exp')
1 loops, best of 3: 1.21 s per loop

In [7]: cancel(risch_integrate(f, x, handle_first='log').diff(x) - f)
Out[7]: 0

In [8]: cancel(risch_integrate(f, x, handle_first='exp').diff(x) - f)
Out[8]: 0
&lt;/pre&gt;
&lt;p&gt;So go now, and pull my &lt;a href=&quot;http://github.com/asmeurer/sympy/tree/integration3&quot;&gt;branch&lt;/a&gt;, and try this function out.  And report any problems that you have back to me, either through the mailing list, IRC, issue 2010, or as a comment to this blog post (I don’t really care how).&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/710/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/710/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=710&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-08-05T22:30:00+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-8421138063566161330">
	<title>Fredrik Johansson: Euler-Maclaurin summation of hypergeometric series</title>
	<link>http://fredrik-j.blogspot.com/2010/07/euler-maclaurin-summation-of.html</link>
	<content:encoded>I recently fixed another corner case (it's always the corner cases that are hard!) in the hypergeometric function evaluation code in mpmath.&lt;br /&gt;&lt;br /&gt;The difficulty in question concerns the functions &lt;sub&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;&lt;i&gt;p&lt;/i&gt;-1&lt;/sub&gt;(...; ...; &lt;i&gt;z&lt;/i&gt;), of which the Gauss hypergeometric function &lt;sub&gt;2&lt;/sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; is an important special case. These functions can be thought of as generalizations of the geometric series&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://4.bp.blogspot.com/_rh0QblLk0C0/TFCIHTI0lEI/AAAAAAAAAUQ/j-LsprfzhkE/s1600/h3.png&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_rh0QblLk0C0/TFCIHTI0lEI/AAAAAAAAAUQ/j-LsprfzhkE/s400/h3.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 227px; height: 48px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5499044803997111362&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;and the natural logarithm&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TFCHMAB6e3I/AAAAAAAAAUI/pOUKOM2qE_c/s1600/h2.png&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TFCHMAB6e3I/AAAAAAAAAUI/pOUKOM2qE_c/s400/h2.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 341px; height: 50px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5499043785255582578&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;and share the property that the hypergeometric (Maclaurin) series has radius of convergence 1, with a singularity (either algebraic or logarithmic, as above) at &lt;i&gt;z&lt;/i&gt; = 1.&lt;br /&gt;&lt;br /&gt;Numerical evaluation is fairly easy for &lt;i&gt;z&lt;/i&gt; in most of the complex plane. The series for &lt;sub&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;&lt;i&gt;p&lt;/i&gt;-1&lt;/sub&gt;(...; ...; &lt;i&gt;z&lt;/i&gt;) converges like the geometric series, so direct summation works well for, say, |&lt;i&gt;z&lt;/i&gt;| ≤ &lt;i&gt;r&lt;/i&gt; 0.9. Likewise, there is an analytic continuation formula which transforms &lt;i&gt;z&lt;/i&gt; to 1/&lt;i&gt;z&lt;/i&gt;, allowing evaluation for (say) |&lt;i&gt;z&lt;/i&gt;| ≥ 1.1.&lt;br /&gt;&lt;br /&gt;The remaining shell around the unit circle 0.9 &amp;lt; |&lt;i&gt;z&lt;/i&gt;| &amp;lt; 1.1 is the difficult region. In fact, &lt;sub&gt;2&lt;/sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; can still (essentially) be computed using exact transformations here, but the higher cases remain difficult. As mentioned in an &lt;a href=&quot;http://fredrik-j.blogspot.com/2009/12/analytic-continuation-of-3f2-4f3-and.html&quot;&gt;earlier post&lt;/a&gt;, mpmath handles this by calling &lt;tt&gt;nsum()&lt;/tt&gt; which applies convergence acceleration to the slowly converging series. In particular, &lt;tt&gt;nsum&lt;/tt&gt; implements the (generalized) &lt;a href=&quot;http://en.wikipedia.org/wiki/Shanks_transformation&quot;&gt;Shanks transformation&lt;/a&gt; which is extremely efficient for this particular type of series – in fact, it works outside the radius of convergence (Shanks transformation effectively computes a Padé approximant), so it can be used anywhere in the difficult shell.&lt;br /&gt;&lt;br /&gt;Still, the Shanks transformation is most efficient when arg(&lt;i&gt;z&lt;/i&gt;) = ±π and unfortunately degenerates as arg(&lt;i&gt;z&lt;/i&gt;) → 0, i.e. close to &lt;i&gt;z&lt;/i&gt; = 1. &lt;tt&gt;nsum&lt;/tt&gt; also implements &lt;a href=&quot;http://en.wikipedia.org/wiki/Richardson_extrapolation&quot;&gt;Richardson extrapolation&lt;/a&gt;, which sometimes works at &lt;i&gt;z&lt;/i&gt; = 1, but only for special parameter combinations in the hypergeometric series (although those special combinations happen to be quite important – they include the case where the hypergeometric series reduces to a polygamma function or polylogarithm).&lt;br /&gt;&lt;br /&gt;Thus, we have the following evaluation strategy for &lt;sub&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;sub&gt;&lt;i&gt;p&lt;/i&gt;-1&lt;/sub&gt;:&lt;br /&gt;&lt;br /&gt;Blue: direct summation (with respect to &lt;i&gt;z&lt;/i&gt; or 1/&lt;i&gt;z&lt;/i&gt;)&lt;br /&gt;Yellow: Shanks transformation&lt;br /&gt;Red: ???&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/_rh0QblLk0C0/TFImLM1V3pI/AAAAAAAAAUY/al-aaPxHOPw/s1600/circle.png&quot;&gt;&lt;img src=&quot;http://2.bp.blogspot.com/_rh0QblLk0C0/TFImLM1V3pI/AAAAAAAAAUY/al-aaPxHOPw/s400/circle.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 300px; height: 300px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5499500068838170258&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;A commenter &lt;a href=&quot;http://fredrik-j.blogspot.com/2009/12/analytic-continuation-of-3f2-4f3-and.html?showComment=1274751298704#c5051305326286671188&quot;&gt;suggested&lt;/a&gt; trying some other convergence acceleration techniques (like the Levin transformation). But it seems that they still will fail in some cases.&lt;br /&gt;&lt;br /&gt;Thus I've finally implemented the &lt;a href=&quot;http://en.wikipedia.org/wiki/Euler%E2%80%93Maclaurin_formula&quot;&gt;Euler-Maclaurin summation formula&lt;/a&gt; for the remaining case. The E-M formula differs from other convergence acceleration techniques in that it is based on analyticity of the integrand and does not require a particular rate of convergence. It is implemented in mpmath as &lt;tt&gt;sumem()&lt;/tt&gt;, but requires a little work to apply efficiently.&lt;br /&gt;&lt;br /&gt;To apply the E-M formula to a hypergeometric series Σ &lt;i&gt;T&lt;/i&gt;(&lt;i&gt;k&lt;/i&gt;), the term &lt;i&gt;T&lt;/i&gt;(&lt;i&gt;k&lt;/i&gt;) must first of all obviously be extended to an analytic function of &lt;i&gt;k&lt;/i&gt;, which is done the straightforward way by considering the rising factorials as quotients of gamma functions &lt;i&gt;a&lt;/i&gt;(&lt;i&gt;a&lt;/i&gt;+1)...(&lt;i&gt;a&lt;/i&gt;+&lt;i&gt;k&lt;/i&gt;−1) = Γ(&lt;i&gt;a&lt;/i&gt;+&lt;i&gt;k&lt;/i&gt;) / Γ(&lt;i&gt;a&lt;/i&gt;).&lt;br /&gt;&lt;br /&gt;We are left with the difficulty of having to integrate &lt;i&gt;T&lt;/i&gt;(&lt;i&gt;k&lt;/i&gt;) and also to compute &lt;i&gt;n&lt;/i&gt;-th order derivatives of this function for the tail expansion in the E-M formula (neither of which can be done in closed form). Fortunately, numerical integration with &lt;tt&gt;quad()&lt;/tt&gt; works very well, but the derivatives remain a problem.&lt;br /&gt;&lt;br /&gt;By default, &lt;tt&gt;sumem()&lt;/tt&gt; computes the derivatives using finite differences. Although this works, it gets extremely expensive at high precision for hypergeometric series due to the rapidly increasing cost of evaluating the gamma function as the precision increases. But &lt;i&gt;T&lt;/i&gt;(&lt;i&gt;k&lt;/i&gt;) is a product of functions that &lt;i&gt;individually&lt;/i&gt; can be differentiated logarithmically in closed form (in terms of polygamma functions). I therefore implemented the equivalent of symbolic high-order differentiation for products and the exponential function using generators.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;diffs_prod&lt;/tt&gt; generates the high-order derivatives of a product, given generators for products of individual factors:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; f = lambda x: exp(x)*cos(x)*sin(x)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; u = diffs(f, 1)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; v = diffs_prod([diffs(exp,1), diffs(cos,1), diffs(sin,1)])&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;1.23586333600241&lt;br /&gt;1.23586333600241&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;0.104658952245596&lt;br /&gt;0.104658952245596&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;-5.96999877552086&lt;br /&gt;-5.96999877552086&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;-12.4632923122697&lt;br /&gt;-12.4632923122697&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;diffs_exp&lt;/tt&gt; generates the high-order derivatives of exp(&lt;i&gt;f&lt;/i&gt;(&lt;i&gt;x&lt;/i&gt;)), given a generator for the derivatives of &lt;i&gt;f&lt;/i&gt;(&lt;i&gt;x&lt;/i&gt;):&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; def diffs_loggamma(x):&lt;br /&gt;...     yield loggamma(x)&lt;br /&gt;...     i = 0&lt;br /&gt;...     while 1:&lt;br /&gt;...         yield psi(i,x)&lt;br /&gt;...         i += 1&lt;br /&gt;...&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; u = diffs_exp(diffs_loggamma(3))&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; v = diffs(gamma, 3)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;2.0&lt;br /&gt;2.0&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;1.84556867019693&lt;br /&gt;1.84556867019693&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;2.49292999190269&lt;br /&gt;2.49292999190269&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; next(u); next(v)&lt;br /&gt;3.44996501352367&lt;br /&gt;3.44996501352367&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Actually only differentiation of the exponential function is necessary, which I didn't realize at first, but the product differentiation is still a nice feature to have.&lt;br /&gt;&lt;br /&gt;Exponential differentiation amounts to constructing a polynomial of &lt;i&gt;n&lt;/i&gt;+1 variables (the derivatives of &lt;i&gt;f&lt;/i&gt;), which has &lt;i&gt;P&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;) (partition function) ≈ exp(√&lt;i&gt;n&lt;/i&gt;) terms. Despite the rapid growth, it is indeed faster to use this approach to differentiate gamma function products at high precision, since the precision can be kept constant. In fact, this should even work in double precision (&lt;tt&gt;fp&lt;/tt&gt; arithmetic) although I think it's broken right now due to some minor bug.&lt;br /&gt;&lt;br /&gt;As a result of all this, here are two examples that now work (the results have full accuracy):&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; mp.dps = 25&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; hyper(['1/3',1,'3/2',2], ['1/5','11/6','41/8'], 1)&lt;br /&gt;2.219433352235586121250027&lt;br /&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; hyper(['1/3',1,'3/2',2], ['1/5','11/6','5/4'], 1)&lt;br /&gt;+inf&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; eps1 = extradps(6)(lambda: 1 - mpf('1e-6'))()&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; hyper(['1/3',1,'3/2',2], ['1/5','11/6','5/4'], eps1)&lt;br /&gt;2923978034.412973409330956&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Application: roots of polynomials&lt;/h4&gt;&lt;br /&gt;&lt;br /&gt;A neat application is to compute the roots of quintic polynomials. Such roots can be expressed in closed form using hypergeometric functions, as outlined in the Wikipedia article &lt;a href=&quot;http://en.wikipedia.org/wiki/Bring_radical&quot;&gt;Bring radical&lt;/a&gt;. This is more interesting in theory than practice, since polynomial roots can be calculated very efficiently using iterative methods.&lt;br /&gt;&lt;br /&gt;In particular, the roots of &lt;i&gt;x&lt;/i&gt;&lt;sup&gt;5&lt;/sup&gt; - &lt;i&gt;x&lt;/i&gt; + &lt;i&gt;t&lt;/i&gt; are given (in some order) by&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://4.bp.blogspot.com/_rh0QblLk0C0/TFlkH0bljiI/AAAAAAAAAUk/X7Tl8d54GH4/s1600/1f2a0c3edbd9e10fdd6a6aa5e1c33fe9.png&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_rh0QblLk0C0/TFlkH0bljiI/AAAAAAAAAUk/X7Tl8d54GH4/s400/1f2a0c3edbd9e10fdd6a6aa5e1c33fe9.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 400px; height: 107px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5501538505305984546&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;where&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TFlkIFqd6yI/AAAAAAAAAUs/UZUhNW2xwdg/s1600/a28bdaf32bfb6fb82ec5e4f98feb7c7e.png&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TFlkIFqd6yI/AAAAAAAAAUs/UZUhNW2xwdg/s400/a28bdaf32bfb6fb82ec5e4f98feb7c7e.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 400px; height: 96px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5501538509931801378&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Just verifying one case:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; mp.dps = 25; mp.pretty = True&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; t = mpf(3)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; for r in polyroots([1,0,0,0,-1,t]):&lt;br /&gt;...     print r&lt;br /&gt;... &lt;br /&gt;-1.341293531690699250693537&lt;br /&gt;(0.9790618691253385511579325 - 0.6252190807348055061205923j)&lt;br /&gt;(0.9790618691253385511579325 + 0.6252190807348055061205923j)&lt;br /&gt;(-0.3084151032799889258111639 + 1.249926913731033699905407j)&lt;br /&gt;(-0.3084151032799889258111639 - 1.249926913731033699905407j)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; -t*hyper(['1/5','2/5','3/5','4/5'], ['1/2','3/4','5/4'], 3125*t**4/256)&lt;br /&gt;(-0.9790618691253385511579325 + 0.6252190807348055061205923j)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Now, we can choose &lt;i&gt;t&lt;/i&gt; such that the hypergeometric argument becomes unity:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; t = root(mpf(256)/3125,4)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; for r in polyroots([1,0,0,0,-1,t]):&lt;br /&gt;...     print r&lt;br /&gt;... &lt;br /&gt;-1.103842268886161371052433&lt;br /&gt;(0.6687403049764220240032331 + 3.167963942396665205386494e-14j)&lt;br /&gt;(0.6687403049764220240032331 - 3.172324181973539074536523e-14j)&lt;br /&gt;(-0.1168191705333413384770166 + 1.034453571405662514459057j)&lt;br /&gt;(-0.1168191705333413384770166 - 1.034453571405662514459057j)&lt;br /&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; -t*hyper(['1/5','2/5','3/5','4/5'], ['1/2','3/4','5/4'], 1)&lt;br /&gt;-0.6687403049764220240032331&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;The last line would previously fail.&lt;br /&gt;&lt;br /&gt;Interesting to note is that the value at the singular point &lt;i&gt;z&lt;/i&gt; = 1 corresponds to a double root. This also makes &lt;tt&gt;polyroots&lt;/tt&gt; return inaccurate values (note the imaginary parts), a known deficiency that should be fixed...&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Better methods&lt;/h4&gt;&lt;br /&gt;&lt;br /&gt;In fact, there may be better methods than the Euler-Maclaurin formula. One such approach is to use the &lt;a href=&quot;http://mathworld.wolfram.com/Abel-PlanaFormula.html&quot;&gt;Abel-Plana formula&lt;/a&gt;, which I've also recently implemented as &lt;tt&gt;sumap()&lt;/tt&gt;. The Abel-Plana formula gives the exact value for an infinite series (subject to some special growth conditions on the analytically extended summand) as a sum of two integrals.&lt;br /&gt;&lt;br /&gt;The Abel-Plana formula is particularly useful when the summand decreases like a power of &lt;i&gt;k&lt;/i&gt;; for example when the sum is a pure zeta function:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; sumap(lambda k: 1/k**2.5, [1,inf])&lt;br /&gt;1.34148725725091717975677&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; zeta(2.5)&lt;br /&gt;1.34148725725091717975677&lt;br /&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; sumap(lambda k: 1/(k+1j)**(2.5+2.5j), [1,inf])&lt;br /&gt;(-3.385361068546473342286084 - 0.7432082105196321803869551j)&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; zeta(2.5+2.5j, 1+1j)&lt;br /&gt;(-3.385361068546473342286084 - 0.7432082105196321803869551j)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;It actually works very well for the generalized hypergeometric series at the &lt;i&gt;z&lt;/i&gt; = 1 singularity (which, as mentioned earlier, is a generalized polygamma function, polylogarithm, or zeta function of integer argument), and near the singularity as well. It should even be slightly faster than the Euler-Maclaurin formula since no derivatives are required. Yet another possibility is to integrate a Mellin-Barnes type contour for the hypergeometric function directly.&lt;br /&gt;&lt;br /&gt;But at present, I don't want to modify the existing hypergeometric code because it works and would only get more complicated. Rather, I want to improve &lt;tt&gt;nsum&lt;/tt&gt; so it can handle all of this more easily without external hacks. The numerical integration code should also be improved first, because there are still certain parameter combinations where the hypergeometric function evaluation fails due to slow convergence in the numerical integration (this is due to an implementation issue and not an inherent limitation of the integration algorithm).&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-8421138063566161330?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-08-04T13:27:53+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="http://ojensen.wordpress.com/?p=197">
	<title>Øyvind Jensen: Reliable and testable C code</title>
	<link>http://ojensen.wordpress.com/2010/08/02/reliable-and-testable-c-code/</link>
	<content:encoded>&lt;p&gt;In my previous blog post I wrote about the new layer of testing that became available when the tensor module got functionality to analyze and report the structure of indexed expressions. Since then, I have improved the C printer and the C code generator by removing hacks that used to provide such functionality and replaced it with calls to the more robust methods defined in the tensor module.&lt;/p&gt;
&lt;p&gt;I put up these improvements for &lt;a href=&quot;http://hosted.smartbear.com/sympy/go?page=ReviewDisplay&amp;amp;reviewid=6&quot;&gt;review&lt;/a&gt;, and got valuable feedback that I spent the rest of the time implementing.  In addition, I have addressed Ronan’s comments to my last blog post, and this has lead to stylistic improvements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now an indexed expression is written with [] instead of ().  This is more  pythonic, as [] is used with all the builtin sequences.  This is also consistent with numpy.&lt;/li&gt;
&lt;li&gt;Some classes have been renamed: IndexedElement is now Indexed, and the old Indexed class is now called IndexedBase.  The new terminology should be less confusing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The C code generator has become quite versatile and capable of handling complicated array expressions.  Here is a little demonstration of my current codegen_C3 branch:&lt;/p&gt;
&lt;pre&gt;In [1]: A, x, y = map(IndexedBase, ['A', 'x', 'y'])

In [2]: i = Idx('i', m)

In [3]: j = Idx('j', n)

In [4]: print ccode(A[i, i], assign_to=z)  #trace of a matrix
z = 0;
for (int i=0; i&amp;lt;m; i++){
 z = z + A[i + i*m];
}

In [5]: print ccode(A[i, j]*x[j] + y[i], assign_to=y[i]) #matrix-vector 1
for (int i=0; i&amp;lt;m; i++){
 for (int j=0; j&amp;lt;n; j++){
 y[i] = x[j]*A[j + i*n] + y[i];
 }
}

In [6]: print ccode(A[i, j]*x[j], assign_to=y[i]) #matrix-vector 2
for (int i=0; i&amp;lt;m; i++){
 y[i] = 0;
}
for (int i=0; i&amp;lt;m; i++){
 for (int j=0; j&amp;lt;n; j++){
 y[i] = x[j]*A[j + i*n] + y[i];
 }
}
&lt;/pre&gt;
&lt;p&gt;The code printer takes care of introducing and initialization of accumulator variables if needed, not the codegen module as previaously.  The initialization is skipped if the left hand side variable is also present on the right hand side (as in statement In[5]).&lt;/p&gt;
&lt;p&gt;Finally, you may have noticed that this post was a little bit delayed.  This is because I was traveling in the weekend and didn’t get as much time for blogging as I had planned.  I’ll make up for it by blogging twice this week.&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/ojensen.wordpress.com/197/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/ojensen.wordpress.com/197/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=ojensen.wordpress.com&amp;amp;blog=13891021&amp;amp;post=197&amp;amp;subd=ojensen&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-08-02T10:23:22+00:00</dc:date>
	<dc:creator>jegerjensen</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9135222751616024074.post-143425197871935102">
	<title>Matthew Curry: More Design Issues</title>
	<link>http://mattjcurry.blogspot.com/2010/07/more-design-issues.html</link>
	<content:encoded>Unfortunately, it seems with my project that we keep running into more and more design issues. Put simply, the issues arise with Sympy's Mul and Add (and Pow) classes. In order for my quantum objects to be handled properly, we are going to have to subclass these classes. You can find more information about the issues &lt;a href=&quot;https://docs.google.com/document/pub?id=1aDhhEam6TzOYdtEBd9Yw_vD3jW7MFHnz6lpsPb87V9w&quot;&gt;here&lt;/a&gt; (originally posted on the Sympy Google group).&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;With all that to say, there still is a bit of time for coding left! Next week, we are going to subclass Mul, Add, and Pow (qmul, qadd, qpow). After that happens, I plan on creating a physics example that uses the existing quantum library I've helped build. I think I'm going to do the particle in a box (with infinitely strong walls) and use a position state to do so.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;More on this next week when we get everything sorted out!&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/9135222751616024074-143425197871935102?l=mattjcurry.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-31T18:56:00+00:00</dc:date>
	<dc:creator>mcurry</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-6568744196982634289.post-6122266783960777317">
	<title>Ond&amp;#345;ej &amp;#268;ert&amp;iacute;k: Week July 26 - 30</title>
	<link>http://ondrejcertik.blogspot.com/2010/07/week-july-26-30.html</link>
	<content:encoded>This week I have been wrapping up my work at LLNL and trying to generate some comparisons between different approaches to adapt to multiple eigenvectors at once.&lt;br /&gt;&lt;br /&gt;It turns out that most of the issues are in the way we create the new mesh for the next adaptivity iteration, in particular, how do we choose which candidates to refine. I have tried to converge to the lowest eigenvector (as well as to any other eigenvector too), to the sum of the eigenvectors, to each eigenvector individually and taking the union of the meshes and so on. I have also implemented the uniform p-FEM as well as tried p-FEM and hp-FEM using the approaches I mentioned above.&lt;br /&gt;&lt;br /&gt;It seems to be crucial to have a good initial mesh, at least for p-FEM. If I use a good mesh and p-adaptivity, I am able to get the best results so far. In principle hp adaptivity should be at least as good, but our current approach doesn't show it yet. Hopefully we'll manage to make it work.&lt;br /&gt;&lt;br /&gt;Besides that I have also implemented H1 norms for the Function class (based on Fekete points) by calculating coefficients with regards to a FE basis and some other little things.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/6568744196982634289-6122266783960777317?l=ondrejcertik.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-31T07:49:27+00:00</dc:date>
	<dc:creator>Ondřej Čertík</dc:creator>
</item>
<item rdf:about="http://asmeurersympy.wordpress.com/?p=683">
	<title>Aaron Meurer: Integration of primitive functions</title>
	<link>http://asmeurersympy.wordpress.com/2010/07/31/integration-of-primitive-functions/</link>
	<content:encoded>&lt;p&gt;&lt;strong&gt;Integration of Primitive Functions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So this past week, I had another break through in my project.  The &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;first break through&lt;/a&gt;, as you may recall, was the completion of the &lt;code&gt;integrate_hyperexponential()&lt;/code&gt; function, which allowed for the integration in hyperexponential extensions, including proving the nonexistence of elementary integrals.  Now I have worked my way up to this level on the other major half of the integration algorithm (actually, major third; more on that later): integration of primitive elements.  &lt;/p&gt;
&lt;p&gt;This time, I can refer you to my &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/24/the-risch-algorithm-part-2-elementary-functions/&quot;&gt;previous blog post&lt;/a&gt; for definitions.  The chief thing here is that there is now a function in my &lt;tt&gt;integration3&lt;/tt&gt; branch called &lt;code&gt;integrate_primitive()&lt;/code&gt;, and it is used primarily for integrating functions with logarithms.&lt;/p&gt;
&lt;p&gt;So, how about some examples?  The first one comes from &lt;a href=&quot;http://asmeurersympy.wordpress.com/feed/&quot;&gt;Algorithms for computer algebra By Keith O. Geddes, Stephen R. Czapor, George Labahn&lt;/a&gt; (example 12.8).  I like it because it contains both exponentials and logarithms, in a way that they do not depend on each other, so it can be integrated with either &lt;code&gt;integrate_primitive()&lt;/code&gt; or &lt;code&gt;integrate_hyperexponential()&lt;/code&gt;.  In either case, the polynomial part is &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cfrac%7Bx%7D%7Bx+%2B+1%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\frac{x}{x + 1}&quot; class=&quot;latex&quot; title=&quot;\frac{x}{x + 1}&quot; /&gt;, so recursively calling the other function is not required.  (for those of you who have been following my &lt;tt&gt;integration3&lt;/tt&gt; branch, you may notice that this is blatantly taken from the commit history).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hover over the code and click on the left-most, “view source” icon (a paper icon with &lt;tt&gt;&amp;lt; &amp;gt;&lt;/tt&gt; over it) to view without breaks.  Opens in a new window.&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [1]: from sympy.integrals.risch import integrate_primitive,
integrate_hyperexponential

In [2]: f = (x*(x + 1)*((x**2*exp(2*x**2) - log(x + 1)**2)**2 +
2*x*exp(3*x**2)*(x - (2*x**3 + 2*x**2 + x + 1)*log(x + 1))))/((x +
1)*log(x + 1)**2 - (x**3 + x**2)*exp(2*x**2))**2

In [3]: f
Out[3]:
          ⎛                          2                                                   ⎞
          ⎜⎛                       2⎞                                                   2⎟
          ⎜⎜     2           2  2⋅x ⎟        ⎛    ⎛           2      3⎞           ⎞  3⋅x ⎟
x⋅(1 + x)⋅⎝⎝- log (1 + x) + x ⋅ℯ    ⎠  + 2⋅x⋅⎝x - ⎝1 + x + 2⋅x  + 2⋅x ⎠⋅log(1 + x)⎠⋅ℯ    ⎠
──────────────────────────────────────────────────────────────────────────────────────────
                                                                2
                         ⎛                                    2⎞
                         ⎜   2                  ⎛ 2    3⎞  2⋅x ⎟
                         ⎝log (1 + x)⋅(1 + x) - ⎝x  + x ⎠⋅ℯ    ⎠

In [4]: var('t0, t1')
Out[4]: (t₀, t₁)

In [5]: a, d = map(lambda i: Poly(i, t1), f.subs(exp(x**2),
t0).subs(log(x + 1), t1).as_numer_denom())

In [6]: a
Out[6]:
Poly((x + x**2)*t1**4 + (-2*t0**2*x**3 - 2*t0**2*x**4)*t1**2 +
(-2*t0**3*x**2 - 4*t0**3*x**3 - 6*t0**3*x**4 - 8*t0**3*x**5 -
4*t0**3*x**6)*t1 + 2*t0**3*x**3 + 2*t0**3*x**4 + t0* *4*x**5 +
t0**4*x**6, t1, domain='ZZ[x,t0]')

In [7]: d
Out[7]: Poly((1 + 2*x + x**2)*t1**4 + (-2*t0**2*x**2 - 4*t0**2*x**3 -
2*t0**2*x**4)*t1**2 + t0**4*x**4 + 2*t0**4*x**5 + t0**4*x**6, t1,
domain='ZZ[x,t0]')

In [8]: D = [Poly(1, x), Poly(2*x*t0, t0), Poly(1/(x + 1), t1)]

In [9]: r = integrate_primitive(a, d, D, [x, t0, t1], [lambda x: log(x +
1), lambda x: exp(x**2)])

In [10]: r
Out[10]:
⎛   ⎛                ⎛ 2⎞⎞      ⎛                ⎛ 2⎞⎞        ⎛ 2⎞                                ⎞
⎜   ⎜                ⎝x ⎠⎟      ⎜                ⎝x ⎠⎟        ⎝x ⎠                ⌠               ⎟
⎜log⎝log(1 + x) + x⋅ℯ    ⎠   log⎝log(1 + x) - x⋅ℯ    ⎠     x⋅ℯ    ⋅log(1 + x)     ⎮   x           ⎟
⎜───────────────────────── - ───────────────────────── - ────────────────────── + ⎮ ───── dx, True⎟
⎜            2                           2                                    2   ⎮ 1 + x         ⎟
⎜                                                           2           2  2⋅x    ⌡               ⎟
⎝                                                        log (1 + x) - x ⋅ℯ                       ⎠
&lt;/pre&gt;
&lt;p&gt;An explanation:  &lt;code&gt;f&lt;/code&gt; is the function we are integrating.  Preparsing is not implemented yet, so we have to do it manually in &lt;tt&gt;[5]&lt;/tt&gt;.  &lt;tt&gt;[8]&lt;/tt&gt; is the list of derivations of the monomials we are working with, &lt;code&gt;[x, t0, t1]&lt;/code&gt;, which represent &lt;img src=&quot;http://s0.wp.com/latex.php?latex=x&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;x&quot; class=&quot;latex&quot; title=&quot;x&quot; /&gt;, &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7Bx%5E2%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{x^2}&quot; class=&quot;latex&quot; title=&quot;e^{x^2}&quot; /&gt;, and &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Clog%7B%28x+%2B+1%29%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\log{(x + 1)}&quot; class=&quot;latex&quot; title=&quot;\log{(x + 1)}&quot; /&gt;, respectively. Because the outermost monomial is a logarithm (primitive), we call &lt;code&gt;integrate_primitive()&lt;/code&gt; on it.  The last argument of the function is the back substitution list, in reverse order because that is the order we have to back substitute in.  We can see the result contains an unevaluated Integral.  This is because the recursive calls to integrate over the smaller extensions have not yet been implemented.  In the final version, &lt;code&gt;integrate()&lt;/code&gt; will automatically call &lt;code&gt;ratint()&lt;/code&gt; in this case on it to give the complete answer.  The second argument of the result, True, indicates that the integral was elementary and that this is the complete integral.&lt;/p&gt;
&lt;p&gt;Because the extensions did not depend on each other, we could have also integrated in &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%2C+%5Clog%7B%28x+%2B+1%29%7D%2C+e%5E%7Bx%5E2%7D%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x, \log{(x + 1)}, e^{x^2})&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x, \log{(x + 1)}, e^{x^2})&quot; /&gt; instead of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%2C+e%5E%7Bx%5E2%7D%2C+%5Clog%7B%28x+%2B+1%29%7D%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x, e^{x^2}, \log{(x + 1)})&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x, e^{x^2}, \log{(x + 1)})&quot; /&gt;:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [11]: a1, d1 = map(lambda i: Poly(i, t0), f.subs(exp(x**2), t0).subs(log(x + 1), t1).as_numer_denom())

In [12]: D1 = [Poly(1, x), Poly(1/(x + 1), t1), Poly(2*x*t0, t0)]

In [13]: r1 = integrate_hyperexponential(a1, d1, D1, [x, t1, t0], [lambda x: exp(x**2), lambda x: log(x + 1)])

In [14]: r1
Out[14]:
⎛   ⎛              ⎛ 2⎞⎞      ⎛                ⎛ 2⎞⎞                                                ⎞
⎜   ⎜log(1 + x)    ⎝x ⎠⎟      ⎜  log(1 + x)    ⎝x ⎠⎟          ⎛ 2⎞                                  ⎟
⎜log⎜────────── + ℯ    ⎟   log⎜- ────────── + ℯ    ⎟       2  ⎝x ⎠                  ⌠               ⎟
⎜   ⎝    x             ⎠      ⎝      x             ⎠      x ⋅ℯ    ⋅log(1 + x)       ⎮   x           ⎟
⎜─────────────────────── - ───────────────────────── + ────────────────────────── + ⎮ ───── dx, True⎟
⎜           2                          2                                        2   ⎮ 1 + x         ⎟
⎜                                                             2           3  2⋅x    ⌡               ⎟
⎝                                                      - x⋅log (1 + x) + x ⋅ℯ                       ⎠
&lt;/pre&gt;
&lt;p&gt;We can verify by taking the derivative that the results in each case are antiderivatives of the original function, &lt;code&gt;f&lt;/code&gt;, even though they appear different.&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [15]: cancel(r[0].diff(x) - f)
Out[15]: 0

In [16]: cancel(r1[0].diff(x) - f)
Out[16]: 0
&lt;/pre&gt;
&lt;p&gt;We can see in each case, the remaining unevaluated &lt;code&gt;Integral&lt;/code&gt; was in &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x)&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x)&quot; /&gt; only, meaning that the recursive call to &lt;code&gt;integrate_hyperexponential()&lt;/code&gt; or &lt;code&gt;integrate_primitive()&lt;/code&gt;, respectively, would not have been necessary. Finally, we can see that choosing the correct extension to integrate over can make a difference, time wise:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [17]: %timeit integrate_primitive(a, d, D, [x, t0, t1], [lambda x: log(x + 1), lambda x: exp(x**2)])
1 loops, best of 3: 1.91 s per loop

In [18]: %timeit integrate_hyperexponential(a1, d1, D1, [x, t1, t0], [lambda x: exp(x**2), lambda x: log(x + 1)])
1 loops, best of 3: 2.63 s per loop
&lt;/pre&gt;
&lt;p&gt;Just as with the exponential case, the function can prove the integrals are non-elementary. This is the so-called &lt;a href=&quot;http://en.wikipedia.org/wiki/Logarithmic_integral&quot;&gt;logarithmic integral&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [19]: f1 = 1/log(x)

In [20]: a, d = map(lambda i: Poly(i, t1), f1.subs(log(x), t1).as_numer_denom())

In [21]: a
Out[21]: Poly(1, t1, domain='ZZ')

In [22]: d
Out[22]: Poly(t1, t1, domain='ZZ')

In [23]: integrate_primitive(a, d, [Poly(1, x), Poly(1/x, t1)], [x, t1], [log])
Out[23]: (0, False)
&lt;/pre&gt;
&lt;p&gt;The second argument, &lt;code&gt;False&lt;/code&gt;, indicates that the integral was non-elementary.  Namely, the function has proven that the function &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f+-+D%280%29+%3D+%5Cfrac%7B1%7D%7B%5Clog%7B%28x%29%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;f - D(0) = \frac{1}{\log{(x)}}&quot; class=&quot;latex&quot; title=&quot;f - D(0) = \frac{1}{\log{(x)}}&quot; /&gt; does not have an elementary anti-derivative over &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%2C+%5Clog%7B%28x%29%7D%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x, \log{(x)})&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x, \log{(x)})&quot; /&gt; (see the &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;previous post&lt;/a&gt; for more information).&lt;/p&gt;
&lt;p&gt;Finally, be aware that, just as with &lt;code&gt;integrate_hyperexponential()&lt;/code&gt; many integrals will  raise &lt;code&gt;NotImplementedError&lt;/code&gt;, because the subroutines necessary to solve them have not yet been finished.&lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [25]: f = log(log(x))**2

In [26]: f.diff(x)
Out[26]:
2⋅log(log(x))
─────────────
   x⋅log(x)

In [27]: a, d = map(lambda i: Poly(i, t1),
cancel(f.diff(x)).subs(log(x), t0).subs(log(t0), t1).as_numer_denom())

In [28]: a
Out[28]: Poly(2*t1, t1, domain='ZZ')

In [29]: d
Out[29]: Poly(t0*x, t1, domain='ZZ[x,t0]')

In [30]: D = [Poly(1, x), Poly(1/x, t0), Poly(1/(x*t0), t1)]

In [31]: integrate_primitive(a, d, D, [x, t0, t1], [lambda x: log(log(x)), log])
---------------------------------------------------------------------------
NotImplementedError: Remaining cases for Poly RDE not yet implemented.
&lt;/pre&gt;
&lt;p&gt;Now one thing that I want to add from the above examples taken from the commit message is that logarithms are not the only function that are primitive.  The Li function (the logarithmic integral, as above), considered as an elementary extension of &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%2C+%5Clog%7B%28x%29%7D%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x, \log{(x)})&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x, \log{(x)})&quot; /&gt; is also primitive.  But even among the commonly defined elementary functions, there is one other, acrtangents.  &lt;/p&gt;
&lt;pre class=&quot;brush: python;&quot;&gt;In [32]: diff(atan(x)**2, x)
Out[32]:
2⋅atan(x)
─────────
       2
  1 + x  

In [33]: integrate_primitive(Poly(2*t, t), Poly(1 + x**2, t), [Poly(1, x), Poly(1/(1 + x**2), t)], [x, t], [atan])

Out[33]:
⎛    2         ⎞
⎝atan (x), True⎠

In [34]: integrate_primitive(Poly(t, t), Poly(x, t), [Poly(1, x), Poly(1/(1 + x**2), t)], [x, t], [atan])

Out[34]:
⎛⌠                  ⎞
⎜⎮ atan(x)          ⎟
⎜⎮ ─────── dx, False⎟
⎜⎮    x             ⎟
⎝⌡                  ⎠
&lt;/pre&gt;
&lt;p&gt;Due to a bug in the code right now, the final version returns the non-elementary integral in the final result.  Suffice it to say that it has proven that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cint+%7B%5Cfrac%7B%5Carctan%7B%28x%29%7D%7D%7Bx%7D+dx%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\int {\frac{\arctan{(x)}}{x} dx}&quot; class=&quot;latex&quot; title=&quot;\int {\frac{\arctan{(x)}}{x} dx}&quot; /&gt; is non-elementary. As far as I know, this isn’t any special function.  Actually, it’s just a random function containing arctan that looked non-elementary to me that I plugged in and found out that I was correct.  It’s very similar in form to the &lt;a href=&quot;http://en.wikipedia.org/wiki/Exponential_integral&quot;&gt;exponential integral&lt;/a&gt; (Ei) or the &lt;a href=&quot;http://en.wikipedia.org/wiki/Sine_integral#Sine_integral&quot;&gt;Sine/Cosine Integral&lt;/a&gt; (Si/Ci), which is how I guessed that it would be non-elementary.  Maybe it should be called ATi().&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Status Update&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So it has come to my attention that the suggested “pencils down” date is one week from Monday, and the hard “pencils down” date is two weeks from Monday (see the &lt;a href=&quot;http://socghop.appspot.com/document/show/gsoc_program/google/gsoc2010/timeline&quot;&gt;Google Summer of Code Timeline&lt;/a&gt;).  Now, no matter how fast I work, my work cannot be pushed in until Mateusz’s latest polys branch gets pushed in, because my work is based on top of it.  I plan on continuing work on the integration algorithm beyond the summer until I finish the transcendental part of the algorithm, and even after that, I want to look into implementing other integration related things, like definite integration using &lt;a href=&quot;http://en.wikipedia.org/wiki/Meijer-G&quot;&gt;Meijer G-functions,&lt;/a&gt; and the algebraic part of the algorithm.  But for now, these are the things that I need to do for the transcendental part, which is this summer’s work:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;1. Implement the preparsing algorithms. &lt;/em&gt; This part is two-fold.  First, I need to implement algorithms based on the Risch Structure Theorems, which allow me to determine if an extension is algebraic or not (if it is algebraic, we cannot integrate it because only the transcendental part is implemented).  The other part will be the function that actually goes through an expression and tries to build up a differential extension from it so it can be integrated.  This can be a tricky part. For example, if we want to integrate &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f+%3D+e%5Ex+%2B+e%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;f = e^x + e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;f = e^x + e^{\frac{x}{2}}&quot; /&gt;, we want to first choose &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_1%3De%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_1=e^{\frac{x}{2}}&quot; class=&quot;latex&quot; title=&quot;t_1=e^{\frac{x}{2}}&quot; /&gt; so that &lt;img src=&quot;http://s0.wp.com/latex.php?latex=f+%3D+t_1%5E2+%2B+t_1&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;f = t_1^2 + t_1&quot; class=&quot;latex&quot; title=&quot;f = t_1^2 + t_1&quot; /&gt;, because if we choose &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_1%3De%5Ex&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_1=e^x&quot; class=&quot;latex&quot; title=&quot;t_1=e^x&quot; /&gt;, then &lt;img src=&quot;http://s0.wp.com/latex.php?latex=t_2%3De%5E%7B%5Cfrac%7Bx%7D%7B2%7D%7D%3D%5Csqrt%7Bt_1%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;t_2=e^{\frac{x}{2}}=\sqrt{t_1}&quot; class=&quot;latex&quot; title=&quot;t_2=e^{\frac{x}{2}}=\sqrt{t_1}&quot; /&gt; will be algebraic over &lt;img src=&quot;http://s0.wp.com/latex.php?latex=%5Cmathbb%7BQ%7D%28x%2C+t_1%29&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;\mathbb{Q}(x, t_1)&quot; class=&quot;latex&quot; title=&quot;\mathbb{Q}(x, t_1)&quot; /&gt;.  This is one case where we might try adding an algebraic extensions but where it can be avoided.  The solution will have to be to go through and find the common denominators of the exponentials.  I’m also considering that this might happen in more advanced ways, so it could be necessary for the function to backtrack in the extension tree to see if it can do it in an entirely transcendental way.  Fortunately, the Risch Structure Theorems give us a decision procedure for determining if an extension can be written in terms of the previous extensions (is algebraic over it), but this will still be a very hard function to get right.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2. Finish the remaining cases for &lt;code&gt;integrate_hyperexponential()&lt;/code&gt; and &lt;code&gt;integrate_primitive()&lt;/code&gt;.&lt;/em&gt; As you could see in this post, as well as in the &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;previous one&lt;/a&gt;, there are many integrals that cannot yet be integrated because the special cases for them have not been implemented yet.  Most of these actually rely on implementing the structure theorem algorithms from &lt;strong&gt;1&lt;/strong&gt;, and implementing them once that is finished will not take long, because they will just be straight copying of the pseudocode from Bronstein’s book.  But some of them, particularly ones from the primitive case, are not spelt out so well in Bronstein’s book, and will require more thinking (and thus time) on my part.  I should note that the Structure Theorem algorithms are also this way.&lt;/p&gt;
&lt;p&gt;&lt;em&gt; 3. Implement the hypertangent case. &lt;/em&gt; The ability to integrate in tangent extensions is the other &lt;em&gt;third&lt;/em&gt; I mentioned above.  Since tangents require more special casing, I plan on doing this only after I have finished &lt;strong&gt;1&lt;/strong&gt; and &lt;strong&gt;2&lt;/strong&gt;.  This is actually not much work, because most of the algorithms for solving the particular subproblem for tangents (called the &lt;em&gt;Coupled Risch Differential Equation&lt;/em&gt;) are exactly the same as those for solving the subproblem for hyperexponentials (the &lt;em&gt;Risch Differential Equation&lt;/em&gt;), which are already (mostly) implemented in the hyperexponential part.  There are only a few extra functions that need to be written for it.  Also, you will still be able to integrate functions that contain tangents, such as &lt;img src=&quot;http://s0.wp.com/latex.php?latex=e%5E%7B%5Ctan%7B%28x%29%7D%7D&amp;amp;bg=ffffff&amp;amp;fg=333333&amp;amp;s=0&quot; alt=&quot;e^{\tan{(x)}}&quot; class=&quot;latex&quot; title=&quot;e^{\tan{(x)}}&quot; /&gt; (recall &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;last time&lt;/a&gt; that we showed that &lt;code&gt;integrate_hyperexponential()&lt;/code&gt; can prove that this does not have an elementary integral).  It just won’t be able to integrate when the top-most extension is a tangent.&lt;/p&gt;
&lt;p&gt;So here is what I plan on doing.  Right now, I am going to focus my work on &lt;strong&gt;1&lt;/strong&gt;, since most of &lt;strong&gt;2&lt;/strong&gt; can’t be done until it is anyway.  But more importantly, I want to have a prototype user-level function for the Risch Algorithm.  The reason I want this is so that people can try it out, without having to do the preparsing like I did above, but rather they can just call &lt;code&gt;risch_integrate(f, x)&lt;/code&gt;, and it will return the integral of &lt;code&gt;f&lt;/code&gt;, prove that it is non-elementary and reduce it into the elementary and non-elementary parts, or explain why it cannot do it (either because the function is not transcendental or because something is not implemented yet).  My chief desire for doing this is so that people can try out my code and find the bugs in it for me.  I have already found many critical errors in the code (returns a wrong result), and I want to iron these out before anything goes in.  The best way to do this will be to release a working user-level function and hope that people try it out for me.  &lt;/p&gt;
&lt;p&gt;Also, even if &lt;strong&gt;2&lt;/strong&gt; and &lt;strong&gt;3&lt;/strong&gt; are not finished, if I have &lt;strong&gt;1&lt;/strong&gt;, I can integrate it with &lt;code&gt;integrate()&lt;/code&gt; (no pun intended) and just have it bail if it raises &lt;code&gt;NotImplementedError&lt;/code&gt; I will need to come up with a way to differentiate between this and the case where it returns an unevaluated &lt;code&gt;Integral&lt;/code&gt; because it has proven that an elementary antiderivative does not exist.  Any suggestions?&lt;/p&gt;
&lt;p&gt;I plan on continuing work after the summer until I finish &lt;strong&gt;1&lt;/strong&gt; through &lt;strong&gt;3&lt;/strong&gt;, though I won’t pretend that my work won’t slow down considerably when I start classes in August.  I also promise to finish the &lt;a href=&quot;http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/&quot;&gt;Risch Algorithm posts&lt;/a&gt; that I promised.&lt;/p&gt;
&lt;p&gt;And for what it’s worth, I plan on working my ass off this next two weeks.&lt;/p&gt;
&lt;br /&gt;  &lt;a href=&quot;http://feeds.wordpress.com/1.0/gocomments/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/comments/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godelicious/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/delicious/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gofacebook/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/facebook/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gotwitter/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/twitter/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/gostumble/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/stumble/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/godigg/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/digg/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;a href=&quot;http://feeds.wordpress.com/1.0/goreddit/asmeurersympy.wordpress.com/683/&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;http://feeds.wordpress.com/1.0/reddit/asmeurersympy.wordpress.com/683/&quot; alt=&quot;&quot; border=&quot;0&quot; /&gt;&lt;/a&gt; &lt;img src=&quot;http://stats.wordpress.com/b.gif?host=asmeurersympy.wordpress.com&amp;amp;blog=7467151&amp;amp;post=683&amp;amp;subd=asmeurersympy&amp;amp;ref=&amp;amp;feed=1&quot; alt=&quot;&quot; height=&quot;1&quot; border=&quot;0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2010-07-31T06:44:31+00:00</dc:date>
	<dc:creator>asmeurer</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-936818886435977143.post-5753626938397121846">
	<title>Addison Cugini: Integration of General Quantum</title>
	<link>http://addisoncugini.blogspot.com/2010/07/integration-of-general-quantum.html</link>
	<content:encoded>This week, I started to integrate Matt Curry's general quantum stuff into my code; this was done both to prevent replication of code in our two modules and to test to see if his code worked in a practical problem.&lt;br /&gt;&lt;br /&gt;That said, I spent quite a bit of time this week inside Matt's code.  Dr. Granger and I ported my represent function into Matt's code so that we could represent not just Qbit systems, but also other systems by specifying a BasisSet and how to represent an individual State or Operator in the Basis. Matt and I worked together on developing validate functions that use the new op.priority feature to check to see if Quantum expressions are valid; testing this is still ongoing and has serious limitations because Sympy's AssocOp classes cannot know the special rules that go along with its args. This leads to issues that are hard such as how to call our validate functions automatically when all quantum objects are held within a Sympy binary-operation (e.g. Mul(Operator, |Ket&amp;gt;) + Mul(Operator, |Ket&amp;gt;).&lt;br /&gt;&lt;br /&gt;While helping Matt get his code up and working, I was also busy inheriting and porting features from Matt's code. This was a pain as little changes caused large errors throughout my code; I especially had a hard time dealing with the ket attribute inside State since Sympy keeps all attributes inside an args list rather than an ensemble of separate attributes with their own names. This ultimately meant that I had to rewrite how I parsed the args for Qbit, making args[0] be a tuple which contained the real attributes and args[1] be information about it being a ket.&lt;br /&gt;&lt;br /&gt;As I continue to play with Matt's code, I get a better idea of the serious design problems he is running into. These issues have apparently been run into before with  Matrices (The issues with Matrices are very similar in that they have special rules for what can be multiplied and need to maintain these rules even when held inside a Mul object). The Matrix class got around this by standing alone, not inheriting from Expr, and rewriting its own __mul__ method; this meant that, since Expr's don't know how to multiply by Matricies, Python would default to the Matrix's __(r)mul__ method. This is quite kludge-y, I should hope we come up with a better solution than this. The addition of op-priority is a good start to the fix, but will only fully work if the Mul object itself knows how to use this feature.&lt;br /&gt;&lt;br /&gt;I need to clean up both my and Matt's code in the following weeks as I would like to have a good product by the end of GSoC.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/936818886435977143-5753626938397121846?l=addisoncugini.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-30T22:07:12+00:00</dc:date>
	<dc:creator>AddisonCugini</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-22566012.post-6741089899169036082">
	<title>Christian Muise: Clause Learning Flunk</title>
	<link>http://haz-tech.blogspot.com/2010/07/clause-learning-flunk.html</link>
	<content:encoded>A few days back, I was on my way to write up a blog post detailing how impressive the new system is (and it /does/ have some great speedups in there). To be thorough, I wanted to show results for different parameters being disabled, but to my surprise I discovered clause learning was hurting. This flies in the face of everything we know about SAT solving, so the hunt for reasoning commenced.&lt;br /&gt;&lt;br /&gt;Well long story short, the hunt continues but a likely reason is the lack of impact that the simple clause learning scheme actually has. Monitoring the clauses that cause unit propagation (a measure of how useful a clause is) reveals that the learned clauses aren't actually ever being used -- big-time bummer. It's because of this, I've disabled the conflict analysis in the &lt;a href=&quot;http://github.com/haz/sympy/commit/35c0bdab85b754de91a1fb1a606155e9b4628210&quot;&gt;latest version&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;But results are still be be had. First off, how much better are we than the original DPLL solver, and how bad does the clause learning actually hurt? Well the answers are (roughly) pretty good, and not much ;). Here's a graph plotting the run-time for the three approaches (-CA means clause learning was disabled):&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; href=&quot;http://3.bp.blogspot.com/_DvrW_QLstcQ/TE9MirdDSSI/AAAAAAAACLI/VT2jesJMXYc/s1600/dpll.png&quot;&gt;&lt;img src=&quot;http://3.bp.blogspot.com/_DvrW_QLstcQ/TE9MirdDSSI/AAAAAAAACLI/VT2jesJMXYc/s400/dpll.png&quot; height=&quot;315&quot; border=&quot;0&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Note that the y-axis is on a log scale, so the differences are actually more drastic than they appear. Take-away: the new sat-solver is doing great, and the clause learning doesn't hurt that much...just doesn't help like we'd expect.&lt;br /&gt;&lt;br /&gt;Next up is the impact of watch literals. I'll have a blog post in a day or two for the final installment of &quot;what goes into a SAT solver&quot;, and the focus will be on watch literals. The introduction of this data structure hack heralded in a wave of killer SAT solvers, and they helped out here too. The following is a comparison (with clause learning disabled) between using watch literals and not using them:&lt;br /&gt;&lt;br /&gt;&lt;div style=&quot;clear: both; text-align: center;&quot; class=&quot;separator&quot;&gt;&lt;a style=&quot;margin-left: 1em; margin-right: 1em;&quot; href=&quot;http://3.bp.blogspot.com/_DvrW_QLstcQ/TE9Mivz864I/AAAAAAAACLM/Gkn_qTnwkg0/s1600/watch+literal.png&quot;&gt;&lt;img src=&quot;http://3.bp.blogspot.com/_DvrW_QLstcQ/TE9Mivz864I/AAAAAAAACLM/Gkn_qTnwkg0/s400/watch+literal.png&quot; height=&quot;318&quot; border=&quot;0&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Oh, and it should be noted that when points don't exist, it's because the solver just couldn't handle it in a reasonable amount of time.&lt;br /&gt;&lt;br /&gt;So in the interest of actually letting SymPy users see these enhancements, I'm going to wrap up this week with that final post, and post-pone the clause learning investigation until more time is available. Next up is investigating how a &lt;a href=&quot;http://en.wikipedia.org/wiki/Truth_maintenance_system&quot;&gt;truth maintenance system&lt;/a&gt; can be used to smartly cache queries to the assumption framework. If we can avoid repeated SAT queries (no matter how beefy the solver is), that's a win.&lt;br /&gt;&lt;br /&gt;One final note, there will likely be an incorporation of an industrial SAT-solver interface for those who really want the power. This will be through the &lt;a href=&quot;http://4c110.ucc.ie/numberjack/&quot;&gt;Numberjack Library&lt;/a&gt;, and be optional if you happen to have it installed. The start of it is in &lt;a href=&quot;http://github.com/haz/sympy/tree/numberjack&quot;&gt;this branch&lt;/a&gt;, but we'll need to wait until the next version of Numberjack is released due to limitations it currently has.&lt;br /&gt;&lt;br /&gt;That's all for now. Cheers.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/22566012-6741089899169036082?l=haz-tech.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-27T21:26:54+00:00</dc:date>
	<dc:creator>Haz</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-4754734402679928849.post-4782331091283891322">
	<title>Fredrik Johansson: Post Sage Days 24 report</title>
	<link>http://fredrik-j.blogspot.com/2010/07/post-sage-days-24-report.html</link>
	<content:encoded>Now that I've overcome the immediate effects of SDWS (Sage Days Withdrawal Syndrome), I should write a brief report about &lt;a href=&quot;http://wiki.sagemath.org/days24&quot;&gt;Sage Days 24&lt;/a&gt; which took place last week at the &lt;a href=&quot;http://www.risc.jku.at/&quot;&gt;Research Institute for Symbolic Computation&lt;/a&gt; (RISC), located in a small town called Hagenberg just outside Linz in Austria. Many thanks for the organizers for inviting me!&lt;br /&gt;&lt;br /&gt;Since I'm starting as a Ph.D. student at RISC in October, it was nice to get an early view of the site and meet some current students and staff. The location is quite beautiful, my only complaint being the extremely high temperature last week (they say the weather is more normal most of the year!).&lt;br /&gt;&lt;br /&gt;SD24 was titled &quot;Symbolic Computation in Differential Algebra and Special Functions&quot;, which pretty accurately describes the topics covered. Some points of interest:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://modular.math.washington.edu/&quot;&gt;William Stein&lt;/a&gt; talked about his vision for Sage (short and long term), including goals for special functions support.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://algo.inria.fr/chyzak/&quot;&gt;Frédéric Chyzak&lt;/a&gt; gave a talk about the &lt;a href=&quot;http://ddmf.msr-inria.inria.fr/ddmf&quot;&gt;Dynamic Dictionary of Mathematical Functions&lt;/a&gt;. I really like the approach of starting from a minimal definition of a special function (a differential equation with initial conditions) and generating series expansions, Chebyshev approximations (etc.) algorithmically.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://homepages.cwi.nl/~nicot/&quot;&gt;Nico Temme&lt;/a&gt; talked about numerical evaluation of special functions, which was familiar grounds to me, but with much food for thought.&lt;br /&gt;&lt;br /&gt;I met &lt;a href=&quot;http://www.risc.jku.at/home/mkauers&quot;&gt;Manuel Kauers&lt;/a&gt;, my future supervisor, who gave a neat &lt;a href=&quot;http://www.risc.uni-linz.ac.at/people/mkauers/publications/kauers10d.pdf&quot;&gt;presentation&lt;/a&gt; of some recent research.&lt;br /&gt;&lt;br /&gt;There were many other interesting &lt;a href=&quot;http://wiki.sagemath.org/days24/schedule&quot;&gt;talks&lt;/a&gt; and discussions as well, and I gave a talk about special function evaluation in mpmath (based on my SD23 talk). And of course, I met various other Sage developers and got some coding done as well.&lt;br /&gt;&lt;br /&gt;I had hoped to get generalized hypergeometric functions into Sage during SD24. There is now a &lt;a href=&quot;http://trac.sagemath.org/sage_trac/ticket/2516&quot;&gt;patch&lt;/a&gt;, but it still needs some more work.&lt;br /&gt;&lt;br /&gt;I also implemented &lt;a href=&quot;http://dlmf.nist.gov/12&quot;&gt;parabolic cylinder functions&lt;/a&gt; (PCFs) in mpmath, the last remaining chapter of hypergeometric functions listed in the &lt;a href=&quot;http://dlmf.nist.gov/&quot;&gt;DLMF&lt;/a&gt; (mpmath now covers chapters 1-20, 22, 24-25, partially 26-27, and 33). &lt;a href=&quot;http://code.google.com/p/mpmath/source/detail?r=1178&quot;&gt;Code commit here.&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;Technically, parabolic cylinder functions are just scaled (linear combinations of) confluent hypergeometric functions or Whittaker functions, but they are a bit tricky to compute due to cancellation and branch cuts.&lt;br /&gt;&lt;br /&gt;An example from Nico Temme's talk was to evaluate &lt;i&gt;D&lt;/i&gt;&lt;sub&gt;ν&lt;/sub&gt;(&lt;i&gt;z&lt;/i&gt;) with ν = -300.14 and &lt;i&gt;z&lt;/i&gt; = 300.15 (Maple 13 takes 5 seconds to give an answer that has the wrong sign and is off by 692 orders of magnitude). The new &lt;tt&gt;pcfd&lt;/tt&gt; function in mpmath instantaneously (in about a millisecond) gives the correct result:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; pcfd(-300.14, 300.15)&lt;br /&gt;6.83322814925713e-10526&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; mp.dps = 30&lt;br /&gt;&amp;gt;&amp;gt;&amp;gt; pcfd('-300.14', '300.15')&lt;br /&gt;6.83322814923312844480669009487e-10526&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;All the curve plots from &lt;a href=&quot;http://dlmf.nist.gov/12.3&quot;&gt;DLMF 12.3&lt;/a&gt; can be reproduced as follows:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;f1 = lambda x: pcfu(0.5,x)&lt;br /&gt;f2 = lambda x: pcfu(2,x)&lt;br /&gt;f3 = lambda x: pcfu(3.5,x)&lt;br /&gt;f4 = lambda x: pcfu(5,x)&lt;br /&gt;f5 = lambda x: pcfu(8,x)&lt;br /&gt;plot([f1,f2,f3,f4,f5], [-3,3], [0,3])&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TE8rBfwSyWI/AAAAAAAAAT4/yXcCJbIwnBY/s1600/12.3.1.png&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TE8rBfwSyWI/AAAAAAAAAT4/yXcCJbIwnBY/s320/12.3.1.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 320px; height: 241px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5498660974746585442&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;f1 = lambda x: pcfv(0.5,x)&lt;br /&gt;f2 = lambda x: pcfv(2,x)&lt;br /&gt;f3 = lambda x: pcfv(3.5,x)&lt;br /&gt;f4 = lambda x: pcfv(5,x)&lt;br /&gt;f5 = lambda x: pcfv(8,x)&lt;br /&gt;plot([f1,f2,f3,f4,f5], [-3,3], [-3,3])&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;a href=&quot;http://4.bp.blogspot.com/_rh0QblLk0C0/TE8q-HO2hkI/AAAAAAAAATw/WXCAP26FD4k/s1600/12.3.2.png&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_rh0QblLk0C0/TE8q-HO2hkI/AAAAAAAAATw/WXCAP26FD4k/s320/12.3.2.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 320px; height: 241px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5498660916624262722&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;f1 = lambda x: pcfu(-0.5,x)&lt;br /&gt;f2 = lambda x: pcfu(-2,x)&lt;br /&gt;f3 = lambda x: pcfu(-3.5,x)&lt;br /&gt;f4 = lambda x: pcfu(-5,x)&lt;br /&gt;plot([f1,f2,f3,f4], [-8,8], [-6,6])&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/_rh0QblLk0C0/TE8q9LYwyzI/AAAAAAAAATo/0vcabZzyZAY/s1600/12.3.3.png&quot;&gt;&lt;img src=&quot;http://2.bp.blogspot.com/_rh0QblLk0C0/TE8q9LYwyzI/AAAAAAAAATo/0vcabZzyZAY/s320/12.3.3.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 320px; height: 241px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5498660900559702834&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;f1 = lambda x: pcfv(-0.5,x)&lt;br /&gt;f2 = lambda x: pcfv(-2,x)&lt;br /&gt;f3 = lambda x: pcfv(-3.5,x)&lt;br /&gt;f4 = lambda x: pcfv(-5,x)&lt;br /&gt;plot([f1,f2,f3,f4], [-8,8], [-6,6])&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;a href=&quot;http://2.bp.blogspot.com/_rh0QblLk0C0/TE8q8_dxhVI/AAAAAAAAATg/yDsmRuu6U08/s1600/12.3.4.png&quot;&gt;&lt;img src=&quot;http://2.bp.blogspot.com/_rh0QblLk0C0/TE8q8_dxhVI/AAAAAAAAATg/yDsmRuu6U08/s320/12.3.4.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 320px; height: 241px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5498660897359496530&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;f1 = lambda x: pcfu(-8,x)&lt;br /&gt;f2 = lambda x: pcfv(-8,x)*gamma(0.5-(-8))&lt;br /&gt;f3 = lambda x: hypot(f1(x), f2(x))&lt;br /&gt;plot([f1,f2,f3], [-6,6], [-120,120])&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TE8q8md5fTI/AAAAAAAAATY/a3iHULych3w/s1600/12.3.5.png&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TE8q8md5fTI/AAAAAAAAATY/a3iHULych3w/s320/12.3.5.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 320px; height: 241px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5498660890649132338&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;f1 = lambda x: diff(pcfu,(-8,x),(0,1))&lt;br /&gt;f2 = lambda x: diff(pcfv,(-8,x),(0,1))*gamma(0.5-(-8))&lt;br /&gt;f3 = lambda x: hypot(f1(x), f2(x))&lt;br /&gt;plot([f1,f2,f3], [-6,6], [-220,220])&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TE8q8fCSxkI/AAAAAAAAATQ/S8ziTJv4nf4/s1600/12.3.6.png&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_rh0QblLk0C0/TE8q8fCSxkI/AAAAAAAAATQ/S8ziTJv4nf4/s320/12.3.6.png&quot; alt=&quot;&quot; style=&quot;display: block; margin: 0px auto 10px; text-align: center; cursor: pointer; cursor: hand; width: 320px; height: 241px;&quot; border=&quot;0&quot; id=&quot;BLOGGER_PHOTO_ID_5498660888654300738&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;A little more information can be found in the &lt;a href=&quot;http://mpmath.googlecode.com/svn/trunk/doc/build/functions/bessel.html#parabolic-cylinder-functions&quot;&gt;mpmath documentation section for PCFs&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Thanks again to the &lt;a href=&quot;http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=0757627&amp;amp;version=noscript&quot;&gt;NSF grant&lt;/a&gt; enabling this work.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/4754734402679928849-4782331091283891322?l=fredrik-j.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-27T19:19:06+00:00</dc:date>
	<dc:creator>Fredrik Johansson</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-6568744196982634289.post-274396393864768585">
	<title>Ond&amp;#345;ej &amp;#268;ert&amp;iacute;k: Week July 19 - 23</title>
	<link>http://ondrejcertik.blogspot.com/2010/07/week-july-19-23.html</link>
	<content:encoded>This week I have learned how projections work in detail and wrote it up here:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://theoretical-physics.net/dev/src/math/la.html&quot;&gt;http://theoretical-physics.net/dev/src/math/la.html&lt;br /&gt;&lt;/a&gt;&lt;br /&gt;including all proofs (that orthogonal projection finds the closest vector and so on). At the end of the notes I have calculated some examples in 1D, so that one can see that indeed it doesn't depend on the basis and that the basis doesn't even have to be orthogonal. Then one has to use this approach to calculate the coefficients:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://theoretical-physics.net/dev/src/math/la.html#nonorthogonal-basis&quot;&gt;http://theoretical-physics.net/dev/src/math/la.html#nonorthogonal-basis&lt;br /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;I have then implemented it in h1d. Due to the lack of time, I am now developing everything in my private branch. I'll obtain the permission in about 2 or 3 weeks, so then I'll push it into the master.&lt;br /&gt;&lt;br /&gt;Besides that I have implemented Chebyshev points for orders greater than 48, for which I don't have exact Fekete points anymore (it'd be just a matter of running my sympy script longer, but I was hitting some accuracy issues when solving those large polynomials numerically -- one needs to obtain all roots, so Chebyshev points are ok for now). So I can now represent arbitrary polynomials in 1D. &lt;br /&gt;&lt;br /&gt;I have implemented powering of the discrete function, it automatically determines which polynomial order it has to use and creates a new discrete function (the power) on the new mesh. I wrote lots of tests for that, and I hit an interesting bug, that my naive comparison code:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;assert abs(x-y) &amp;lt; eps&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;was not good enough anymore for larger numbers and I had to read some documentation, and implement the following function:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;@vectorize(0, 1)&lt;br /&gt;def feq(a, b, max_relative_error=1e-12, max_absolute_error=1e-12):&lt;br /&gt;    a = float(a)&lt;br /&gt;    b = float(b)&lt;br /&gt;    # if the numbers are close enough (absolutely), then they are equal&lt;br /&gt;    if abs(a-b) &amp;lt; max_absolute_error:&lt;br /&gt;        return True&lt;br /&gt;    # if not, they can still be equal if their relative error is small&lt;br /&gt;    if abs(b) &amp;gt; abs(a):&lt;br /&gt;        relative_error = abs((a-b)/b)&lt;br /&gt;    else:&lt;br /&gt;        relative_error = abs((a-b)/a)&lt;br /&gt;    return relative_error &amp;lt;= max_relative_error&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;Then I implemented the global H1 and L2 projections, so far the projected function is hardwired, I still need to allow the user to specify any discrete function to be projected. I need to precalculate it and so on.&lt;br /&gt;&lt;br /&gt;I wrote bunch of tests for the projections and powers and I always discovered some bugs by writing more tests, so the progress is slow, but at least I can trust the code that is tested.&lt;br /&gt;&lt;br /&gt;I also helped Pavel to fix couple segfaults, as well as some other things.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/6568744196982634289-274396393864768585?l=ondrejcertik.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-24T02:27:53+00:00</dc:date>
	<dc:creator>Ondřej Čertík</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-936818886435977143.post-2894031447728849147">
	<title>Addison Cugini: QALU and Measurement Gates</title>
	<link>http://addisoncugini.blogspot.com/2010/07/qalu-and-measurement-gates.html</link>
	<content:encoded>As I said in the last blog post, measurement has been implemented as a one-shot irreversible function in my code; I made it a function because measurement should not distribute to each orthogonal state inside the quantum state of the system. This could not easily be implemented in Sympy as every object (including my gates) is assumed to be distributive. This leads to some generality problems as one cannot construct a general circuit object with a mix of measurement gates and Unitary Gates. I did a one-shot measurement rather than an ensemble measurement as the one-shot measurement was needed immediately for my implementation of Shor's algorithm.&lt;br /&gt;&lt;br /&gt;This week, I fixed these problems. In order to ensure measurement did not distribute, I had to subclass Gate into a NonDistributiveGate class which would be given special logic inside my apply method. This required me to carefully review apply and make sure that the .expand() method was used judiciously so that integer factors combined correctly while ensuring that gates did not distribute to the individual orthogonal states. This took much longer than I thought it would. I have also begun to implement a notion of ensemble measurement which will return a tuple of measurement outcomes.&lt;br /&gt;&lt;br /&gt;Another thing I have been putting off is the creation of a set of quantum logic which implements common arithmetic quantum mechanically; this logic would be key in doing a legitimate and realistic simulation of all processes needed to do Shor's or Grover's algorithms. Making this logic required a look through the literature on reversible logic and a review of my old notes from my assembly language class. Reversible logic requires some junk bits which store extra information; since I am simulating a quantum computer and not a purely classical reversible machine, I can cheat a little and use measurement to irreversibly destroy information which bring down the number of necessary junk bits and the logic needed to manage them. Thus, I was able to implement a quantum mechanical Add, Bitshift and Multiply. I still need to create logic which can take powers and preform the mod function. Also, I might want to consider optimizing the number of gates and junk bits needed for these operations as they require quite a few.&lt;br /&gt;&lt;br /&gt;The addition of tests to my code has been going smoothly as well. If I want to merge this code by the end of GSoC, I will need to begin to base my code off Matt Curry's code and document-test my code like crazy. These will likely be my primary concern for the next few weeks.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/936818886435977143-2894031447728849147?l=addisoncugini.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-23T19:55:10+00:00</dc:date>
	<dc:creator>AddisonCugini</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-22566012.post-7163828547914825642">
	<title>Christian Muise: Clause Learning and Heuristics</title>
	<link>http://haz-tech.blogspot.com/2010/07/clause-learning-and-heuristics.html</link>
	<content:encoded>&lt;hr /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;i&gt;Clause Learning&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;  Everyone should learn from their mistakes, right? Of course ;). Well SAT solvers are no different. If the solver discovers that the problem has no solution when a subset of the variables are set a certain way, then that is useful knowledge -- this knowledge is captured in the form of new clauses that are added to the theory.&lt;br /&gt;&lt;br /&gt;  Now you may think that since we're doing a systematic search, we won't ever need that information again: for example if x=True / y=True / z=False led to an inconsistency and we backtracked to try other values of z, y and x, will we ever use the fact that (!x | !y | z) must hold? When using a static variable ordering, the answer is no. This is because if we backtrack, we will never see the same setting of variables again that led to the inconsistency. However static variable orderings are brutal :p.&lt;br /&gt;&lt;br /&gt;  Let's expand on our example to see clause learning in a little more detail. Imagine the SAT solver went as follows:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Set x = True&lt;/li&gt;&lt;li&gt;From unit propagation set v1 = True and v2 = False&lt;/li&gt;&lt;li&gt;Set y = True&lt;/li&gt;&lt;li&gt;From unit propagation set v3 = False, v4 = True, v5 = False&lt;/li&gt;&lt;li&gt;Set z = False&lt;/li&gt;&lt;li&gt;From unit propagation we get the empty clause !!conflict!!&lt;/li&gt;&lt;/ul&gt;  So what do we know? Well right off the bat x = v1 = y = v4 = True and v2 = v3 = v5 = z = False is enough to make the theory unsatisfiable (so solution exists with those settings). But remember that unit propagation is a sound procedure -- the variables v1 - v5 are all implied by setting x and y to True [0]. So really just the settings to x, y, and z are enough to cause the problem. How could we have avoided it? Well what if we had the clause (!x | !y | z)? Note that this is just say at least one of the variables was set different. If we had that clause to begin with, our search would have looked like this:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Set x = True&lt;/li&gt;&lt;li&gt;From unit propagation set v1 = True and v2 = False&lt;/li&gt;&lt;li&gt;Set y = True&lt;/li&gt;&lt;li&gt;From unit propagation set v3 = False, v4 = True, v5 = False, &lt;b&gt;z = True&lt;/b&gt;&lt;/li&gt;&lt;li&gt;...&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;  So what we do is add the clause, (!x | !y | z), to our database of clauses and continue the search. Since we're backtracking, we'll set z=True anyways (the clause wasn't really needed), but in the future (say if we backtrack higher and go down another branch, we may face the same decisions. This is when the clause really becomes useful.&lt;br /&gt;&lt;br /&gt;  Now the method I just described uses a very simple technique to figure out the clause it should create / add -- it picks the negation of all the decisions you've made so far. However there are far more complex schemes that are ongoing research. I may incorporate these into SymPy some day, but for now the default &lt;a href=&quot;http://github.com/haz/sympy/commit/e85c6a8d7ac736bcbe1d60c3cb96d4f932421db4&quot;&gt;works great&lt;/a&gt; ;).&lt;br /&gt;&lt;br /&gt;  Another common concern (which I'll avoid dealing with for now) is how to detect useless clauses -- eventually learned clauses are no longer triggering and just taking up precious cycles in the solving process (and memory too). Elaborate cache flushing schemes have been proposed (and still are being actively researched), but SymPy likely won't be getting to the point where that would be necessary.&lt;br /&gt;&lt;br /&gt;  So that's all for clause learning. It's extremely helpful in the context of SAT solving, and is finally in our SymPy solver.&lt;br /&gt;&lt;br /&gt;[0]: I won't go into detail here, but you get the same result if you set a number of variables and then do unit prop as if you interleaved unit prop with each variable setting.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;div style=&quot;text-align: center;&quot;&gt;&lt;i&gt;VSIDS Heuristic&lt;/i&gt;&lt;/div&gt;&lt;br /&gt;  So behind any reasonable SAT solver is a great heuristic. Variable State Independent Decaying Sum (VSIDS) is one such heuristic. What does a heuristic do? Well at each node in the search tree, it should tell you what variable to set, and what to set it to.&lt;br /&gt;&lt;br /&gt;  VSIDS works by three main steps:&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;li&gt;First it assigns a score to every literal (or variable setting if you will) matching the number of clauses that the literal appears in. So if a literal is in a large number of clauses, it will be picked before one that isn't.&lt;/li&gt;&lt;li&gt;Every time a clause is added, the literals in that clause get their score bumped up (by 1). Every time a clause is deleted, the scores get reduced (by 1).&lt;/li&gt;&lt;li&gt;At regular intervals, /every/ literal has their score reduced by a constant factor (divide by two is typical).&lt;/li&gt;&lt;/ol&gt;  So what does this accomplish? Well at a high level it prefers variable settings that will satisfy the majority of clauses, and over time (through steps 2 and 3) it will prefer literals that will satisfy a large number of learned clauses. This has the effect of avoiding bad parts of the search space where a solution is unlikely to exist.&lt;br /&gt;&lt;br /&gt;  The SymPy solver &lt;a href=&quot;http://github.com/haz/sympy/commit/4690882e075e0ef1bbfdd3f8155e365fcdac17eb&quot;&gt;now has VSIDS&lt;/a&gt; driving the search, with the one step of #3 missing (coming soon ;)). The beauty of VSIDS is how nicely it plays with the clause-learning of the SAT solver to make things exceptionally fast.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;  That's all for now. I'll have another post soon showing some recent results, and one more within the following week to describe the data structures that make all this possible.&lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img src=&quot;https://blogger.googleusercontent.com/tracker/22566012-7163828547914825642?l=haz-tech.blogspot.com&quot; alt=&quot;&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2010-07-23T18:34:35+00:00</dc:date>
	<dc:creator>Haz</dc:creator>
</item>

</rdf:RDF>
